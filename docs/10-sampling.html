<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 10 Sampling | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 10 Sampling | Experimentology">

<title>Chapter 10 Sampling | Experimentology</title>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.18/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li><a href="1-experiments.html#experiments"><span class="toc-section-number">1</span> Experiments</a></li>
<li><a href="2-theories.html#theories"><span class="toc-section-number">2</span> Theories</a></li>
<li><a href="3-replication.html#replication"><span class="toc-section-number">3</span> Replication and reproducibility</a></li>
<li><a href="4-ethics.html#ethics"><span class="toc-section-number">4</span> Ethics</a></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li><a href="5-estimation.html#estimation"><span class="toc-section-number">5</span> Estimation</a></li>
<li><a href="6-inference.html#inference"><span class="toc-section-number">6</span> Inference</a></li>
<li><a href="7-models.html#models"><span class="toc-section-number">7</span> Models</a></li>
<li class="part"><span><b>III Design</b></span></li>
<li><a href="8-measurement.html#measurement"><span class="toc-section-number">8</span> Measurement</a></li>
<li><a href="9-design.html#design"><span class="toc-section-number">9</span> Design of experiments</a></li>
<li><a href="10-sampling.html#sampling"><span class="toc-section-number">10</span> Sampling</a></li>
<li class="part"><span><b>IV Execution</b></span></li>
<li><a href="11-prereg.html#prereg"><span class="toc-section-number">11</span> Preregistration</a></li>
<li><a href="12-collection.html#collection"><span class="toc-section-number">12</span> Data collection</a></li>
<li><a href="13-management.html#management"><span class="toc-section-number">13</span> Project management</a></li>
<li class="part"><span><b>V Reporting</b></span></li>
<li><a href="14-writing.html#writing"><span class="toc-section-number">14</span> Writing</a></li>
<li><a href="15-viz.html#viz"><span class="toc-section-number">15</span> Visualization</a></li>
<li><a href="16-meta.html#meta"><span class="toc-section-number">16</span> Meta-analysis</a></li>
<li><a href="17-conclusions.html#conclusions"><span class="toc-section-number">17</span> Conclusions</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li><a href="A-git.html#git"><span class="toc-section-number">A</span> GitHub Tutorial</a></li>
<li><a href="B-rmarkdown.html#rmarkdown"><span class="toc-section-number">B</span> R Markdown Tutorial</a></li>
<li><a href="C-tidyverse.html#tidyverse"><span class="toc-section-number">C</span> Tidyverse Tutorial</a></li>
<li><a href="D-ggplot.html#ggplot"><span class="toc-section-number">D</span> ggplot Tutorial</a></li>
<li><a href="E-instructors.html#instructors"><span class="toc-section-number">E</span> Instructor‚Äôs guide</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="sampling" class="section level1" number="10">
<h1><span class="header-section-number">Chapter 10</span> Sampling</h1>
<div class="learning-goals">
<p>üçé Learning goals:</p>
<ul>
<li>Discuss sampling theory and stratified sampling</li>
<li>Reason about limitations of different samples, especially convenience samples</li>
<li>Learn how to choose and justify an appropriate sample size for your experiment</li>
<li>Consider sampling biases and how they affect your inferences</li>
</ul>
</div>
<p>As we keep reminding you, experiments are designed to yield measurements of a causal effect. But a causal effect of what, and for whom? These are questions that are often given surprisingly little air time in our papers. Titles in our top journals read ‚ÄúDaxy thinking promotes fribbles,‚Äù ‚ÄúDoing fonzy improves smoodling,‚Äù or ‚ÄúBlicket practice produces more foozles than smonkers.‚Äù<label for="tufte-sn-163" class="margin-toggle sidenote-number">163</label><input type="checkbox" id="tufte-sn-163" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">163</span> Titles changed to protect the original authors. These researchers might very well have said more specific things in the text of their paper.</span> Each of these uses <strong>generic language</strong> to state a claim that is implied to be generally true <span class="citation">(<a href="#ref-dejesus2019" role="doc-biblioref">DeJesus et al., 2019</a>)</span>,<label for="tufte-sn-164" class="margin-toggle sidenote-number">164</label><input type="checkbox" id="tufte-sn-164" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">164</span> Generic language is a fascinating linguistic phenomenon. When we say things like ‚Äúmosquitoes transmit malaria,‚Äù we don‚Äôt mean that <em>all</em> mosquitos do it, only something like ‚Äúit‚Äôs a valid and diagnostic generalization about mosquitoes in contrast to other relevant insects or other creatures that they are spreaders of malaria‚Äù <span class="citation">(<a href="#ref-tessler2019" role="doc-biblioref">Tessler &amp; Goodman, 2019</a>)</span>.</span> but for each of these, we could reasonably ask ‚Äúdoing fonzy improves smoodling <em>for whom</em>?‚Äù Is it everyone? Or a particular set of people? And similarly, we might want to ask ‚Äú<em>how much</em> and <em>what kind</em> of fonzy reading?‚Äù These are questions about the <strong>generalizability of research</strong>.<label for="tufte-sn-165" class="margin-toggle sidenote-number">165</label><input type="checkbox" id="tufte-sn-165" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">165</span> Imagine for a second what a non-generic version of one of these titles might look like: ‚ÄúReading one particular selection of fonzy for fifteen minutes in the lab improved 36 college students‚Äô smoodling scores on a questionnaire.‚Äù It seems pretty clear that we wouldn‚Äôt let the authors get away with a fully general version of their claim: ‚ÄúDoing [<em>any</em>] fonzy improves smoodling [<em>for anyone</em>].‚Äù That‚Äôs just a bad generalization.</span></p>
<p>We‚Äôve already run into generalizability in our treatment of statistical estimation and inference. When we estimated a particular quantity (say, the effect of fonzy), we did so in our own sample. But we then used inferential tools to reason about how this <strong>sample</strong>‚Äôs estimate related to the <strong>population</strong> as a whole. How do we link up these statistical tools for generalization to the scientific questions we have about the generalizability of our findings? That‚Äôs the question of this chapter.</p>
<p>The first key set of decisions in experiment planning is what population to sample from and how to sample. We‚Äôll start by talking about the basics of <strong>sampling theory</strong>: different ways of sampling and the generalizations they do and don‚Äôt license. In this context, we also discuss <strong>stimulus sampling</strong>, a pervasive and under-appreciated challenge to the generalizability of behavioral research. A second set of key decisions is about <strong>sample size</strong> planning. We‚Äôll start with classic <strong>power analysis</strong> but then introduce several other ways that an experimenter can plan and justify their sample size. In the final section, we‚Äôll consider some of the broader issues that come up in sampling, including several sampling biases that can lead to biases in the experimental effect. We‚Äôll end with a discussion of some broader questions about generalizability in behavioral research.</p>
<div class="case-study">
<p>üî¨ Case study: Is everyone as bad at describing smells as I am?</p>
<p>Since Darwin, scientists have assumed that smell is a vestigial sense in humans ‚Äì one that we don‚Äôt even bother to encode in language. In English we don‚Äôt even have consistent words for odors. We can say something is ‚Äústinky,‚Äù ‚Äúfragrant, or maybe‚Äùmusty,‚Äù but beyond these, all our words for smells are about the <em>source</em> of the smell, not the qualities of it. Bananas, roses, and skunks all have distinctive smells, but we don‚Äôt have any vocabulary for naming what is common or uncommon about them. And when we make up ad-hoc vocabulary, it‚Äôs typically quite inconsistent <span class="citation">(<a href="#ref-majid2014" role="doc-biblioref">Majid &amp; Burenhult, 2014</a>)</span>. The same situation applies across many languages.</p>
<p>So, would it be a good generalization about human beings ‚Äì all people ‚Äì that olfaction as a sense is de-emphasized relative to vision? This inference has a classic sample-to-population structure. We notice that, within several samples of participants using widely-spoken languages, we observe limited and inconsistent vocabulary for smells, as well as poor discrimination. We use these samples to license an inference to the population ‚Äì in this case, the entire human population.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:sampling-majid2014"></span>
<img src="images/sampling/majid2014.png" alt="Data from Majid and Burenhult (2014) on the consistency of color and odor naming in English and Jahai speakers. Higher values indicate more consistent descriptions. Pie charts indicate the type of language being used." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 10.1: Data from Majid and Burenhult (2014) on the consistency of color and odor naming in English and Jahai speakers. Higher values indicate more consistent descriptions. Pie charts indicate the type of language being used.<!--</p>-->
<!--</div>--></span>
</p>
<p>But these inferences about the universal lack of olfactory vocabulary are likely based on choosing the wrong sample. Multiple hunter-gatherer groups appear to have large vocabularies for consistent smell description. For example, the Jahai, a hunter-gatherer group on the Malay Peninsula, have a vocabulary that includes at least twelve words for distinct odors, for example /c≈ãŒµs/, which names odors with a ‚Äústinging smell‚Äù like gasoline, smoke, or bat droppings. When Jahai speakers are asked to name odors, they produce shorter and much more consistent descriptions than English speakers ‚Äì in fact, their smell descriptions were as consistent as their color descriptions (Figure <a href="10-sampling.html#fig:sampling-majid2014">10.1</a>). Further studies implicate the hunter-gatherer lifestyle as a factor: while several hunter-gatherer groups show good odor naming, nearby horticulturalist groups don‚Äôt <span class="citation">(<a href="#ref-majid2018" role="doc-biblioref">Majid &amp; Kruspe, 2018</a>)</span>.</p>
<p>Generalizations about humans are tricky. If you want to estimate the average odor naming ability, you could take a random sample of humans and evaluate their odor naming. Most of the individuals in the sample would likely speak English, Mandarin, Hindi, or Spanish. Almost certainly, none of them would speak Jahai, which spoken by only a little more than a thousand people and is listed as <a href="https://www.ethnologue.com/language/jhi">Threatened</a> by Ethnologue. Your estimate of low odor naming stability would be a good guess for the majority of the world‚Äôs population.</p>
<p>On the other hand, it‚Äôs more complicated to jump from a statistical generalization about average ability to a richer claim, like ‚Äúas humans evolved, they lost olfactory ability and gained visual ability.‚Äù Such claims about <em>what humans are like</em> require much more care and much stronger evidence <span class="citation">(<a href="#ref-piantadosi2014" role="doc-biblioref">Piantadosi &amp; Gibson, 2014</a>)</span>. From a sampling perspective, human behavior and cognition show immense and complex <strong>heterogeneity</strong> ‚Äì variability of individuals and variability across clusters. As a result, naive random samples will have very high variance, leading to problematic generalizations. Put simply, if we want to know what people in general are like, we can‚Äôt just choose a bunch of English speakers on a college campus in the United States.</p>
</div>
<div id="sampling-theory" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> Sampling theory</h2>
<p>The basic idea of sampling is simple: you want to estimate some measurement for a large or infinite population by measuring a sample from that population.<label for="tufte-sn-166" class="margin-toggle sidenote-number">166</label><input type="checkbox" id="tufte-sn-166" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">166</span> There are some tools for dealing with estimation in smaller populations where your sample is a substantial fraction of the population (e.g., a survey of your department where you get responses from half of the students). We won‚Äôt discuss those here; our focus is on generalizing to large populations of humans.</span> Sampling strategies are split into two categories: <strong>probability sampling</strong> ‚Äì in which every member of the population has some chance of being selected ‚Äì and <strong>non-probability sampling</strong> ‚Äì in which there are some members of the population that simply cannot be selected. We‚Äôll begin by discussing probability sampling, then we‚Äôll talk about a useful technique for sampling called <strong>stratified sampling</strong>.</p>
<div id="classical-probability-sampling" class="section level3" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> Classical probability sampling</h3>
<p>Classical sampling theory is built around the idea of <strong>probability sampling</strong>. There is some <strong>sampling frame</strong> containing every member of the population ‚Äì think of a giant phone book with every adult human‚Äôs name in it. Then we use some kind of <strong>sampling strategy</strong>, maybe at the simplest just a completely random choice, to select <span class="math inline">\(N\)</span> humans from that sample frame, and then we collect our measure with them. This scenario is the one that informs all of our statistical results about how sample means converge to the population mean (as in Chapter <a href="6-inference.html#inference">6</a>).</p>
<p>Unfortunately, we essentially <em>never</em> do sampling of this sort in psychological research. Gathering random samples from the large populations that we‚Äôd like to generalize to is far too difficult and expensive. Consider the problems involved in doing some experiment with a sample of <em>all adult humans</em>, or even <em>adult English-speaking humans who are located in the United States</em>. As soon as you start to think about what it would take to collect a probability sample of this kind of population, the complexities get overwhelming. How will you find their names (what if they aren‚Äôt in the phone book)? How will you contact them (what if they don‚Äôt have email)? How will they do your experiment (what if they don‚Äôt have an up-to-date web browser)? What if they don‚Äôt want to participate?</p>
<p>Instead, the vast majority of psychology research has been conducted with <strong>convenience samples</strong>: non-probability samples that feature individuals who can be recruited easily, like college undergraduates or workers on crowdsourcing platforms like Amazon Mechanical Turk (see Chapter <a href="12-collection.html#collection">12</a>). These convenience samples present very different generalization challenges.</p>
</div>
<div id="representative-samples-and-stratified-sampling" class="section level3" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> Representative samples and stratified sampling</h3>
<p>For survey research ‚Äì think about election polling ‚Äì there are many sophisticated techniques for dealing with these issues; although this field is still imperfect, it has advanced considerably in trying to predict complex and dynamic behaviors. One of the basic ideas is the construction of <strong>representative samples</strong>: samples that resemble the population in their representation of one or several sociodemographic characteristics like gender, income, race and ethnicity, age, political orientation. These samples can be constructed by random sampling, but they can also be constructed through non-probability methods like recruiting quotas of individuals from different groups. These methods are critical for much social science research, but they have been used less frequently in experimental psychology research and aren‚Äôt necessarily a critical part of the beginning experimentalist‚Äôs toolkit.<label for="tufte-sn-167" class="margin-toggle sidenote-number">167</label><input type="checkbox" id="tufte-sn-167" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">167</span> Readers can come up with counter-examples of recent studies that focus on representative sampling, but our guess is that they will prove the rule more generally. For example, a recent study tested the generality of growth mindset interventions for US high school students using a national sample <span class="citation">(<a href="#ref-yeager2019" role="doc-biblioref">Yeager et al., 2019</a>)</span>. This large-scale study sampled more than 100 high schools from a sampling frame of all registered high schools in the US, then randomly assigned students within schools that agreed to participate. They then checked that the schools that agreed to participate were representative of the broader population of schools. This study is great stuff, but we hope you agree that if you find yourself in this kind of situation ‚Äì planning a multi-investigator 5 year consortium study on a national sample ‚Äì you might want to consult with a statistician and not use an introductory book like this one.</span></p>
<p>There is one exception that we think you should know about, however. Imagine you‚Äôre interested in a particular measure in a population ‚Äì say, attitudes towards tea drinking across US adults ‚Äì but you think that this measure will vary with one or more characteristics such as whether the adults are frequent, infrequent, or non-coffee drinkers. Even worse, your measure might be more variable within one group: perhaps most coffee drinkers feel OK about tea, but non-drinkers either love it (they are tea drinkers) or hate it (they don‚Äôt drink any hot beverages). A simple random sample from this population will converge asymptotically to the correct population average for tea-drinking attitudes. But it will do so somewhat more slowly than ideal because any given sample may over- or under-sample non-drinkers just by chance.</p>
<div class="figure"><span id="fig:sampling-stratified"></span>
<p class="caption marginnote shownote">
Figure 10.2: Illustration of stratified sampling. The left panel shows the sampling frame. The upper frames show the sampling frame stratified by a participant characteristic and a stratified sample. The lower frame shows a simple random sample, which happens to omit one group completely by chance.
</p>
<img src="images/sampling/stratified-sample2.png" alt="Illustration of stratified sampling. The left panel shows the sampling frame. The upper frames show the sampling frame stratified by a participant characteristic and a stratified sample. The lower frame shows a simple random sample, which happens to omit one group completely by chance." width="\linewidth"  />
</div>
<p><strong>Stratified sampling</strong> is a very useful trick that makes your effect estimates more precise in cases like this one <span class="citation">(<a href="#ref-neyman1992" role="doc-biblioref">Neyman, 1992</a>)</span>. If you know the proportion of frequent, infrequent, or non-coffee drinkers in the population, you can sample within those subpopulations to ensure that your sample is representative along this dimension. This situation is pictured in Figure <a href="10-sampling.html#fig:sampling-stratified">10.2</a>, which shows how a particular sampling frame can be broken up into groups for stratified sampling (top). The result is a sample that matches the population proportions on a particular characteristic. In contrast, a simple random sample (bottom) can over- or under-sample the subgroups by chance.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:sampling-stratified-sim"></span>
<img src="experimentology_files/figure-html/sampling-stratified-sim-1.png" alt="Simulation showing the potential benefits of stratification. Each dot is an estimated mean for a sample of a particular size, sampled randomly or with stratification. Red points show the mean and standard deviation of sample estimates." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 10.3: Simulation showing the potential benefits of stratification. Each dot is an estimated mean for a sample of a particular size, sampled randomly or with stratification. Red points show the mean and standard deviation of sample estimates.<!--</p>-->
<!--</div>--></span>
</p>
<p>Stratified sampling can lead to substantial gains in the precision of your estimate. These gains are most prominent when either the groups differ a lot in their mean or when they differ a lot in their variance.<label for="tufte-sn-168" class="margin-toggle sidenote-number">168</label><input type="checkbox" id="tufte-sn-168" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">168</span> There are several important refinements of stratified sampling in case you think these methods are important for your problem. In particular, <strong>optimal sampling</strong> can help you figure out how to over-sample groups with higher variance.</span> On the other hand, if the characteristic on which you stratify participants doesn‚Äôt relate to your measure at all, then stratified sampling converges just as fast as random sampling (though it‚Äôs a bit more of a pain to implement). Figure <a href="10-sampling.html#fig:sampling-stratified-sim">10.3</a> shows a simulation of the scenario in Figure <a href="10-sampling.html#fig:sampling-stratified">10.2</a>, in which each coffee preference group has a different tea attitude mean, and the smallest group has the biggest variance. Although the numbers here are invented, it‚Äôs clear that estimation error is much smaller in the stratified group and estimation error declines much more quickly as samples get larger.</p>
<p>Stratification is everywhere, and it‚Äôs useful even in convenience samples. For example, researchers who are interested in development typically stratify their samples across ages (e.g., recruiting equal numbers of two- and three-year-olds for a study of preschoolers). It‚Äôs not that you can‚Äôt estimate developmental change in a pure random sample; instead, it‚Äôs that you are guaranteed good coverage of the range of interest when you stratify. If you have a measure that you think varies with a particular characteristic, it‚Äôs not a bad idea to consider stratification. But don‚Äôt go overboard ‚Äì you can drive yourself to distraction finding the last left-handed non-binary coffee drinker to complete your sample. Focus on stratifying when you know the measure varies with the characteristic of interest.</p>
</div>
</div>
<div id="convenience-samples-generalizability-and-the-weird-problem" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Convenience samples, generalizability, and the WEIRD problem</h2>
<p>Let‚Äôs go back to the question of generalizability. How generalizable are the experimental effect estimates that we obtain in our experiments? We‚Äôll start by laying out the worst version of the problem of generalizability in experimental psychology. Maybe we don‚Äôt really know anything about any population of interest. We‚Äôll then try to pull back from the brink and discuss some reasons why we might not want to be in despair despite some of the true generalizability issues that plague the psychology literature.</p>
<div id="the-worst-version-of-the-problem" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> The worst version of the problem</h3>
<p>Psychology is the study of the human mind. But from a sampling theory standpoint, not a single estimate in the published literature is based on a sample from the human population. So no estimate can be generalized to the object of study. And the situation is worse than that. Here are three of the most severe issues that have been raised regarding the generalizability of psychology research.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Convenience samples</strong>. In the middle of the last section, we dropped a little bombshell: almost all research in experimental psychology is performed with convenience samples. This issue has led to the remark that ‚Äúthe existing science of human behavior is largely the science of the behavior of sophomores‚Äù <span class="citation">(McNemar, 1946, quoted in <a href="#ref-rosenthal1984" role="doc-biblioref">Rosenthal &amp; Rosnow, 1984</a>)</span>. As we‚Äôll discuss again in Chapter <a href="12-collection.html#collection">12</a>, the samples we have easy access to don‚Äôt represent the populations we want to describe. There is a twitter account devoted to finding biology papers that make big claims about curing diseases and appending the qualifier ‚Äúin mice‚Äù to them. We might consider whether we need to do the same to psychology papers. Would ‚ÄúDoing fonzy improves smoodling <em>in sophomore college undergraduates in the Western US</em>‚Äù make it into a top journal?</p></li>
<li><p><strong>The WEIRD problem</strong>. Not only are the convenience samples that we study not representative of the local or national contexts in which they are recruited, those local and national contexts are also very far from the broader human experience (see <a href="1-experiments.html#experiments">1</a>. <span class="citation">Henrich et al. (<a href="#ref-henrich2010" role="doc-biblioref">2010</a>)</span> coined the term WEIRD (Western, Educated, Industrialized, Rich, and Democratic) to sum up some of the ways that typical participants in psychology experiments differ from the typical human experience. Participants from WEIRD cultures likely think, speak, reason, and perceive differently than those from other backgrounds. The vast over-representation of WEIRD participants in the literature has led some researchers to suggest that published results simply reflect ‚ÄúWEIRD psychology‚Äù ‚Äì a small and idiosyncratic part of a much broader universe of human psychology.<label for="tufte-sn-169" class="margin-toggle sidenote-number">169</label><input type="checkbox" id="tufte-sn-169" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">169</span> The term WEIRD has been very useful in drawing attention to the lack of representation of the breadth of human experiences in experimental psychology. But one negative consequence of this idea has been the response that what we need to do as a field is to sample more ‚Äúnon-WEIRD‚Äù people. The imposition of a binary distinction ‚Äì in which every culture outside the WEIRD moniker is the same in some major respect ‚Äì is unfair and not useful <span class="citation">(<a href="#ref-syed2020" role="doc-biblioref">Syed &amp; Kathawalla, 2020</a>)</span>. A better starting point is to consider the way that cultural variation might guide our choices about sampling, as we discuss below.</span></p></li>
<li><p><strong>The item sampling issue</strong>. As we discussed in Chapter <a href="7-models.html#models">7</a>, we‚Äôre typically not just trying to generalize to new people, we‚Äôre also trying to generalize to new stimuli <span class="citation">(<a href="#ref-westfall2015" role="doc-biblioref">Westfall et al., 2015</a>)</span>. The problem is that our experiments often use a very small set of stimuli, constructed by experimenters in an ad-hoc way rather than sampled as representatives of a broader population of stimuli that we hope to generalize to with our effect size estimate.<label for="tufte-sn-170" class="margin-toggle sidenote-number">170</label><input type="checkbox" id="tufte-sn-170" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">170</span> What‚Äôs more, our statistical analyses sometimes fail to take stimulus variation into account <span class="citation">(<a href="#ref-clark1973" role="doc-biblioref">Clark, 1973</a>)</span>.</span> Unless we know about the relationship of our stimuli to the broader population, our estimates may be biased in yet another way.</p></li>
</ol>
<p>In sum, experiments in the psychology literature primarily measure effects from WEIRD convenience samples of people and unsystematic samples of experimental stimuli. Should we throw up our hands and resign ourselves to an ungeneralizable ‚Äúscience‚Äù of sample-specific anecdotes?</p>
</div>
<div id="reasons-for-hope-and-ways-forward" class="section level3" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Reasons for hope and ways forward</h3>
<p>We think the situation isn‚Äôt as bleak as the arguments above might have suggested. Underlying each of the arguments above is the notion of <strong>heterogeneity</strong> in effects, the idea that particular experimental effects vary in the population.</p>
<p>Let‚Äôs think through a very simple version of this argument. Let‚Äôs say we have an experiment that measures the smoodling effect, and it turns out that smoodling is completely universal and invariant throughout the human population. Now, if we want to get a precise estimate of smoodling, we can take any sample we want because everyone will show the same pattern. Because smoodling is homogeneous, a biased, non-representative sample will not cause problems. It turns out that there are likely tasks like this ‚Äì for example, the Stroop task. The Stroop task is a bad individual difference measure because it produces a consistent and similar interference effect for many different participants <span class="citation">(<a href="#ref-hedge2018" role="doc-biblioref">Hedge et al., 2018</a>)</span>.</p>
<div class="figure"><span id="fig:sampling-heterogeneity"></span>
<p class="caption marginnote shownote">
Figure 10.4: Illustration of the interaction of heterogeneity and convenience samples. Left hand panels show sample composition. Individual plots show the weighted distribution of responses on some measure.
</p>
<img src="images/sampling/heterogeneity.png" alt="Illustration of the interaction of heterogeneity and convenience samples. Left hand panels show sample composition. Individual plots show the weighted distribution of responses on some measure." width="\linewidth"  />
</div>
<p>Figure <a href="10-sampling.html#fig:sampling-heterogeneity">10.4</a> illustrates this argument more broadly. If you have a random sample (top), then your sample mean and your population mean will converge to the same value, regardless of whether the effect is homogeneous (right) or heterogeneous (right). That‚Äôs the beauty of sampling theory.<label for="tufte-sn-171" class="margin-toggle sidenote-number">171</label><input type="checkbox" id="tufte-sn-171" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">171</span> You do get faster convergence if you stratify the sample, though ‚Äì that‚Äôs precisely what our simulation above showed.</span> Tf you have a convenience sample (bottom), one part of the population is over-represented in the sample. The convenience sample doesn‚Äôt cause problems if the effect is homogeneous in the population ‚Äì as with the case of smoodling or Stroop. The trouble comes when you have a heterogeneous effect. Because one group is over-represented, you get systematic bias in the sample mean relative to the population mean.</p>
<p>So the problems listed above ‚Äì convenience samples, WEIRD samples, and narrow stimulus samples ‚Äì only cause problems if effects are heterogeneous. Are they? The short answer is, <em>we don‚Äôt know</em>. If you‚Äôre reading carefully, you‚Äôll notice a problem. Convenience samples are fine in the presence of homogeneous effects, but we only use convenience samples so we may not know which effects are homogeneous!</p>
<p>We can‚Äôt do better than this circularity without a theory of what should be variable and what should be consistent between individuals.<label for="tufte-sn-172" class="margin-toggle sidenote-number">172</label><input type="checkbox" id="tufte-sn-172" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">172</span> Many people have theorized about the ways that culture and language in general might moderate psychological processes <span class="citation">(e.g., <a href="#ref-markus1991" role="doc-biblioref">Markus &amp; Kitayama, 1991</a>)</span>. What we‚Äôre talking about is related but slightly different ‚Äì a theory not of what‚Äôs different, but of when there should be any difference and when there shouldn‚Äôt be.</span> As naive observers of human behavior, differences between people often loom large. We are keen observers of social characteristics like age, gender, race, class, and education. For this reason, our first theories of psychology often foreground these characteristics as the primary locus for variation between people. Certainly these characteristics are important, but they fail to explain many of the <em>in</em>variances of human psychology as well. An alternative line of theorizing starts with the idea that ‚Äúlower-level‚Äù parts of psychology ‚Äì like perception ‚Äì should be less variable than ‚Äúhigher-level‚Äù faculties like social cognition. This kind of theory sounds like a useful place to start, but there are also plenty of counter-examples in the literature <span class="citation">(<a href="#ref-henrich2010" role="doc-biblioref">Henrich et al., 2010</a>)</span>.</p>
<p>One positive direction for the future is the rise of multi-lab, multi-nation studies. For example, ManyLabs 2 systematically investigated replicability of a set of phenomena across cultures <span class="citation">(<a href="#ref-klein2018" role="doc-biblioref">O. Klein et al., 2018</a>)</span>, finding limited variation in effects between WEIRD sites and other sites. And in a study comparing a set of convenience and probability samples, <span class="citation">Coppock et al. (<a href="#ref-coppock2018" role="doc-biblioref">2018</a>)</span> found limited demographic heterogeneity in a sample of experimental effects from across the social sciences. Large-scale studies like these offer the possibility of measuring and systematically characterizing demographic and cultural variation ‚Äì as well as how variation itself varies between phenomena!</p>
</div>
<div id="reasoning-about-sampling-bias" class="section level3" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> Reasoning about sampling bias</h3>
<p>In fields like econometrics or epidemiology that use observational methods to estimate causal effects, reasoning about sampling biases is a critical part of estimating generalizable effects. That‚Äôs because the measure that these fields are interested in ‚Äì for example, outcomes to do with health and wealth ‚Äì vary widely across individuals. So if you assess some association, say between tea consumption and cardiovascular disease, you need to think very carefully about how your sampling process interacts with this causal structure.</p>
<p>Imagine you want to measure the association between wealth and happiness through a survey. As we discussed in Chapter <a href="1-experiments.html#experiments">1</a>, there are plenty of confounds that we can come up with: factors that might make you both wealthier and happier. We can also create other sorts of problems if we are careless in our sampling. One prominent problem that we can induce is called <strong>collider bias</strong>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:sampling-money"></span>
<img src="images/sampling/money3-drawing.png" alt="Four reasons why money and happiness can be correlated in a particular sample: 1. causal relationship, 2. reverse causality, 3. confounding with friendship, and 4. collider bias in your sample." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 10.5: Four reasons why money and happiness can be correlated in a particular sample: 1. causal relationship, 2. reverse causality, 3. confounding with friendship, and 4. collider bias in your sample.<!--</p>-->
<!--</div>--></span>
</p>
<p>Suppose we recruited our sample from the clients of a social services agency. Unfortunately, both of our variables might have a causal relationship with presence in a social service agency (Figure <a href="10-sampling.html#fig:sampling-money">10.5</a>: people might be interacting with the agency for financial or benefits assistance, or else for psychological services (perhaps due to depression). In this sample, we might see a <em>negative</em> association between wealth and happiness ‚Äì on average the people coming for financial assistance would have less wealth and more happiness than the people coming for psychological services ‚Äì instead of the <em>positive</em> but confounded association we talked about in Chapter <a href="1-experiments.html#experiments">1</a>. The take-home here is that if there is a causal relationship between your variables of interest and presence in your sample, you have <strong>collider bias</strong>.</p>
</div>
</div>
<div id="sample-size-planning" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> Sample size planning</h2>
<p>Now that you have spent some time considering your sample and what population it represents, how many people will your sample contain? As we learned in Chapter <a href="3-replication.html#replication">3</a>, continuing to collect data until you observe a <span class="math inline">\(p &lt; .05\)</span> in an inferential test is a good way to get a false positive. To avoid this situation, you need some kind of plan for when you will stop collecting data! Your <strong>stopping rule</strong> can then be a key part of your preregistration, so as to be transparent that your choice of stopping rule didn‚Äôt invalidate your statistical inference (see Chapter <a href="11-prereg.html#prereg">11</a>).</p>
<p>The simplest stopping rule is ‚ÄúI‚Äôll collect data until I get to a target <span class="math inline">\(N\)</span>‚Äù ‚Äì all that‚Äôs needed in this case is a value for <span class="math inline">\(N\)</span>. Classically, this value was computed using <strong>power analysis</strong>, which can provide a value for which you have a good chance of rejecting the null hypothesis given a particular expected effect size. But standard power analysis relies on knowing what size effect you are expecting, which is often an unrealistic assumption. If we knew what size effect we expected, wouldn‚Äôt we already have the information that we are conducting the experiment to get?</p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:sampling-stopping-rules">Table 10.1: </span>Example classes of experimental stopping rules.</span><!--</caption>--></p>
<table>
<colgroup>
<col width="1%" />
<col width="15%" />
<col width="46%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th align="right"></th>
<th align="left">Method</th>
<th align="left">Stopping Rule</th>
<th align="left">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Power analysis</td>
<td align="left">Stop at N for known probability of rejecting the null given known effect size</td>
<td align="left">Randomized trial with strong expectations about effect size</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">Smallest effect size of interest</td>
<td align="left">Stop at N for known probability of rejecting the null for effects greater than some minimum</td>
<td align="left">Measurement of unknown but important effect</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="left">Resource constraint</td>
<td align="left">Stop collecting data after a certain amount of time or after a certain amount of resources are used</td>
<td align="left">Time-limited field work</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="left">Precision analysis</td>
<td align="left">Stop at N that provides some known degree of precision in measure</td>
<td align="left">Experimental measurement to compare with predictions of cognitive models</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="left">Sequential analysis</td>
<td align="left">Stop when a known inferential criterion is reached</td>
<td align="left">Intervention trial designed to accept or reject null with maximal efficiency</td>
</tr>
</tbody>
</table>
<p>There are many different stopping rules that can be used to justify a sample size (Table @ref(tab:sampling-stopping rules)). Each of these can provide a valid justification for a particular sample size, but they are most useful in different situations. We‚Äôll first introduce classic power analysis both because it is a common standard and because it illustrates some of the concepts used in others (e.g., <strong>smallest effect size of interest</strong> or SESOI analysis). We‚Äôll then discuss alternative approaches.</p>
<div id="classic-power-analysis" class="section level3" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Classic power analysis</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:sampling-neyman-pearson"></span>
<img src="images/inference/power-alpha.png" alt="Standard decision matrix for NHST." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 10.6: Standard decision matrix for NHST.<!--</p>-->
<!--</div>--></span>
</p>
<p>Let‚Äôs start by reviewing the null-hypothesis significance testing paradigm that we introduced in Chapter <a href="6-inference.html#inference">6</a>. Recall that we introduced a decision-theoretic view of testing in Section 6.3.3, shown again in Figure <a href="10-sampling.html#fig:sampling-neyman-pearson">10.6</a>. The idea was that we‚Äôve got some null hypothesis <span class="math inline">\(H_0\)</span> and some alternative <span class="math inline">\(H_1\)</span> ‚Äì something like ‚Äúno effect‚Äù and ‚Äúyes, there is some effect with known size‚Äù‚Äì and we want to use data to decide which state we‚Äôre in. <span class="math inline">\(\alpha\)</span> is our criterion for rejecting the null. <span class="math inline">\(\beta\)</span></p>
</div>
<div id="alternative-approaches-to-sample-size-planning" class="section level3" number="10.3.2">
<h3><span class="header-section-number">10.3.2</span> Alternative approaches to sample size planning</h3>
<ul>
<li>Smallest effect size of interest (SESOI analysis)
<ul>
<li>Precision-based sample size planning (Bland 2009; Lash and Kaufman 2015) (malcolmbarrett.shinyapps.io/precisely)</li>
<li>Simulation based</li>
<li>Sequential analysis (Sch√∂nbrodt et al.¬†2017)</li>
</ul></li>
</ul>
<p>sample calculations for within/between subjects
<a href="http://daniellakens.blogspot.com/2016/11/why-within-subject-designs-require-less.html" class="uri">http://daniellakens.blogspot.com/2016/11/why-within-subject-designs-require-less.html</a>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6640316/" class="uri">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6640316/</a></p>
<!-- ### Repeated measures designs: more people or more items?  -->
<!-- DeBolt and Oakes -->
</div>
<div id="sample-sizes-for-replication-studies" class="section level3" number="10.3.3">
<h3><span class="header-section-number">10.3.3</span> Sample sizes for replication studies</h3>
<p>Setting the sample size for a replication study has been a persistent issue in the meta-science literature. Naively speaking, it seems like you should be able to compute the effect size for the original study and then simply use that as the basis for a classical power analysis. This approach has several flaws, however. First, the effect size from the original published paper is likely an overestimate of the true effect size due to publication bias <span class="citation">(<a href="#ref-nosek2021" role="doc-biblioref">Brian A. Nosek et al., 2021</a>)</span>.<label for="tufte-sn-173" class="margin-toggle sidenote-number">173</label><input type="checkbox" id="tufte-sn-173" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">173</span> Imagine the counterfactual world in which the same study had yielded a smaller and perhaps non-significant effect size. Would it still have been published in the same form, and would you still want to replicate? If not, then consider the fact that the authors ‚Äúgot lucky‚Äù ‚Äì even if the effect is truly present, perhaps this particular experiment happened to observe a larer effect than the true value just by chance.</span> Second, the power analysis will only yield the sample size at which the replication will have a particular chance of rejecting the null at some criterion. But it‚Äôs quite possible that the original experiment could be <span class="math inline">\(p&lt;.05\)</span>, the replication could be <span class="math inline">\(p&gt;.05\)</span>, and yet they could not differ from one another. So a statistically significant replication of the original effect size is not necessarily what you want to aim for.</p>
<p>Faced with these issues, a replication sample size can be planned in several other ways. First, replicators can use standard strategies above such as SESOI or resource-based planning to rule out large effects with high probability or to spend a known amount of time or money. The issue is that these strategies can produce an unsatisfying result if the SESOI is high or limited resources are allocated; a conclusive answer can require a very substantial commitment of resources.</p>
<p>Second, <span class="citation">Simonsohn (<a href="#ref-simonsohn2015" role="doc-biblioref">2015</a>)</span> recommends the ‚Äúsmall telescopes‚Äù approach. The idea is not to test whether there <em>is</em> an effect, but rather where there is an effect <em>large enough that the original study could have detected it</em>. The analogy is to astronomy. If a birdwatcher points their binoculars at the sky and claims to have discovered a new planet, we want to ask not just whether there is a planet at that location, but also whether there is any possibility that they could have seen it using that device ‚Äì if not, perhaps they are right but for the wrong reasons! Simonsohn shows that, if a replicator collects 2.5 times as large a sample as the original, they have 80% power to detect any effect that was reasonably detectable by the original. This simple rule of thumb provides one good starting place for conservative replication studies.</p>
<p>Finally, replicators can make use of sequential Bayesian analysis, in which they attempt to gather substantial evidence relative to the support for <span class="math inline">\(H_1\)</span> <em>or</em> <span class="math inline">\(H_0\)</span>. This is an appealing option because it allows for efficient collection of data that reflects whether an effect is likely to be present in a particular sample, especially in the face of the sometimes prohibitively large samples necessary for SESOI or ‚Äúsmall telescopes‚Äù analyses.</p>
</div>
</div>
<div id="summary-sampling" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> Summary: Sampling</h2>
<p>Your goal as an experimenter is to estimate a causal effect. But the effect for whom? This chapter has tried to help you think about how you generalize from your experimental sample to some target population. It‚Äôs very rare for you to be conducting an experiment based on a probability sample in which every member of the population. In the case that you are using a convenience sample, you will need to consider how bias introduced by the sample could relate to the effect estimate you observed. Do you think this effect is likely to be very heterogeneous in the population? Are there theories that suggest that it might be larger or smaller for the convenience sample you recruited?</p>
<p>Questions about generalizability and sampling depend on the precise construct you are studying, and there is no mechanistic procedure for answering them. Instead, you simply have to ask yourself: how does my sampling procedure qualify the inference I want to make based on my data? Being transparent about your reasoning can be very helpful ‚Äì both to you and to readers of your work who want to contextualize the generality of your findings.</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-9" class="exercise"><strong>Exercise 10.1  </strong></span>Form an argument about this controversial position: We want to understand human cognition generally, but it‚Äôs a more efficient research strategy to start by studying certain features of cognition (perception, for example) in WEIRD convenience populations and then later check our generalizations in non-WEIRD groups.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-10" class="exercise"><strong>Exercise 10.2  </strong></span>Form an argument about this controversial position: The most influential experiments aren‚Äôt generalizations of some number to a population, they are demonstration experiments that show that some particular effect is possible under some circumstances (think Milgram‚Äôs conformity studies, where people apparently shocked a confederate at an experimenter‚Äôs prompting), so often specific population sampling is secondary.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-11" class="exercise"><strong>Exercise 10.3  </strong></span>Form an argument about this controversial position: Nothing you learn from US college undergraduates is likely to generalize to the US population as a whole, so we should dramatically decrease the use of this convenience population.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-12" class="exercise"><strong>Exercise 10.4  </strong></span>Form an argument about this controversial position: We can‚Äôt ever make generalizations about the human mind because so much of the historical human population is simply inaccessible to us (we can‚Äôt do experiments on ancient Greek psychology). Psychological samples are also sampling a particular moment in time.</p>
</div>
<div class="reading">
<p>üìö Suggested readings:</p>
<ul>
<li><p>Henrich, J., Heine, S. J., &amp; Norenzayan, A. (2010). The WEIRDest people in the world? <em>Behavioral and Brain Sciences,</em> 33(2-3), 61-83.</p></li>
<li></li>
</ul>
</div>

</div>
</div>



<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-clark1973" class="csl-entry">
Clark, H. H. (1973). The language-as-fixed-effect fallacy: A critique of language statistics in psychological research. <em>Journal of Verbal Learning and Verbal Behavior</em>, <em>12</em>(4), 335‚Äì359.
</div>
<div id="ref-coppock2018" class="csl-entry">
Coppock, A., Leeper, T. J., &amp; Mullinix, K. J. (2018). Generalizability of heterogeneous treatment effect estimates across samples. <em>Proceedings of the National Academy of Sciences</em>, <em>115</em>(49), 12441‚Äì12446.
</div>
<div id="ref-dejesus2019" class="csl-entry">
DeJesus, J. M., Callanan, M. A., Solis, G., &amp; Gelman, S. A. (2019). Generic language in scientific communication. <em>Proceedings of the National Academy of Sciences</em>, <em>116</em>(37), 18370‚Äì18377.
</div>
<div id="ref-hedge2018" class="csl-entry">
Hedge, C., Powell, G., &amp; Sumner, P. (2018). The reliability paradox: Why robust cognitive tasks do not produce reliable individual differences. <em>Behavior Research Methods</em>, <em>50</em>(3), 1166‚Äì1186.
</div>
<div id="ref-henrich2010" class="csl-entry">
Henrich, J., Heine, S. J., &amp; Norenzayan, A. (2010). The weirdest people in the world? <em>Behavioral and Brain Sciences</em>, <em>33</em>(2-3), 61‚Äì83.
</div>
<div id="ref-klein2018" class="csl-entry">
Klein, O., Hardwicke, T. E., Aust, F., Breuer, J., Danielsson, H., Mohr, A. H., IJzerman, H., Nilsonne, G., Vanpaemel, W., &amp; Frank, M. C. (2018). <em>A practical guide for transparency in psychological science</em>.
</div>
<div id="ref-majid2014" class="csl-entry">
Majid, A., &amp; Burenhult, N. (2014). Odors are expressible in language, as long as you speak the right language. <em>Cognition</em>, <em>130</em>(2), 266‚Äì270.
</div>
<div id="ref-majid2018" class="csl-entry">
Majid, A., &amp; Kruspe, N. (2018). Hunter-gatherer olfaction is special. <em>Current Biology</em>, <em>28</em>(3), 409‚Äì413.
</div>
<div id="ref-markus1991" class="csl-entry">
Markus, H. R., &amp; Kitayama, S. (1991). Culture and the self: Implications for cognition, emotion, and motivation. <em>Psychological Review</em>, <em>98</em>(2), 224.
</div>
<div id="ref-neyman1992" class="csl-entry">
Neyman, J. (1992). On the two different aspects of the representative method: The method of stratified sampling and the method of purposive selection. In <em>Breakthroughs in statistics</em> (pp. 123‚Äì150). Springer.
</div>
<div id="ref-nosek2021" class="csl-entry">
Nosek, Brian A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Almenberg, A. D., Fidler, F., Hilgard, J., Kline, M., Nuijten, M. B.others. (2021). Replicability, robustness, and reproducibility in psychological science. <em>Annual Review of Psychology</em>.
</div>
<div id="ref-piantadosi2014" class="csl-entry">
Piantadosi, S. T., &amp; Gibson, E. (2014). Quantitative standards for absolute linguistic universals. <em>Cognitive Science</em>, <em>38</em>(4), 736‚Äì756.
</div>
<div id="ref-rosenthal1984" class="csl-entry">
Rosenthal, R., &amp; Rosnow, R. L. (1984). <em>Essentials of behavioral research: Methods and data analysis</em>. McGraw-Hill.
</div>
<div id="ref-simonsohn2015" class="csl-entry">
Simonsohn, U. (2015). Small telescopes: Detectability and the evaluation of replication results. <em>Psychol. Sci.</em>, <em>26</em>(5), 559‚Äì569.
</div>
<div id="ref-syed2020" class="csl-entry">
Syed, M., &amp; Kathawalla, U. (2020). Cultural psychology, diversity, and representation in open science. <em>Cultural Methods in Psychology: Describing and Transforming Cultures</em>, 427‚Äì454.
</div>
<div id="ref-tessler2019" class="csl-entry">
Tessler, M. H., &amp; Goodman, N. D. (2019). The language of generalization. <em>Psychological Review</em>, <em>126</em>(3), 395.
</div>
<div id="ref-westfall2015" class="csl-entry">
Westfall, J., Judd, C. M., &amp; Kenny, D. A. (2015). Replicating studies in which samples of participants respond to samples of stimuli. <em>Perspectives on Psychological Science</em>, <em>10</em>(3), 390‚Äì399.
</div>
<div id="ref-yeager2019" class="csl-entry">
Yeager, D. S., Hanselman, P., Walton, G. M., Murray, J. S., Crosnoe, R., Muller, C., Tipton, E., Schneider, B., Hulleman, C. S., Hinojosa, C. P.others. (2019). A national experiment reveals where a growth mindset improves achievement. <em>Nature</em>, <em>573</em>(7774), 364‚Äì369.
</div>
</div>
<p style="text-align: center;">
<a href="9-design.html"><button class="btn btn-default">Previous</button></a>
<a href="11-prereg.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<link href="www/global.css" rel="stylesheet">
<script src="www/global.js"></script>


</body>
</html>
