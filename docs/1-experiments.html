<!DOCTYPE html>
<html>

<head>


<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 1 Experiments | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 1 Experiments | Experimentology">

<title>Chapter 1 Experiments | Experimentology</title>

<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.21/datatables.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>



<link rel="stylesheet" type="text/css" href="/assets/index.page.c5e7dffa.css"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/src/index.page.client.jsx.df9edbd0.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/contents.b9575bfb.js"></head>

<body>




<div class="row">
<div class="col-sm-12">
<header class="_toc_1lnsy_1" id="toc"><a class="_book_title_1lnsy_24" href="/">Experimentology: An Open Science Approach to Experimental Psychology Methods</a><nav><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Preliminaries</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="1-experiments">Experiments</a><a class="_chapter_title_1lnsy_32" href="2-theories">Theories</a><a class="_chapter_title_1lnsy_32" href="3-replication">Replication and reproducibility</a><a class="_chapter_title_1lnsy_32" href="4-ethics">Ethics</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Statistics</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="5-estimation">Estimation</a><a class="_chapter_title_1lnsy_32" href="6-inference">Inference</a><a class="_chapter_title_1lnsy_32" href="7-models">Models</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Design</div><div class="_part_title_rest_1lnsy_32"> and Planning</div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="8-measurement">Measurement</a><a class="_chapter_title_1lnsy_32" href="9-design">Design of experiments</a><a class="_chapter_title_1lnsy_32" href="10-sampling">Sampling</a><a class="_chapter_title_1lnsy_32" href="11-strategy">Experimental strategy</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Execution</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="12-prereg">Preregistration</a><a class="_chapter_title_1lnsy_32" href="13-consent">Recruitment and Consent</a><a class="_chapter_title_1lnsy_32" href="14-collection">Data collection</a><a class="_chapter_title_1lnsy_32" href="15-management">Project management</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Analysis</div><div class="_part_title_rest_1lnsy_32"> and Reporting</div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="16-viz">Visualization</a><a class="_chapter_title_1lnsy_32" href="17-eda">Exploratory data analysis</a><a class="_chapter_title_1lnsy_32" href="18-writing">Writing</a><a class="_chapter_title_1lnsy_32" href="19-meta">Meta-analysis</a><a class="_chapter_title_1lnsy_32" href="20-conclusions">Conclusions</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Appendices</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="A-git">GitHub Tutorial</a><a class="_chapter_title_1lnsy_32" href="B-rmarkdown">R Markdown Tutorial</a><a class="_chapter_title_1lnsy_32" href="C-tidyverse">Tidyverse Tutorial</a><a class="_chapter_title_1lnsy_32" href="D-ggplot">ggplot Tutorial</a><a class="_chapter_title_1lnsy_32" href="E-instructors">Instructor’s guide</a></div></div></nav></header>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="experiments" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Experiments</h1>
<div class="box learning_goals"><div class="Collapsible"><span id="collapsible-trigger-1654141393360" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1654141393360" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="apple-whole" class="svg-inline--fa fa-apple-whole " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M336 128c-32 0-80.02 16.03-112 32.03c-32.01-16-79.1-32.02-111.1-32.03C32 128 .4134 210.5 .0033 288c-.5313 99.97 63.99 224 159.1 224c32 0 48-16 64-16c16 0 32 16 64 16c96 0 160.4-122.8 159.1-224C447.7 211.6 416 128 336 128zM320 32V0h-32C243.8 0 208 35.82 208 80v32h32C284.2 112 320 76.18 320 32z"></path></svg>Learning goals<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M169.4 278.6C175.6 284.9 183.8 288 192 288s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25s-32.75-12.5-45.25 0L192 210.8L54.63 73.38c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25L169.4 278.6zM329.4 265.4L192 402.8L54.63 265.4c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25l160 160C175.6 476.9 183.8 480 192 480s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25S341.9 252.9 329.4 265.4z"></path></svg></span><div id="collapsible-content-1654141393360" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1654141393360"><div class="Collapsible__contentInner">
<ul>
<li>Define “experiment”</li>
<li>Reason about the relationship between the experimental method and causal inference</li>
<li>Articulate the critical role of randomization in causal inference</li>
<li>Consider constraints on generalizability for experimental estimates</li>
</ul>
</div></div></div></div>
<p>Welcome to Experimentology. This is a book about how to do psychology experiments! Much of what we cover in the book is about the nitty gritty of how to design your study, how to analyze your data, or even how to name your files! But before we can get into all that, we’re going to need to have a conversation about what an experiment is. And that in turn will lead us pretty quickly to talk about <strong>causality</strong>, since the unique contribution of experiments is to help us measure causal effects.</p>
<p>The guiding mantra of this book is that experiments are for estimating causal effects, and that good experiments do so in a maximally precise and unbiased way, leading to strong generalizations. Much of our advice about how to navigate decision-making with respect to measurement, design, and sampling comes directly from this mantra.</p>
<div id="what-is-an-experiment-and-why-would-you-do-one" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> What is an experiment, and why would you do one?</h2>


<p>When you do an experiment, you change the world in order to learn something new. This common-sense definition has two parts to it: the <strong>manipulation</strong> and the <strong>measure</strong>. The manipulation is the thing you are doing to the world, and the measure is the way you quantify the effects that your actions had. The manipulation licenses <strong>causal inference</strong>, which is our first topic. A second ingredient, <strong>randomization</strong>, licenses inferences about the locus of the causal effect.

</p>
<p>Let’s think through an example. If you’ve ever tried to write a paper or even a tricky email while listening to vocal music with lyrics, you might have had the feeling that the lyrics of the music interfered with your own writing. Let’s call this the “Dylan Hypothesis” – listening to music like Bob Dylan’s lyrically rich songs decreases writing skill in the moment while you’re listening to its.</p>
<p>The Dylan Hypothesis is a <strong>causal hypothesis</strong> – meaning that we ascribe responsibility for the decrease in writing skill to this factor particularly.<label for="tufte-sn-2" class="margin-toggle sidenote-number">2</label><input type="checkbox" id="tufte-sn-2" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">2</span> Defining causality is one of the trickiest and oldest problems in philosophy, and we won’t attempt to solve it here! But from a psychological perspective, we’re fond of <span class="citation">D. Lewis (<a href="#ref-lewis1973" role="doc-biblioref">1973</a>)</span>’s “counterfactual” analysis of causality. On this view, the Dylan Hypothesis amounts to the claim that, in some situation, if we <em>hadn’t</em> played Dylan, we <em>wouldn’t</em> have experienced a decrement in writing ability.</span> In what follows, we’ll try to be precise about the causal inferences we’re discussing.</p>
<p>
<span class="marginnote shownote">
<span style="display: block;" id="fig:intro-dylan1"></span>
<img src="images/intro/dylan1.png" alt="The hypothesized causal relationship of the Dylan Hypothesis." width="\linewidth" />
Figure 1.1: The hypothesized causal relationship of the Dylan Hypothesis.
</span>
</p>
<p>In Figure <a href="1-experiments.html#fig:intro-dylan1">1.1</a>, we show the Dylan Hypothesis using a kind of diagram called a <strong>causal graphical model</strong> <span class="citation">(<a href="#ref-pearl1998" role="doc-biblioref">Pearl, 1998</a>)</span>. Our outcome is writing skill (<span class="math inline">\(Y\)</span>) and our predictor is Dylan listening (<span class="math inline">\(X\)</span>). The edge between them represents a hypothesized causal relationship. Dylan listening is hypothesized have to a causal effect on writing skill, and not vice versa. Now let’s talk about how experiments allow us to make these causal inferences.</p>
</div>
<div id="causal-inference" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Causal inference</h2>
<p>Most science textbooks don’t start a definition of what an experiment is; psychology textbooks are an exception <span class="citation">(<a href="#ref-winston1996" role="doc-biblioref">Winston &amp; Blais, 1996</a>)</span>. Perhaps this is because experiments are a critical method for making strong causal inferences, which are otherwise in short supply in psychology, and so the contrast between experimental and non-experimental research is very salient for psychologists (and economists too). In contrast, the role of causality is much more straightforward in the physical sciences – so straightforward that they don’t talk about it at all.</p>
<p>Causal inference is a central issue in any field that deals with human beings. People are very complex systems. Even from an intuitive perspective, there are many obvious factors – personality, values, culture, physiology, genes – that influence any individual choice. Further, scientists typically have relatively limited opportunities to intervene on complex social systems. Although we can carry out some kinds of experiments within ethical and practical limits, we’re not just allowed to go around doing what we want to the people around us, just to see what happens! This situation stands in stark contrast to the physical sciences: you can do pretty much anything you want with a chemical solution.</p>
<p>Returning to the Dylan Hypothesis, suppose we did an observational study where we measured our variables – Dylan listening and writing quality – in a large population.<label for="tufte-sn-3" class="margin-toggle sidenote-number">3</label><input type="checkbox" id="tufte-sn-3" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">3</span> This sounds impractical, but let’s imagine some kind of dystopian, Google Docs+Spotify surveillance in which the companies team up to monitor your writing and listening habits and provide quantitative estimates of writing quality and lyric density. Big data!</span> We might compute a correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and find some non-zero relationship between them. If we did this study, you might predict that listening to Dylan would be related to better writing.</p>
<p>
<span class="marginnote shownote">
<span style="display: block;" id="fig:intro-dylan2"></span>
<img src="images/intro/dylan2.png" alt="Cofounding with age in the Dylan Hypothesis." width="\linewidth" />
Figure 1.2: Cofounding with age in the Dylan Hypothesis.
</span>
</p>
<p>Can we make a causal inference? No. Correlation doesn’t equal causation here. There is (at least one) confounding third variable: age (<span class="math inline">\(Z\)</span>). Age is positively related to both Dylan listening and writing skill in our population of interest. Older people tend to be good writers and also tend to be more into folk rockers.<label for="tufte-sn-4" class="margin-toggle sidenote-number">4</label><input type="checkbox" id="tufte-sn-4" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">4</span> We won’t even put a question mark on this edge because it seems likely to be true.</span></p>
<p>The causal relationship of age to our other two variables means that variation in <span class="math inline">\(Z\)</span> can induce a correlation in <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, even in the absence of a true causal link. When <span class="math inline">\(Z\)</span> is higher, so are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> on average, so they are correlated. This gives us a slightly more precise definition of <strong>confounding</strong>, a concept that everyone learns to use and recognize in discussing experimental design. In our observational experiment, age is <strong>confounded</strong> with Dylan listening because it has a causal relationship with both the predictor and the outcome.<label for="tufte-sn-5" class="margin-toggle sidenote-number">5</label><input type="checkbox" id="tufte-sn-5" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">5</span> There’s a more technical definition that’s more precise here: that is, age provides a “backdoor” from Dylan listening into writing skill. The “backdoor criterion” (it’s really called that!) is a way to define confounding in more complex causal graphs.</span></p>
<p>Experiments are when we intervene on the world and measure the consequences. Here, this means forcing some people to listen to Dylan. In the language of graphical models, if we control the Dylan listening, variable <span class="math inline">\(X\)</span> is causally exogenous – not caused by anything else in the system). We “snipped” the causal link between age and Dylan listening, shown by the scissors icon in Figure <a href="1-experiments.html#fig:intro-dylan3">1.3</a>.</p>
<p>
<span class="marginnote shownote">
<span style="display: block;" id="fig:intro-dylan3"></span>
<img src="images/intro/dylan3.png" alt="Experimental intervention snips the causal link between the confounded variable and the outcome." width="\linewidth" />
Figure 1.3: Experimental intervention snips the causal link between the confounded variable and the outcome.
</span>
</p>
<p>In sum, experiments allow us to make strong causal inferences because they allow us to wield the causal scissors, severing the links that would ordinarily allow “upstream” variables like age to confound our inferences.<label for="tufte-sn-6" class="margin-toggle sidenote-number">6</label><input type="checkbox" id="tufte-sn-6" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">6</span> There is a whole wonderful field of causal inference methods for non-experimental and pseudo-experimental designs. Much of this work happens in econometrics and not psychology, and the methods are extremely sophisticated. We recommend <span class="citation">Cunningham (<a href="#ref-cunningham2021" role="doc-biblioref">2021</a>)</span> as an open access introductory text.</span></p>
</div>
<div id="randomization" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Randomization</h2>
<p>When we talk about experiments in psychology, we are talking about experiments that are designed based on the logic of <strong>comparison</strong>. In the physical sciences, we can intervene on a system, comparing before and after the intervention. An example of a simple experiment would be to measure the temperature of some water, heat it, and then measure the temperature again. We feel relatively warranted in making the inference that the heat caused the temperature to rise.</p>
<p>This logic feels sound because we believe that our action heating the water is the only thing that’s different between our initial measurement (which we might call a <strong>control</strong> measurement<label for="tufte-sn-7" class="margin-toggle sidenote-number">7</label><input type="checkbox" id="tufte-sn-7" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">7</span> Interestingly, this term is not much more than a hundred years old; it starts appearing in the medical literature in the 1890s and the psychological literature soon after that <span class="citation">(<a href="#ref-boring1954" role="doc-biblioref">Boring, 1954</a>)</span>.</span>) and the measurement after our experimental intervention. It feels like we “held everything constant” between the two observations. This is <span class="citation">Mill (<a href="#ref-mill1869" role="doc-biblioref">1869</a>)</span>’s “method of differences”:</p>
<blockquote>
<p>If an instance in which the phenomenon under investigation occurs, and an instance in which it does not occur, have every circumstance in common save one, that one occurring only in the former; the circumstance in which alone the two instances differ, is the effect, or the cause, or an indispensable part of the cause, of the phenomenon.”</p>
</blockquote>
<p>In other words, comparison allows for causal inferences.</p>
<p>The trouble is that it’s not always as easy to “hold everything constant.” Let’s do two different analogously-designed Dylan Hypothesis experiments. The first will be a <strong>within-participants</strong> design. We ask someone to produce two writing samples for us to rate; the first is written in silence and the second while listening to <em>Blood on the Tracks</em>. Now we have a problem: our two measurements occur at different times. Being the second observation as opposed to the first might have a causal effect on writing skill – perhaps the participant practiced, perhaps they feel more comfortable in our experimental setup. Perhaps they feel more tired. In other words, we have introduced another confound – this time between parts of the experiment and Dylan listening.</p>
<p>
<span class="marginnote shownote">
<span style="display: block;" id="fig:intro-dylan4"></span>
<img src="images/intro/dylan4.png" alt="Confounding with order." width="\linewidth" />
Figure 1.4: Confounding with order.
</span>
</p>
<p>Here’s our second experimental design, a <strong>between-participants</strong> design.
We get some individuals to listen to Dylan or not – say we have our parents listen to Dylan and our friends do the experiment in silence – and then measure their writing during the assigned listening (or non-listening) period. Now we have a different issue. The participants in the control and experimental (Dylan) are different from one another. Even though we intervened in the world, we might as well be in the situation of Figure <a href="1-experiments.html#fig:intro-dylan2">1.2</a>, in the sense that we have differences between our participants that could make a causal difference (e.g., their age). Again, it doesn’t seem like everything got held constant.</p>
<p>Although structurally these two situations are quite different, they have a single theoretical solution: <strong>randomization</strong>. Randomization – whether of the order of an intervention in a sequence or the assignment of participants to conditions – is the key intervention that is guaranteed to break causal dependencies. In the case of the order confound, random assignment of condition order guarantees that our estimate of Dylan on writing skill is <strong>unbiased</strong><label for="tufte-sn-8" class="margin-toggle sidenote-number">8</label><input type="checkbox" id="tufte-sn-8" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">8</span> Unbiased with respect to order, of course! It could be biased by many other things.</span> on average.<label for="tufte-sn-9" class="margin-toggle sidenote-number">9</label><input type="checkbox" id="tufte-sn-9" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">9</span> It could be biased in any one situation. Because order has two known states, we can also <strong>balance</strong> order rather than randomizing it. We’ll talk in some depth in Chapter <a href="9-design.html#design">9</a> about how to deal with these sorts of nuisance procedural confounds and when randomization vs. counterbalancing strategies are most appropriate.</span> In the case of the participant confound, <strong>random assignment</strong> of participants to conditions is the key step that breaks the connection between the myriad confounds related to individual participants’ identities and the manipulation of interest.</p>
<p>Random assignment is so central to the recipe of experimental psychology that sometimes we don’t even think about it as an ingredient! But without it, the cake simply doesn’t rise. One classic example of a violation of random assignment is the sequential recruitment of participants to conditions (e.g., first testing the non-Dylan group and then the Dylan group). This kind of practice can seem unproblematic to a research assistant carrying out a study (we’ve done it!). But it confounds time with group participation and can lead to all sorts of unforeseen issues in causal inference. Imagine that Dylan wins the Nobel prize somewhere during the recruitment process. This event obviously could change the nature of your manipulation. But so could infinite other events – from a global pandemic all the way to the normal course of the seasons changing. Random assignment is the only way to avoid these confounds.</p>
<p>Random assignment is great, but there is a caveat. Random assignment cannot rescue your <em>individual</em> sample from biases. For example, in your randomly-assigned conditions, maybe a few more Dylan condition participants happened to be run after his Nobel than before. Instead, random assignment guarantees that <em>on average</em> your estimate of the causal effect will be unbiased – even if you get lucky or unlucky on this individual instance of your experiment.<label for="tufte-sn-10" class="margin-toggle sidenote-number">10</label><input type="checkbox" id="tufte-sn-10" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">10</span> We’ll return to the topic of whether you should test for or adjust for “unhappy randomization” in Chapter <a href="7-models.html#models">7</a>. A brief answer here, to pique your curiosity: no.</span> That’s pretty good, and maybe it’s the best you can hope for!</p>
</div>
<div id="who-are-we-measuring" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Who are we measuring?</h2>
<p>In our running example of the Dylan hypothesis, we have been quite vague about the scope and limitations of generalization. Is this a causal estimate that should apply to all people? Of US college students? Of Boomers that grew up listening to Dylan? Estimating an effect via a <strong>sample</strong> – the set of people who participate in the experiment – presupposes a <strong>population</strong> that the sample is drawn from. Psychology researchers often give little thought to this issue, but generalizability across populations is a key challenge for psychology.</p>

<p>To point out the ubiquity of population generalizability issues, <span class="citation">Henrich et al. (<a href="#ref-henrich2010" role="doc-biblioref">2010</a>)</span> coined the acronym <strong>WEIRD</strong>. This catchy name describes the oddness of making generalizations about all of humanity from experiments on a sample that is quite unusual because it is Western, Educated, Industrialized, Rich, and Democratic. Henrich and colleagues argue that seemingly “fundamental” psychological like visual perception, spatial cognition, and social reasoning all differ pervasively across populations – hence, <em>any</em> generalization from an effect estimated with a WEIRD subpopulation is unwarranted.<label for="tufte-sn-11" class="margin-toggle sidenote-number">11</label><input type="checkbox" id="tufte-sn-11" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">11</span> We’ll discuss the problem of sample generalizability – and some ways to reason about the WEIRD problem – in more depth in Chapter <a href="10-sampling.html#sampling">10</a>.</span></p>
<p>A second generalizability challenge is that experimental manipulations are typically realized across specific stimuli. In our Dylan example, this would be using “Like a Rolling Stone” as our only experimental stimulus but then making the claim that our effect generalizes to all Dylan – or even all lyrically-dense music! Yet we too rarely reason about how general our hypothesis across the broader space of stimuli. As we’ll see in Chapters <a href="7-models.html#models">7</a> and <a href="9-design.html#design">9</a>, this issue has consequences for our statistical analysis as well as for our experimental designs <span class="citation">(<a href="#ref-yarkoni2020" role="doc-biblioref">Yarkoni, 2020</a>)</span>.</p>
<p>Questions of generalizability are pervasive, but the first step is simply to acknowledge and reason about them. One mechanism for enforcing thinking about theory scope is the idea that all papers should have a section reporting their limitations. We tend to think this is a good idea. <span class="citation">Simons et al. (<a href="#ref-simons2017" role="doc-biblioref">2017</a>)</span> calls this a Constraints on Generality statement.<label for="tufte-sn-12" class="margin-toggle sidenote-number">12</label><input type="checkbox" id="tufte-sn-12" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">12</span> In an early working draft, the COG statement was called a Statement of Limits on Generality (SLOG), which we found more memorable.</span> They recommend explicit qualification of generalizability across 1) experimental participants, 2) experimental stimuli, 3) procedures, and 4) historical or temporal features.</p>
<div class="box ethical_considerations"><div class="Collapsible"><span id="collapsible-trigger-1654141393362" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1654141393362" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="leaf" class="svg-inline--fa fa-leaf " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M512 165.4c0 127.9-70.05 235.3-175.3 270.1c-20.04 7.938-41.83 12.46-64.69 12.46c-64.9 0-125.2-36.51-155.7-94.47c-54.13 49.93-68.71 107-68.96 108.1C44.72 472.6 34.87 480 24.02 480c-1.844 0-3.727-.2187-5.602-.6562c-12.89-3.098-20.84-16.08-17.75-28.96c9.598-39.5 90.47-226.4 335.3-226.4C344.8 224 352 216.8 352 208S344.8 192 336 192C228.6 192 151 226.6 96.29 267.6c.1934-10.82 1.242-21.84 3.535-33.05c13.47-65.81 66.04-119 131.4-134.2c28.33-6.562 55.68-6.013 80.93-.0054c56 13.32 118.2-7.412 149.3-61.24c5.664-9.828 20.02-9.516 24.66 .8282C502.7 76.76 512 121.9 512 165.4z"></path></svg>Ethical considerations<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M169.4 278.6C175.6 284.9 183.8 288 192 288s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25s-32.75-12.5-45.25 0L192 210.8L54.63 73.38c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25L169.4 278.6zM329.4 265.4L192 402.8L54.63 265.4c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25l160 160C175.6 476.9 183.8 480 192 480s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25S341.9 252.9 329.4 265.4z"></path></svg></span><div id="collapsible-content-1654141393362" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1654141393362"><div class="Collapsible__contentInner"><p class="title">Consequences of poor generalizability</p>
<p></p>
<p>Generalizability questions can seem abstract, but it can have substantial practical consequences when experimental research is applied. To take an example from medical research, it has been common practice for decades to study drug effects in mouse models. What is less well-appreciated is that the typical mouse model has been the <em>male</em> mouse only, with a six-fold difference in use of male relative to female mice. This seemingly practical decision may have widespread consequences <span class="citation">(<a href="#ref-shansky2021" role="doc-biblioref">Shansky &amp; Murphy, 2021</a>)</span>. Women experience a greater proportion of adverse consequences from pharmaceutical treatments than men, likely because research on development and evaluation of such treatments is conducted on male animals.</p>
<p>When it comes to research with humans, the analogy is clear. We hope that our findings are implemented in practice through the creation of psychologically-based policies, treatments, or educational interventions. But if effects are measured using a population that mismatches the population to which the interventions are applied, then we should expect lowered efficacy and perhaps even unanticipated negative effects. To combat this issue, researchers have an ethical obligation to give careful consideration to the limitations of their samples and to the scope of applicability of their claims.</p>
</div></div></div></div>
</div>
<div id="experiments-chapter-summary" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Experiments: Chapter summary</h2>
<p>In this chapter, we defined an experiment as a combination of a manipulation and a measure. This combination, along with randomization, licenses strong causal inferences about the structure of the world. Experiments are a terrible way to learn about the world. They are costly and time-consuming, and sometimes they fail in uninterpretable ways. Yet they are our best method for estimating causal effects; many other techniques exist but they rely on more complex statistical methods that require certain conditions to be feasible.<label for="tufte-sn-13" class="margin-toggle sidenote-number">13</label><input type="checkbox" id="tufte-sn-13" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">13</span> For example, the presence of an external “instrument” – like the weather or the introduction of internet services or changes in state-level policies – that is causally related to your cause of interest but unconnected to your outcome.</span></p>
<p>Sometimes we just need to know about the existence or magnitude effects for some applied goal, say deciding whether implementing a particular curriculum will lead to changes in mathematics test scores. In this case, a randomized trial of the intervention is all that we need, and the causal effect is the end-point of the study. But often in psychology we want to do more. The “extra” thing we would like to do is to build theories. We’ll turn to this topic in Chapter <a href="2-theories.html#theories">2</a>.</p>
<div class="box exercises"><div class="Collapsible"><span id="collapsible-trigger-1654141393363" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1654141393363" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="pen-ruler" class="svg-inline--fa fa-pen-ruler " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M492.7 42.75C517.7 67.74 517.7 108.3 492.7 133.3L436.3 189.7L322.3 75.72L378.7 19.32C403.7-5.678 444.3-5.678 469.3 19.32L492.7 42.75zM44.89 353.2L299.7 98.34L413.7 212.3L158.8 467.1C152.1 473.8 143.8 478.7 134.6 481.4L30.59 511.1C22.21 513.5 13.19 511.1 7.03 504.1C.8669 498.8-1.47 489.8 .9242 481.4L30.65 377.4C33.26 368.2 38.16 359.9 44.89 353.2zM249.4 103.4L103.4 249.4L16 161.9C-2.745 143.2-2.745 112.8 16 94.06L94.06 16C112.8-2.745 143.2-2.745 161.9 16L181.7 35.76C181.4 36.05 181 36.36 180.7 36.69L116.7 100.7C110.4 106.9 110.4 117.1 116.7 123.3C122.9 129.6 133.1 129.6 139.3 123.3L203.3 59.31C203.6 58.99 203.1 58.65 204.2 58.3L249.4 103.4zM453.7 307.8C453.4 308 453 308.4 452.7 308.7L388.7 372.7C382.4 378.9 382.4 389.1 388.7 395.3C394.9 401.6 405.1 401.6 411.3 395.3L475.3 331.3C475.6 330.1 475.1 330.6 476.2 330.3L496 350.1C514.7 368.8 514.7 399.2 496 417.9L417.9 496C399.2 514.7 368.8 514.7 350.1 496L262.6 408.6L408.6 262.6L453.7 307.8z"></path></svg>Exercises<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M169.4 278.6C175.6 284.9 183.8 288 192 288s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25s-32.75-12.5-45.25 0L192 210.8L54.63 73.38c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25L169.4 278.6zM329.4 265.4L192 402.8L54.63 265.4c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25l160 160C175.6 476.9 183.8 480 192 480s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25S341.9 252.9 329.4 265.4z"></path></svg></span><div id="collapsible-content-1654141393363" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1654141393363"><div class="Collapsible__contentInner">
<p>Design an experiment for testing the Dylan Hypothesis. (A) What is the condition structure, what is the measure? How do you control for nuisance variables? (B) What are the best arguments against your proposed experimental design? What would an advocate of the Dylan Hypothesis say if it failed to yield a non-zero effect?</p>
</div></div></div></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-boring1954" class="csl-entry">
Boring, E. G. (1954). The nature and history of experimental control. <em>The American Journal of Psychology</em>, <em>67</em>(4), 573–589. <a href="http://www.jstor.org/stable/1418483">http://www.jstor.org/stable/1418483</a>
</div>
<div id="ref-cunningham2021" class="csl-entry">
Cunningham, S. (2021). <em>Causal inference</em>. Yale University Press.
</div>
<div id="ref-henrich2010" class="csl-entry">
Henrich, J., Heine, S. J., &amp; Norenzayan, A. (2010). The weirdest people in the world? <em>Behavioral and Brain Sciences</em>, <em>33</em>(2-3), 61–83.
</div>
<div id="ref-lewis1973" class="csl-entry">
Lewis, D. (1973). <em>Counterfactuals</em>. John Wiley &amp; Sons.
</div>
<div id="ref-mill1869" class="csl-entry">
Mill, J. S. (1869). <em>A system of logic, ratiocinative and inductive: Being a connected view of the princilples of evidence and the methods of scientific investigation</em>. Harper; brothers.
</div>
<div id="ref-pearl1998" class="csl-entry">
Pearl, J. (1998). Graphical models for probabilistic and causal reasoning. <em>Quantified Representation of Uncertainty and Imprecision</em>, 367–389.
</div>
<div id="ref-shansky2021" class="csl-entry">
Shansky, R. M., &amp; Murphy, A. Z. (2021). Considering sex as a biological variable will require a global shift in science culture. <em>Nature Neuroscience</em>, <em>24</em>(4), 457–464.
</div>
<div id="ref-simons2017" class="csl-entry">
Simons, D. J., Shoda, Y., &amp; Lindsay, D. S. (2017). Constraints on generality (COG): A proposed addition to all empirical papers. <em>Perspectives on Psychological Science</em>, <em>12</em>(6), 1123–1128.
</div>
<div id="ref-winston1996" class="csl-entry">
Winston, A. S., &amp; Blais, D. J. (1996). What counts as an experiment?: A transdisciplinary analysis of textbooks, 1930-1970. <em>The American Journal of Psychology</em>, <em>109</em>(4), 599–616. <a href="http://www.jstor.org/stable/1423397">http://www.jstor.org/stable/1423397</a>
</div>
<div id="ref-yarkoni2020" class="csl-entry">
Yarkoni, T. (2020). The generalizability crisis. <em>Behav. Brain Sci.</em>, 1–37.
</div>
</div>

</div>
</div>




<script type="module" src="/assets/src/index.page.client.jsx.df9edbd0.js"></script><script id="vite-plugin-ssr_pageContext" type="application/json">{"pageContext":{"_pageId":"/src/index","url":"/1-experiments","body":"\n\n\n\n\u003cdiv class=\"row\">\n\u003cdiv class=\"col-sm-12\">\n\u003cdiv id=\"TOC\">\n\u003cul>\n\u003cli>\u003ca href=\"#part-preliminaries\" id=\"toc-part-preliminaries\">(PART) Preliminaries\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"1-experiments.html#experiments\" id=\"toc-experiments\">\u003cspan class=\"toc-section-number\">1\u003c/span> Experiments\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"2-theories.html#theories\" id=\"toc-theories\">\u003cspan class=\"toc-section-number\">2\u003c/span> Theories\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"3-replication.html#replication\" id=\"toc-replication\">\u003cspan class=\"toc-section-number\">3\u003c/span> Replication and reproducibility\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"4-ethics.html#ethics\" id=\"toc-ethics\">\u003cspan class=\"toc-section-number\">4\u003c/span> Ethics\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-statistics\" id=\"toc-part-statistics\">(PART) Statistics\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"5-estimation.html#estimation\" id=\"toc-estimation\">\u003cspan class=\"toc-section-number\">5\u003c/span> Estimation\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"6-inference.html#inference\" id=\"toc-inference\">\u003cspan class=\"toc-section-number\">6\u003c/span> Inference\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"7-models.html#models\" id=\"toc-models\">\u003cspan class=\"toc-section-number\">7\u003c/span> Models\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-design-and-planning\" id=\"toc-part-design-and-planning\">(PART) Design and Planning\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"8-measurement.html#measurement\" id=\"toc-measurement\">\u003cspan class=\"toc-section-number\">8\u003c/span> Measurement\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"9-design.html#design\" id=\"toc-design\">\u003cspan class=\"toc-section-number\">9\u003c/span> Design of experiments\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"10-sampling.html#sampling\" id=\"toc-sampling\">\u003cspan class=\"toc-section-number\">10\u003c/span> Sampling\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"11-strategy.html#strategy\" id=\"toc-strategy\">\u003cspan class=\"toc-section-number\">11\u003c/span> Experimental strategy\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-execution\" id=\"toc-part-execution\">(PART) Execution\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"12-prereg.html#prereg\" id=\"toc-prereg\">\u003cspan class=\"toc-section-number\">12\u003c/span> Preregistration\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"13-consent.html#consent\" id=\"toc-consent\">\u003cspan class=\"toc-section-number\">13\u003c/span> Recruitment and Consent\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"14-collection.html#collection\" id=\"toc-collection\">\u003cspan class=\"toc-section-number\">14\u003c/span> Data collection\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"15-management.html#management\" id=\"toc-management\">\u003cspan class=\"toc-section-number\">15\u003c/span> Project management\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-analysis-and-reporting\" id=\"toc-part-analysis-and-reporting\">(PART) Analysis and Reporting\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"16-viz.html#viz\" id=\"toc-viz\">\u003cspan class=\"toc-section-number\">16\u003c/span> Visualization\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"17-eda.html#eda\" id=\"toc-eda\">\u003cspan class=\"toc-section-number\">17\u003c/span> Exploratory data analysis\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"18-writing.html#writing\" id=\"toc-writing\">\u003cspan class=\"toc-section-number\">18\u003c/span> Writing\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"19-meta.html#meta\" id=\"toc-meta\">\u003cspan class=\"toc-section-number\">19\u003c/span> Meta-analysis\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"20-conclusions.html#conclusions\" id=\"toc-conclusions\">\u003cspan class=\"toc-section-number\">20\u003c/span> Conclusions\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#appendix-appendices\" id=\"toc-appendix-appendices\">(APPENDIX) Appendices\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"A-git.html#git\" id=\"toc-git\">\u003cspan class=\"toc-section-number\">21\u003c/span> GitHub Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"B-rmarkdown.html#rmarkdown\" id=\"toc-rmarkdown\">\u003cspan class=\"toc-section-number\">22\u003c/span> R Markdown Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"C-tidyverse.html#tidyverse\" id=\"toc-tidyverse\">\u003cspan class=\"toc-section-number\">23\u003c/span> Tidyverse Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"D-ggplot.html#ggplot\" id=\"toc-ggplot\">\u003cspan class=\"toc-section-number\">24\u003c/span> ggplot Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"E-instructors.html#instructors\" id=\"toc-instructors\">\u003cspan class=\"toc-section-number\">25\u003c/span> Instructor’s guide\u003c/a>\u003c/li>\n\u003c/ul>\n\u003c/div>\n\u003c/div>\n\u003c/div>\n\u003cdiv class=\"row\">\n\u003cdiv class=\"col-sm-12\">\n\u003cdiv id=\"experiments\" class=\"section level1\" number=\"1\">\n\u003ch1>\u003cspan class=\"header-section-number\">Chapter 1\u003c/span> Experiments\u003c/h1>\n\u003cdiv class=\"box learning_goals\">\n\u003cul>\n\u003cli>Define “experiment”\u003c/li>\n\u003cli>Reason about the relationship between the experimental method and causal inference\u003c/li>\n\u003cli>Articulate the critical role of randomization in causal inference\u003c/li>\n\u003cli>Consider constraints on generalizability for experimental estimates\u003c/li>\n\u003c/ul>\n\u003c/div>\n\u003cp>Welcome to Experimentology. This is a book about how to do psychology experiments! Much of what we cover in the book is about the nitty gritty of how to design your study, how to analyze your data, or even how to name your files! But before we can get into all that, we’re going to need to have a conversation about what an experiment is. And that in turn will lead us pretty quickly to talk about \u003cstrong>causality\u003c/strong>, since the unique contribution of experiments is to help us measure causal effects.\u003c/p>\n\u003cp>The guiding mantra of this book is that experiments are for estimating causal effects, and that good experiments do so in a maximally precise and unbiased way, leading to strong generalizations. Much of our advice about how to navigate decision-making with respect to measurement, design, and sampling comes directly from this mantra.\u003c/p>\n\u003cdiv id=\"what-is-an-experiment-and-why-would-you-do-one\" class=\"section level2\" number=\"1.1\">\n\u003ch2>\u003cspan class=\"header-section-number\">1.1\u003c/span> What is an experiment, and why would you do one?\u003c/h2>\n\u003c!-- - On one hand, experiments are “the worst way to learn about the world” (in the words of one of our mentors). “You can't play 20 questions with nature and win” (Newell 1973). But experiments are also one of our best tools for making strong causal inferences about the hidden structure of the world. They allow us to not just observe the world but to systematically intervene on it. -->\n\u003c!-- - We used to just poke things or people and measure what happened (see Hacking, 1990 on the 19th century craze of just measuring everything for fun.) Now we typically want our experiments to resolve deeper questions or test hypotheses. -->\n\u003cp>When you do an experiment, you change the world in order to learn something new. This common-sense definition has two parts to it: the \u003cstrong>manipulation\u003c/strong> and the \u003cstrong>measure\u003c/strong>. The manipulation is the thing you are doing to the world, and the measure is the way you quantify the effects that your actions had. The manipulation licenses \u003cstrong>causal inference\u003c/strong>, which is our first topic. A second ingredient, \u003cstrong>randomization\u003c/strong>, licenses inferences about the locus of the causal effect.\n\u003c!-- The result is some **generalization** that can be made about unseen observations.  -->\n\u003c!-- We'll talk about each of these in turn. -->\u003c/p>\n\u003cp>Let’s think through an example. If you’ve ever tried to write a paper or even a tricky email while listening to vocal music with lyrics, you might have had the feeling that the lyrics of the music interfered with your own writing. Let’s call this the “Dylan Hypothesis” – listening to music like Bob Dylan’s lyrically rich songs decreases writing skill in the moment while you’re listening to its.\u003c/p>\n\u003cp>The Dylan Hypothesis is a \u003cstrong>causal hypothesis\u003c/strong> – meaning that we ascribe responsibility for the decrease in writing skill to this factor particularly.\u003clabel for=\"tufte-sn-2\" class=\"margin-toggle sidenote-number\">2\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-2\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">2\u003c/span> Defining causality is one of the trickiest and oldest problems in philosophy, and we won’t attempt to solve it here! But from a psychological perspective, we’re fond of \u003cspan class=\"citation\">D. Lewis (\u003ca href=\"#ref-lewis1973\" role=\"doc-biblioref\">1973\u003c/a>)\u003c/span>’s “counterfactual” analysis of causality. On this view, the Dylan Hypothesis amounts to the claim that, in some situation, if we \u003cem>hadn’t\u003c/em> played Dylan, we \u003cem>wouldn’t\u003c/em> have experienced a decrement in writing ability.\u003c/span> In what follows, we’ll try to be precise about the causal inferences we’re discussing.\u003c/p>\n\u003cp>\n\u003cspan class=\"marginnote shownote\">\n\u003c!--\n\u003cdiv class=\"figure\">-->\u003cspan style=\"display:block;\" id=\"fig:intro-dylan1\">\u003c/span>\n\u003cimg src=\"images/intro/dylan1.png\" alt=\"The hypothesized causal relationship of the Dylan Hypothesis.\" width=\"\\linewidth\"  />\n\u003c!--\n\u003cp class=\"caption marginnote\">-->Figure 1.1: The hypothesized causal relationship of the Dylan Hypothesis.\u003c!--\u003c/p>-->\n\u003c!--\u003c/div>-->\u003c/span>\n\u003c/p>\n\u003cp>In Figure \u003ca href=\"1-experiments.html#fig:intro-dylan1\">1.1\u003c/a>, we show the Dylan Hypothesis using a kind of diagram called a \u003cstrong>causal graphical model\u003c/strong> \u003cspan class=\"citation\">(\u003ca href=\"#ref-pearl1998\" role=\"doc-biblioref\">Pearl, 1998\u003c/a>)\u003c/span>. Our outcome is writing skill (\u003cspan class=\"math inline\">\\(Y\\)\u003c/span>) and our predictor is Dylan listening (\u003cspan class=\"math inline\">\\(X\\)\u003c/span>). The edge between them represents a hypothesized causal relationship. Dylan listening is hypothesized have to a causal effect on writing skill, and not vice versa. Now let’s talk about how experiments allow us to make these causal inferences.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"causal-inference\" class=\"section level2\" number=\"1.2\">\n\u003ch2>\u003cspan class=\"header-section-number\">1.2\u003c/span> Causal inference\u003c/h2>\n\u003cp>Most science textbooks don’t start a definition of what an experiment is; psychology textbooks are an exception \u003cspan class=\"citation\">(\u003ca href=\"#ref-winston1996\" role=\"doc-biblioref\">Winston &amp; Blais, 1996\u003c/a>)\u003c/span>. Perhaps this is because experiments are a critical method for making strong causal inferences, which are otherwise in short supply in psychology, and so the contrast between experimental and non-experimental research is very salient for psychologists (and economists too). In contrast, the role of causality is much more straightforward in the physical sciences – so straightforward that they don’t talk about it at all.\u003c/p>\n\u003cp>Causal inference is a central issue in any field that deals with human beings. People are very complex systems. Even from an intuitive perspective, there are many obvious factors – personality, values, culture, physiology, genes – that influence any individual choice. Further, scientists typically have relatively limited opportunities to intervene on complex social systems. Although we can carry out some kinds of experiments within ethical and practical limits, we’re not just allowed to go around doing what we want to the people around us, just to see what happens! This situation stands in stark contrast to the physical sciences: you can do pretty much anything you want with a chemical solution.\u003c/p>\n\u003cp>Returning to the Dylan Hypothesis, suppose we did an observational study where we measured our variables – Dylan listening and writing quality – in a large population.\u003clabel for=\"tufte-sn-3\" class=\"margin-toggle sidenote-number\">3\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-3\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">3\u003c/span> This sounds impractical, but let’s imagine some kind of dystopian, Google Docs+Spotify surveillance in which the companies team up to monitor your writing and listening habits and provide quantitative estimates of writing quality and lyric density. Big data!\u003c/span> We might compute a correlation between \u003cspan class=\"math inline\">\\(X\\)\u003c/span> and \u003cspan class=\"math inline\">\\(Y\\)\u003c/span> and find some non-zero relationship between them. If we did this study, you might predict that listening to Dylan would be related to better writing.\u003c/p>\n\u003cp>\n\u003cspan class=\"marginnote shownote\">\n\u003c!--\n\u003cdiv class=\"figure\">-->\u003cspan style=\"display:block;\" id=\"fig:intro-dylan2\">\u003c/span>\n\u003cimg src=\"images/intro/dylan2.png\" alt=\"Cofounding with age in the Dylan Hypothesis.\" width=\"\\linewidth\"  />\n\u003c!--\n\u003cp class=\"caption marginnote\">-->Figure 1.2: Cofounding with age in the Dylan Hypothesis.\u003c!--\u003c/p>-->\n\u003c!--\u003c/div>-->\u003c/span>\n\u003c/p>\n\u003cp>Can we make a causal inference? No. Correlation doesn’t equal causation here. There is (at least one) confounding third variable: age (\u003cspan class=\"math inline\">\\(Z\\)\u003c/span>). Age is positively related to both Dylan listening and writing skill in our population of interest. Older people tend to be good writers and also tend to be more into folk rockers.\u003clabel for=\"tufte-sn-4\" class=\"margin-toggle sidenote-number\">4\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-4\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">4\u003c/span> We won’t even put a question mark on this edge because it seems likely to be true.\u003c/span>\u003c/p>\n\u003cp>The causal relationship of age to our other two variables means that variation in \u003cspan class=\"math inline\">\\(Z\\)\u003c/span> can induce a correlation in \u003cspan class=\"math inline\">\\(X\\)\u003c/span> and \u003cspan class=\"math inline\">\\(Y\\)\u003c/span>, even in the absence of a true causal link. When \u003cspan class=\"math inline\">\\(Z\\)\u003c/span> is higher, so are \u003cspan class=\"math inline\">\\(X\\)\u003c/span> and \u003cspan class=\"math inline\">\\(Y\\)\u003c/span> on average, so they are correlated. This gives us a slightly more precise definition of \u003cstrong>confounding\u003c/strong>, a concept that everyone learns to use and recognize in discussing experimental design. In our observational experiment, age is \u003cstrong>confounded\u003c/strong> with Dylan listening because it has a causal relationship with both the predictor and the outcome.\u003clabel for=\"tufte-sn-5\" class=\"margin-toggle sidenote-number\">5\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-5\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">5\u003c/span> There’s a more technical definition that’s more precise here: that is, age provides a “backdoor” from Dylan listening into writing skill. The “backdoor criterion” (it’s really called that!) is a way to define confounding in more complex causal graphs.\u003c/span>\u003c/p>\n\u003cp>Experiments are when we intervene on the world and measure the consequences. Here, this means forcing some people to listen to Dylan. In the language of graphical models, if we control the Dylan listening, variable \u003cspan class=\"math inline\">\\(X\\)\u003c/span> is causally exogenous – not caused by anything else in the system). We “snipped” the causal link between age and Dylan listening, shown by the scissors icon in Figure \u003ca href=\"1-experiments.html#fig:intro-dylan3\">1.3\u003c/a>.\u003c/p>\n\u003cp>\n\u003cspan class=\"marginnote shownote\">\n\u003c!--\n\u003cdiv class=\"figure\">-->\u003cspan style=\"display:block;\" id=\"fig:intro-dylan3\">\u003c/span>\n\u003cimg src=\"images/intro/dylan3.png\" alt=\"Experimental intervention snips the causal link between the confounded variable and the outcome.\" width=\"\\linewidth\"  />\n\u003c!--\n\u003cp class=\"caption marginnote\">-->Figure 1.3: Experimental intervention snips the causal link between the confounded variable and the outcome.\u003c!--\u003c/p>-->\n\u003c!--\u003c/div>-->\u003c/span>\n\u003c/p>\n\u003cp>In sum, experiments allow us to make strong causal inferences because they allow us to wield the causal scissors, severing the links that would ordinarily allow “upstream” variables like age to confound our inferences.\u003clabel for=\"tufte-sn-6\" class=\"margin-toggle sidenote-number\">6\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-6\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">6\u003c/span> There is a whole wonderful field of causal inference methods for non-experimental and pseudo-experimental designs. Much of this work happens in econometrics and not psychology, and the methods are extremely sophisticated. We recommend \u003cspan class=\"citation\">Cunningham (\u003ca href=\"#ref-cunningham2021\" role=\"doc-biblioref\">2021\u003c/a>)\u003c/span> as an open access introductory text.\u003c/span>\u003c/p>\n\u003c/div>\n\u003cdiv id=\"randomization\" class=\"section level2\" number=\"1.3\">\n\u003ch2>\u003cspan class=\"header-section-number\">1.3\u003c/span> Randomization\u003c/h2>\n\u003cp>When we talk about experiments in psychology, we are talking about experiments that are designed based on the logic of \u003cstrong>comparison\u003c/strong>. In the physical sciences, we can intervene on a system, comparing before and after the intervention. An example of a simple experiment would be to measure the temperature of some water, heat it, and then measure the temperature again. We feel relatively warranted in making the inference that the heat caused the temperature to rise.\u003c/p>\n\u003cp>This logic feels sound because we believe that our action heating the water is the only thing that’s different between our initial measurement (which we might call a \u003cstrong>control\u003c/strong> measurement\u003clabel for=\"tufte-sn-7\" class=\"margin-toggle sidenote-number\">7\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-7\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">7\u003c/span> Interestingly, this term is not much more than a hundred years old; it starts appearing in the medical literature in the 1890s and the psychological literature soon after that \u003cspan class=\"citation\">(\u003ca href=\"#ref-boring1954\" role=\"doc-biblioref\">Boring, 1954\u003c/a>)\u003c/span>.\u003c/span>) and the measurement after our experimental intervention. It feels like we “held everything constant” between the two observations. This is \u003cspan class=\"citation\">Mill (\u003ca href=\"#ref-mill1869\" role=\"doc-biblioref\">1869\u003c/a>)\u003c/span>’s “method of differences”:\u003c/p>\n\u003cblockquote>\n\u003cp>If an instance in which the phenomenon under investigation occurs, and an instance in which it does not occur, have every circumstance in common save one, that one occurring only in the former; the circumstance in which alone the two instances differ, is the effect, or the cause, or an indispensable part of the cause, of the phenomenon.”\u003c/p>\n\u003c/blockquote>\n\u003cp>In other words, comparison allows for causal inferences.\u003c/p>\n\u003cp>The trouble is that it’s not always as easy to “hold everything constant.” Let’s do two different analogously-designed Dylan Hypothesis experiments. The first will be a \u003cstrong>within-participants\u003c/strong> design. We ask someone to produce two writing samples for us to rate; the first is written in silence and the second while listening to \u003cem>Blood on the Tracks\u003c/em>. Now we have a problem: our two measurements occur at different times. Being the second observation as opposed to the first might have a causal effect on writing skill – perhaps the participant practiced, perhaps they feel more comfortable in our experimental setup. Perhaps they feel more tired. In other words, we have introduced another confound – this time between parts of the experiment and Dylan listening.\u003c/p>\n\u003cp>\n\u003cspan class=\"marginnote shownote\">\n\u003c!--\n\u003cdiv class=\"figure\">-->\u003cspan style=\"display:block;\" id=\"fig:intro-dylan4\">\u003c/span>\n\u003cimg src=\"images/intro/dylan4.png\" alt=\"Confounding with order.\" width=\"\\linewidth\"  />\n\u003c!--\n\u003cp class=\"caption marginnote\">-->Figure 1.4: Confounding with order.\u003c!--\u003c/p>-->\n\u003c!--\u003c/div>-->\u003c/span>\n\u003c/p>\n\u003cp>Here’s our second experimental design, a \u003cstrong>between-participants\u003c/strong> design.\nWe get some individuals to listen to Dylan or not – say we have our parents listen to Dylan and our friends do the experiment in silence – and then measure their writing during the assigned listening (or non-listening) period. Now we have a different issue. The participants in the control and experimental (Dylan) are different from one another. Even though we intervened in the world, we might as well be in the situation of Figure \u003ca href=\"1-experiments.html#fig:intro-dylan2\">1.2\u003c/a>, in the sense that we have differences between our participants that could make a causal difference (e.g., their age). Again, it doesn’t seem like everything got held constant.\u003c/p>\n\u003cp>Although structurally these two situations are quite different, they have a single theoretical solution: \u003cstrong>randomization\u003c/strong>. Randomization – whether of the order of an intervention in a sequence or the assignment of participants to conditions – is the key intervention that is guaranteed to break causal dependencies. In the case of the order confound, random assignment of condition order guarantees that our estimate of Dylan on writing skill is \u003cstrong>unbiased\u003c/strong>\u003clabel for=\"tufte-sn-8\" class=\"margin-toggle sidenote-number\">8\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-8\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">8\u003c/span> Unbiased with respect to order, of course! It could be biased by many other things.\u003c/span> on average.\u003clabel for=\"tufte-sn-9\" class=\"margin-toggle sidenote-number\">9\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-9\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">9\u003c/span> It could be biased in any one situation. Because order has two known states, we can also \u003cstrong>balance\u003c/strong> order rather than randomizing it. We’ll talk in some depth in Chapter \u003ca href=\"9-design.html#design\">9\u003c/a> about how to deal with these sorts of nuisance procedural confounds and when randomization vs. counterbalancing strategies are most appropriate.\u003c/span> In the case of the participant confound, \u003cstrong>random assignment\u003c/strong> of participants to conditions is the key step that breaks the connection between the myriad confounds related to individual participants’ identities and the manipulation of interest.\u003c/p>\n\u003cp>Random assignment is so central to the recipe of experimental psychology that sometimes we don’t even think about it as an ingredient! But without it, the cake simply doesn’t rise. One classic example of a violation of random assignment is the sequential recruitment of participants to conditions (e.g., first testing the non-Dylan group and then the Dylan group). This kind of practice can seem unproblematic to a research assistant carrying out a study (we’ve done it!). But it confounds time with group participation and can lead to all sorts of unforeseen issues in causal inference. Imagine that Dylan wins the Nobel prize somewhere during the recruitment process. This event obviously could change the nature of your manipulation. But so could infinite other events – from a global pandemic all the way to the normal course of the seasons changing. Random assignment is the only way to avoid these confounds.\u003c/p>\n\u003cp>Random assignment is great, but there is a caveat. Random assignment cannot rescue your \u003cem>individual\u003c/em> sample from biases. For example, in your randomly-assigned conditions, maybe a few more Dylan condition participants happened to be run after his Nobel than before. Instead, random assignment guarantees that \u003cem>on average\u003c/em> your estimate of the causal effect will be unbiased – even if you get lucky or unlucky on this individual instance of your experiment.\u003clabel for=\"tufte-sn-10\" class=\"margin-toggle sidenote-number\">10\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-10\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">10\u003c/span> We’ll return to the topic of whether you should test for or adjust for “unhappy randomization” in Chapter \u003ca href=\"7-models.html#models\">7\u003c/a>. A brief answer here, to pique your curiosity: no.\u003c/span> That’s pretty good, and maybe it’s the best you can hope for!\u003c/p>\n\u003c/div>\n\u003cdiv id=\"who-are-we-measuring\" class=\"section level2\" number=\"1.4\">\n\u003ch2>\u003cspan class=\"header-section-number\">1.4\u003c/span> Who are we measuring?\u003c/h2>\n\u003cp>In our running example of the Dylan hypothesis, we have been quite vague about the scope and limitations of generalization. Is this a causal estimate that should apply to all people? Of US college students? Of Boomers that grew up listening to Dylan? Estimating an effect via a \u003cstrong>sample\u003c/strong> – the set of people who participate in the experiment – presupposes a \u003cstrong>population\u003c/strong> that the sample is drawn from. Psychology researchers often give little thought to this issue, but generalizability across populations is a key challenge for psychology.\u003c/p>\n\u003c!-- A critical part of theorizing is saying when your theory *doesn't* apply, and as a group, psychologists tend to be terrible at this [@yarkoni2020]. Maybe Shepard is one of our few exceptions in that he very explicitly claimed a completely universal scope: his law is intended to apply to all people and all stimuli! -->\n\u003cp>To point out the ubiquity of population generalizability issues, \u003cspan class=\"citation\">Henrich et al. (\u003ca href=\"#ref-henrich2010\" role=\"doc-biblioref\">2010\u003c/a>)\u003c/span> coined the acronym \u003cstrong>WEIRD\u003c/strong>. This catchy name describes the oddness of making generalizations about all of humanity from experiments on a sample that is quite unusual because it is Western, Educated, Industrialized, Rich, and Democratic. Henrich and colleagues argue that seemingly “fundamental” psychological like visual perception, spatial cognition, and social reasoning all differ pervasively across populations – hence, \u003cem>any\u003c/em> generalization from an effect estimated with a WEIRD subpopulation is unwarranted.\u003clabel for=\"tufte-sn-11\" class=\"margin-toggle sidenote-number\">11\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-11\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">11\u003c/span> We’ll discuss the problem of sample generalizability – and some ways to reason about the WEIRD problem – in more depth in Chapter \u003ca href=\"10-sampling.html#sampling\">10\u003c/a>.\u003c/span>\u003c/p>\n\u003cp>A second generalizability challenge is that experimental manipulations are typically realized across specific stimuli. In our Dylan example, this would be using “Like a Rolling Stone” as our only experimental stimulus but then making the claim that our effect generalizes to all Dylan – or even all lyrically-dense music! Yet we too rarely reason about how general our hypothesis across the broader space of stimuli. As we’ll see in Chapters \u003ca href=\"7-models.html#models\">7\u003c/a> and \u003ca href=\"9-design.html#design\">9\u003c/a>, this issue has consequences for our statistical analysis as well as for our experimental designs \u003cspan class=\"citation\">(\u003ca href=\"#ref-yarkoni2020\" role=\"doc-biblioref\">Yarkoni, 2020\u003c/a>)\u003c/span>.\u003c/p>\n\u003cp>Questions of generalizability are pervasive, but the first step is simply to acknowledge and reason about them. One mechanism for enforcing thinking about theory scope is the idea that all papers should have a section reporting their limitations. We tend to think this is a good idea. \u003cspan class=\"citation\">Simons et al. (\u003ca href=\"#ref-simons2017\" role=\"doc-biblioref\">2017\u003c/a>)\u003c/span> calls this a Constraints on Generality statement.\u003clabel for=\"tufte-sn-12\" class=\"margin-toggle sidenote-number\">12\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-12\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">12\u003c/span> In an early working draft, the COG statement was called a Statement of Limits on Generality (SLOG), which we found more memorable.\u003c/span> They recommend explicit qualification of generalizability across 1) experimental participants, 2) experimental stimuli, 3) procedures, and 4) historical or temporal features.\u003c/p>\n\u003cdiv class=\"box ethical_considerations\">\n\u003cp>(TITLE) Consequences of poor generalizability\u003c/p>\n\u003cp>Generalizability questions can seem abstract, but it can have substantial practical consequences when experimental research is applied. To take an example from medical research, it has been common practice for decades to study drug effects in mouse models. What is less well-appreciated is that the typical mouse model has been the \u003cem>male\u003c/em> mouse only, with a six-fold difference in use of male relative to female mice. This seemingly practical decision may have widespread consequences \u003cspan class=\"citation\">(\u003ca href=\"#ref-shansky2021\" role=\"doc-biblioref\">Shansky &amp; Murphy, 2021\u003c/a>)\u003c/span>. Women experience a greater proportion of adverse consequences from pharmaceutical treatments than men, likely because research on development and evaluation of such treatments is conducted on male animals.\u003c/p>\n\u003cp>When it comes to research with humans, the analogy is clear. We hope that our findings are implemented in practice through the creation of psychologically-based policies, treatments, or educational interventions. But if effects are measured using a population that mismatches the population to which the interventions are applied, then we should expect lowered efficacy and perhaps even unanticipated negative effects. To combat this issue, researchers have an ethical obligation to give careful consideration to the limitations of their samples and to the scope of applicability of their claims.\u003c/p>\n\u003c/div>\n\u003c/div>\n\u003cdiv id=\"experiments-chapter-summary\" class=\"section level2\" number=\"1.5\">\n\u003ch2>\u003cspan class=\"header-section-number\">1.5\u003c/span> Experiments: Chapter summary\u003c/h2>\n\u003cp>In this chapter, we defined an experiment as a combination of a manipulation and a measure. This combination, along with randomization, licenses strong causal inferences about the structure of the world. Experiments are a terrible way to learn about the world. They are costly and time-consuming, and sometimes they fail in uninterpretable ways. Yet they are our best method for estimating causal effects; many other techniques exist but they rely on more complex statistical methods that require certain conditions to be feasible.\u003clabel for=\"tufte-sn-13\" class=\"margin-toggle sidenote-number\">13\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-13\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">13\u003c/span> For example, the presence of an external “instrument” – like the weather or the introduction of internet services or changes in state-level policies – that is causally related to your cause of interest but unconnected to your outcome.\u003c/span>\u003c/p>\n\u003cp>Sometimes we just need to know about the existence or magnitude effects for some applied goal, say deciding whether implementing a particular curriculum will lead to changes in mathematics test scores. In this case, a randomized trial of the intervention is all that we need, and the causal effect is the end-point of the study. But often in psychology we want to do more. The “extra” thing we would like to do is to build theories. We’ll turn to this topic in Chapter \u003ca href=\"2-theories.html#theories\">2\u003c/a>.\u003c/p>\n\u003cdiv class=\"box exercises\">\n\u003cp>Design an experiment for testing the Dylan Hypothesis. (A) What is the condition structure, what is the measure? How do you control for nuisance variables? (B) What are the best arguments against your proposed experimental design? What would an advocate of the Dylan Hypothesis say if it failed to yield a non-zero effect?\u003c/p>\n\u003c/div>\n\n\u003c/div>\n\u003c/div>\n\u003ch3>References\u003c/h3>\n\u003cdiv id=\"refs\" class=\"references csl-bib-body hanging-indent\" line-spacing=\"2\">\n\u003cdiv id=\"ref-boring1954\" class=\"csl-entry\">\nBoring, E. G. (1954). The nature and history of experimental control. \u003cem>The American Journal of Psychology\u003c/em>, \u003cem>67\u003c/em>(4), 573–589. \u003ca href=\"http://www.jstor.org/stable/1418483\">http://www.jstor.org/stable/1418483\u003c/a>\n\u003c/div>\n\u003cdiv id=\"ref-cunningham2021\" class=\"csl-entry\">\nCunningham, S. (2021). \u003cem>Causal inference\u003c/em>. Yale University Press.\n\u003c/div>\n\u003cdiv id=\"ref-henrich2010\" class=\"csl-entry\">\nHenrich, J., Heine, S. J., &amp; Norenzayan, A. (2010). The weirdest people in the world? \u003cem>Behavioral and Brain Sciences\u003c/em>, \u003cem>33\u003c/em>(2-3), 61–83.\n\u003c/div>\n\u003cdiv id=\"ref-lewis1973\" class=\"csl-entry\">\nLewis, D. (1973). \u003cem>Counterfactuals\u003c/em>. John Wiley &amp; Sons.\n\u003c/div>\n\u003cdiv id=\"ref-mill1869\" class=\"csl-entry\">\nMill, J. S. (1869). \u003cem>A system of logic, ratiocinative and inductive: Being a connected view of the princilples of evidence and the methods of scientific investigation\u003c/em>. Harper; brothers.\n\u003c/div>\n\u003cdiv id=\"ref-pearl1998\" class=\"csl-entry\">\nPearl, J. (1998). Graphical models for probabilistic and causal reasoning. \u003cem>Quantified Representation of Uncertainty and Imprecision\u003c/em>, 367–389.\n\u003c/div>\n\u003cdiv id=\"ref-shansky2021\" class=\"csl-entry\">\nShansky, R. M., &amp; Murphy, A. Z. (2021). Considering sex as a biological variable will require a global shift in science culture. \u003cem>Nature Neuroscience\u003c/em>, \u003cem>24\u003c/em>(4), 457–464.\n\u003c/div>\n\u003cdiv id=\"ref-simons2017\" class=\"csl-entry\">\nSimons, D. J., Shoda, Y., &amp; Lindsay, D. S. (2017). Constraints on generality (COG): A proposed addition to all empirical papers. \u003cem>Perspectives on Psychological Science\u003c/em>, \u003cem>12\u003c/em>(6), 1123–1128.\n\u003c/div>\n\u003cdiv id=\"ref-winston1996\" class=\"csl-entry\">\nWinston, A. S., &amp; Blais, D. J. (1996). What counts as an experiment?: A transdisciplinary analysis of textbooks, 1930-1970. \u003cem>The American Journal of Psychology\u003c/em>, \u003cem>109\u003c/em>(4), 599–616. \u003ca href=\"http://www.jstor.org/stable/1423397\">http://www.jstor.org/stable/1423397\u003c/a>\n\u003c/div>\n\u003cdiv id=\"ref-yarkoni2020\" class=\"csl-entry\">\nYarkoni, T. (2020). The generalizability crisis. \u003cem>Behav. Brain Sci.\u003c/em>, 1–37.\n\u003c/div>\n\u003c/div>\n\u003cp style=\"text-align: center;\">\n\u003ca href=\"index.html\">\u003cbutton class=\"btn btn-default\">Previous\u003c/button>\u003c/a>\n\u003ca href=\"2-theories.html\">\u003cbutton class=\"btn btn-default\">Next\u003c/button>\u003c/a>\n\u003c/p>\n\u003c/div>\n\u003c/div>\n\n\n\n"}}</script></body>

</html>