<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 4 Estimation | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 4 Estimation | Experimentology">

<title>Chapter 4 Estimation | Experimentology</title>

<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />




<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="toc/toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li><a href="1-intro.html#intro"><span class="toc-section-number">1</span> Experiments and theories</a></li>
<li><a href="2-replication.html#replication"><span class="toc-section-number">2</span> Replication and reproducibility</a></li>
<li><a href="3-ethics.html#ethics"><span class="toc-section-number">3</span> Ethics</a></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li><a href="4-estimation.html#estimation"><span class="toc-section-number">4</span> Estimation</a></li>
<li><a href="5-inference.html#inference"><span class="toc-section-number">5</span> Inference</a></li>
<li><a href="6-models.html#models"><span class="toc-section-number">6</span> Models</a></li>
<li class="part"><span><b>III Design and Planning</b></span></li>
<li><a href="7-measurement.html#measurement"><span class="toc-section-number">7</span> Measurement</a></li>
<li><a href="8-design.html#design"><span class="toc-section-number">8</span> Design of experiments</a></li>
<li><a href="9-sampling.html#sampling"><span class="toc-section-number">9</span> Sampling</a></li>
<li><a href="10-prereg.html#prereg"><span class="toc-section-number">10</span> Preregistration</a></li>
<li class="part"><span><b>IV Execution</b></span></li>
<li><a href="11-selection.html#selection"><span class="toc-section-number">11</span> Replicating or extending an existing study</a></li>
<li><a href="12-collection.html#collection"><span class="toc-section-number">12</span> Data collection</a></li>
<li><a href="13-management.html#management"><span class="toc-section-number">13</span> Project management</a></li>
<li class="part"><span><b>V Analysis and Reporting</b></span></li>
<li><a href="14-viz.html#viz"><span class="toc-section-number">14</span> Visualization</a></li>
<li><a href="15-eda.html#eda"><span class="toc-section-number">15</span> Exploratory data analysis</a></li>
<li><a href="16-writing.html#writing"><span class="toc-section-number">16</span> Reproducible writing</a></li>
<li><a href="17-meta.html#meta"><span class="toc-section-number">17</span> Meta-analysis</a></li>
<li><a href="18-conclusions.html#conclusions"><span class="toc-section-number">18</span> Conclusions</a></li>
<li class="part"><span><b>VI Appendices</b></span></li>
<li><a href="19-rmarkdown.html#rmarkdown"><span class="toc-section-number">19</span> R Markdown Tutorial</a></li>
<li><a href="20-tidyverse.html#tidyverse"><span class="toc-section-number">20</span> Tidyverse Tutorial</a></li>
<li><a href="21-ggplot.html#ggplot"><span class="toc-section-number">21</span> ggplot Tutorial</a></li>
<li><a href="22-instructors.html#instructors"><span class="toc-section-number">22</span> Instructor‚Äôs guide</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="estimation" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Estimation</h1>
<div class="learning-goals">
<p>üçé Learning goals:</p>
<ul>
<li>Discuss differences between frequentist and Bayesian perspectives</li>
<li>Contrast inference and estimation as two goals of statistical analysis</li>
<li>Reason about standardized effect sizes and their strengths and weaknesses</li>
<li>Visualize and interpret measures of estimate variability (including confidence intervals)</li>
</ul>
</div>
<!-- ## Meta-notes -->
<!-- NC: this chapter currently has multiple running examples. Part of the reason for this is because the first part focuses on a dichotomous outcome and the second part focuses on a continous outcome. If we switch the first part to a continous outcome (e.g., subjective pleasantness ratings), I can probably make the second part use a consistent study design (e.g., we could compare mean liking ratings between children vs. adults) -->
<!-- ### Topics to cover (not yet incorporated) -->
<!-- * Idea of a sampling distribution (or could go in "Inference") -->
<p>In the first section of this book, our goal was to set up some of the theoretical ideas that motivate our approach to experimental design and planning. We introduced our key thesis, namely that experiments are about measuring causal effects. We also began to discuss some of our key themes, including precision of measurement, reduction of bias, and generalization across populations. In this next section of the book, treating statistical topics, we will integrate these ideas with an analytic toolkit for <strong>estimating</strong> causal effects, <strong>quantifying the size and precision</strong> of estimates (this chapter), making <strong>inferences</strong> about the evidence for such effects (Chapter <a href="5-inference.html#inference">5</a>), and making models for estimation and inference in more complex settings (Chapter <a href="6-models.html#models">6</a>). Although this book is not a statistics text, we hope that these chapters provide some practical foundations for beginning the statistical analysis of your experimental data.</p>
<div class="case-study">
<p>üî¨ Case study: The Lady Tasting Tea</p>
<p>The birth of modern statistical inference came from a single, epochal act of mansplaining.<label for="tufte-sn-1" class="margin-toggle sidenote-number">1</label><input type="checkbox" id="tufte-sn-1" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">1</span> An important piece of context for the work of Ronald Fisher, Karl Pearson, and other early pioneers of statistical inference is that they were all strong proponents of eugenics. Fisher was the founding Chairman of the Cambridge Eugenics Society. Pearson was perhaps even worse, an avowed Social Darwinist who believed fervently in Eugenic legislation. These views are repugnant.</span> Sir Ronald Fisher was apparently at a party when a lady declared that she could tell the difference between cups when the tea was added to the milk vs.¬†the milk to the tea. Rather than taking her at her word, Fisher devised an experimental and data analysis procedure to test her claim.<label for="tufte-sn-2" class="margin-toggle sidenote-number">2</label><input type="checkbox" id="tufte-sn-2" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">2</span> If you‚Äôre interested in this history, we recommend <span class="citation"><a href="#ref-salsburg2001" role="doc-biblioref">Salsburg</a> (<a href="#ref-salsburg2001" role="doc-biblioref">2001</a>)</span>‚Äôs delightful book, ‚ÄúThe Lady Tasting Tea,‚Äù about the origins of modern statistics.</span></p>
<p>The basic schema of the experiment was that the lady would have to judge a set of new cups of tea and sort them into milk-first vs.¬†tea-first sets. Her data would then be analyzed to determine whether her level of correct choice exceeded that expected by chance. While this process now sounds like a quotidian experiment that might be done on a cooking reality show, in fact this is one of those touchstones that feels unremarkable because it literally established the way science was done for the next century.</p>
<p>One important element of the experiment that was unusual was its treatment of design confounds such as pouring order or cup material. Prior experimental practice would have been to try to equate all of the cups as closely as possible, decreasing the influence of confounders. Fisher recognized that this strategy was insufficient and that random assignment was critical for making strong causal inferences about the treatment (milk then tea vs.¬†tea then milk). We discussed the causal power of random assignment in Chapter <a href="1-intro.html#intro">1</a> ‚Äì this experiment is a key touchstone in the popularization of randomized experiments!<label for="tufte-sn-3" class="margin-toggle sidenote-number">3</label><input type="checkbox" id="tufte-sn-3" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">3</span> Randomized experiments were not invented by Fisher. Perhaps the earliest example of a (somewhat) randomized experiment was a trial of scurvey treatments in the 1700s <span class="citation">(<a href="#ref-dunn1997" role="doc-biblioref">Dunn, 1997</a>)</span>. <span class="citation"><a href="#ref-peirce1884" role="doc-biblioref">Peirce &amp; Jastrow</a> (<a href="#ref-peirce1884" role="doc-biblioref">1884</a>)</span> also report a strikingly modern use of randomized stimulus presentation (via shuffling cards). Nevertheless, Fisher‚Äôs statistical work popularized randomized experiments throughout the sciences, in part by integrating them with a set of analytic methods.</span></p>
</div>
<div id="estimating-an-effect" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Estimating an effect</h2>
<p>If experiments are about estimating effects, how do we actually use our experimental data to make these estimates? With apologies to Fisher, for our example we‚Äôll design a slightly more modern version of his experiment using a forced-choice judgment measure. Our causal theory is that the tea quality is affected by milk ordering, so we‚Äôll test that by rating tea quality in both orderings. We present participants with 50 cups of tea (in random order, of course). Half are prepared milk-first, half tea-first. Then the participant must give an independent judgment about each by rating the tea on a scale from 1 (horrible) to 7 (perfect).</p>
<p>Eventually, we‚Äôll want to estimate the effect of milk-first preparation on quality. But for now, our goal will be to estimate the quality of the tea when it is milk-first [the better way, according to some data; <span class="citation"><a href="#ref-kennedy2003" role="doc-biblioref">Kennedy</a> (<a href="#ref-kennedy2003" role="doc-biblioref">2003</a>)</span>]. More formally, we want to use our <strong>sample</strong> of 25 tea judgments to estimate a <strong>population parameter</strong> that we can‚Äôt directly observe, namely the true perceived quality of all possible milk-first cups. Here we‚Äôre looking at this simple estimation problem rather than the more familiar problem where we have a sample of different people from a population and we want to try and estimate the population parameter. In Chapter <a href="6-models.html#models">6</a> we‚Äôll talk more about modeling variability across experimental participants from a population.</p>
<!-- ^[MM: This example is perhaps a little confusing for showing the sample vs. population parameter because the population here is a bit hard to conceptualize. Also, I worry that readers will be mislead into thinking that it's the subjectivity in tea ratings that causes statistical uncertainty, rather than the finite sample size. An easier example for this chapter might be something like estimating the mean height of students at College X, where it's more clear that there is no subjectivity involved and that the population is the mean height if we were to measure every student at College X rather than just a sample.]  -->
<p>We‚Äôll try to go easy on notation but some amount will make things clearer. We will use <span class="math inline">\(\theta\)</span> (‚Äútheta‚Äù) to denote the parameter we want to estimate (the ‚Äúestimand‚Äù) and <span class="math inline">\(\widehat{\theta}\)</span> its sample estimate.<label for="tufte-sn-4" class="margin-toggle sidenote-number">4</label><input type="checkbox" id="tufte-sn-4" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">4</span> Statisticians use ‚Äúhats‚Äù like this to denote sample estimates. One way to remember this is that the ‚Äúperson in the hat‚Äù is wearing a hat to dress up as the actual quantity. Feel free to ignore this but it helps us.</span> This is the probability that the lady is correct in her judgment.</p>
<!-- ^[NC: I am confused because it seems like you now jump back to the original tea example (the probability that the lady is correct in her judgment) vs. ratings of the quality of the tea).]  -->
<div id="maximum-likelihood-estimation" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Maximum likelihood estimation</h3>
<p>OK, you are probably saying, if we we want our estimate of milk-first quality, shouldn‚Äôt we just take her average rating across the 25 cups of tea? The answer is yes, but let‚Äôs unpack that choice for just a moment.</p>
<p>Taking the sample mean as our estimate <span class="math inline">\(\widehat{\theta}\)</span> is an example of an estimation approach called <strong>maximum likelihood estimation</strong>. In general terms, maximum likelihood estimation is a two-step process. First, we assume a <strong>model</strong> for how the data were generated. This model is specified in terms of certain population parameters. In our example, the ‚Äúmodel‚Äù is as simple as they come: we just assume the lady has some unknown accuracy such that on each trial she gets the right answer with probability <span class="math inline">\(\theta\)</span>.<label for="tufte-sn-5" class="margin-toggle sidenote-number">5</label><input type="checkbox" id="tufte-sn-5" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">5</span> In other problems, like multi-variable regression, the model is more complicated, for example involving more than one regression coefficient ‚Äì that‚Äôs what we‚Äôll get to in Chapter <a href="6-models.html#models">6</a>.</span></p>
<p>Second, we try to find the values of the population parameters that make our observed data as likely as possible. For example, if our sample mean is <span class="math inline">\(\widehat{\theta} = .73\)</span>, what underlying value of <span class="math inline">\(\theta\)</span> would make these data most likely to occur? Well, suppose the underlying parameter were <span class="math inline">\(\theta=.99\)</span>. Then it would be pretty unlikely that our sample mean would be so much smaller. So <span class="math inline">\(\theta=.99\)</span> is a poor guess for the population parameter based on these data. Conversely, if the parameter were <span class="math inline">\(\theta=.5\)</span>, it would pretty unlikely that our sample mean would be so much <em>larger</em>. The value of <span class="math inline">\(\theta\)</span> that makes these data most likely is just .73 itself: the sample mean! That is why the sample mean in this case is the maximum likelihood estimate.</p>
</div>
<div id="bayesian-estimation" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Bayesian estimation</h3>
<p>In the case of the lady tasting tea, we don‚Äôt really have strong expectations about what her <span class="math inline">\(\theta\)</span> is. Maybe she‚Äôs tea-sensitive, maybe not. But in some cases, we want to bring our prior knowledge to bear. Say she claimed she could guess the state of each cup of tea without even tasting it ‚Äì or maybe even without even seeing it! You‚Äôd probably be skeptical. (We‚Äôll look at a case like this in the next chapter). How would you formalize this skepticism? One way is by putting in place a prior expectation about her sensitivity.</p>
<!-- [Here I would suggest transitioning by saying that what we did above makes sense if the only criterion for what constitutes a good guess is the data themselves. "But what if we had some background knowledge about heights in this college? For example, we have data from the US Census on adult heights, so we'd probably expect college students to be roughly similar.] -->
<!-- [EXISTING TEXT BELOW] -->
<!-- [^1]: You can't get away from measurement and psychometrics! We said we were really interested in the effect of tea ordering on tea perception. But this number that we're estimating is something more like this particular participant's accuracy, and that's not the same thing that we actually wanted. To get from what we're estimating to our effect of interest, we'd need to establish some **linking hypotheses** about how the participant's accuracy can be derived from the participant's perception and the properties of the stimulus. That's perhaps not worth doing in this toy example, but more generally it's a critical part of getting from your measure to your construct of interest! -->
<p>We can do this via <strong>Bayesian estimation</strong> of <span class="math inline">\(\theta\)</span> ‚Äì our belief about the participant‚Äôs accuracy. We observe some data <span class="math inline">\(d\)</span>, consisting of the set of correct and incorrect responses in the experiment. Now we can use <strong>Bayes‚Äô rule</strong>, a tool from basic probability theory, to estimate this number.</p>
<p>Bayes‚Äô rule says:</p>
<p><span class="math display">\[
\color{purple}{p(\theta | d)} = \frac{\color{red}{p(d | \theta )} \color{blue}{p(\theta )}}{\color{black}{p(d)}}.
\]</span></p>
<p>Each part of this equation has a name, and it‚Äôs worth becoming familiar with them. The thing we want to compute (<span class="math inline">\(p(\theta |d)\)</span>) is called the <strong>posterior probability</strong> ‚Äì it tell us what we should believe about the participant‚Äôs ability given the data we observed. We then break that down into two terms in the numerator.<label for="tufte-sn-6" class="margin-toggle sidenote-number">6</label><input type="checkbox" id="tufte-sn-6" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">6</span> We‚Äôre making the posterior <span style="color: purple;">purple</span> to indicate the combination of likelihood (<span style="color: red;">red</span>) and prior (<span style="color: blue;">blue</span>).</span></p>
<p>The first part of the numerator is <span class="math inline">\(p(d|h)\)</span>, the probability of the data we observed given our hypothesis about the participant‚Äôs ability. This part is called the <strong>likelihood</strong>.<label for="tufte-sn-7" class="margin-toggle sidenote-number">7</label><input type="checkbox" id="tufte-sn-7" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">7</span> Speaking informally, ‚Äúlikelihood‚Äù is just a synonym for probability, but this is a technical meaning for the term, which can get a bit confusing.</span> This term tells us about the relationship between our hypothesis and the data we observed ‚Äì so if we think the participant has high ability (say <span class="math inline">\(\theta = .9\)</span>) then the probability of a bunch of low accuracy observations will be fairly low.</p>
<p>The second term in the numerator, <span class="math inline">\(p(\theta )\)</span>, is called the <strong>prior</strong>. This term encodes our beliefs about how likely our participant is to have different levels of ability. Intuitively, if we think that they are very unlikely to have high tea discrimination ability, we should require more evidence to convince us of a particular level of discrimination. In contrast, if we think they are likely to have this ability, we should be easier to convince.</p>
<div class="figure"><span id="fig:inference-bayes-demo"></span>
<p class="caption marginnote shownote">
Figure 4.1: Examples of Bayesian inference about tea discrimination ability under three different priors (facets). Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior.
</p>
<img src="experimentology_files/figure-html/inference-bayes-demo-1.png" alt="Examples of Bayesian inference about tea discrimination ability under three different priors (facets). Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior." width="\linewidth"  />
</div>
<p>Figure <a href="4-estimation.html#fig:inference-bayes-demo">4.1</a> gives an example of the combination of prior and data.<label for="tufte-sn-8" class="margin-toggle sidenote-number">8</label><input type="checkbox" id="tufte-sn-8" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">8</span> The model we use for this example is called a <strong>Beta-Binomial conjugate model</strong> and is a very convenient model for working with count data representing successes and failures.</span> For the sake of this example, we assume that we have run 12 tea discrimination trials and observed 9 successes and 3 failures. The evidence alone ‚Äì with no prior ‚Äì suggests a discrimination estimate of <span class="math inline">\(9/12 = .75\)</span> (the maximum likelihood estimate). When we use a flat prior, we get the same estimate of 0.75.<label for="tufte-sn-9" class="margin-toggle sidenote-number">9</label><input type="checkbox" id="tufte-sn-9" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">9</span> In general, Bayesian estimates and maximum likelihood estimates will exactly coincide either under a flat prior or as you get infinite data (<span class="math inline">\(n \to \infty\)</span>). Bayesian estimation is most important when you have strong beliefs and not a lot of data.</span> In contrast, if we go in assuming that discrimination is likely to be absent or weak, we are biased downward in our eventual estimate of 0.69; if we go in assuming good discrimination, we end up biased upwards to 0.78.</p>
<!-- TODO: HERE WOULD BE A GREAT PLACE FOR AN INTERACTIVE -->
</div>
</div>
<div id="measures-of-effect-size" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Measures of effect size</h2>
<p>Once we have measured something, we need to make a decision about how to describe this relationship to the world. Sometimes we are working with fairly intuitive relationships that are easy to describe. A researcher might say, for example, that children who drank espresso ran, on average, around the playground for 20 more minutes than children who drank milk. We all have a shared understanding of what 20 minutes mean, so people will likely not have much trouble understanding this estimated effect. But what if something less intuitive was measured, such as how excited the children reported feeling on a 10-point Likert-type scale (1 being ‚Äúnot at all excited‚Äù; 10 being ‚Äúextremely excited‚Äù)? What does it mean, for example, to say that children who drank espresso on average rated their excitement as a 5 and children who drank milk on average rated their excitement as a 4? And how is this comparable to, for instance, a 1-point change on a 100-point excitement scale (1 being ‚Äúnot at all excited‚Äù; 100 being ‚Äúextremely excited?‚Äù</p>
<p>To provide a common language for describing these relationships, some researchers use <em>standardized effect sizes.</em> A common standardized effect size is Cohen‚Äôs <em>d</em>, which provides a standardized estimate of the difference between two means. There are many different ways to calculate Cohen‚Äôs <em>d</em> (Lakens, 2013), but all approaches are usually some variant of the following formula:</p>
<p><span class="math display">\[d = \frac{M_1- M_2}{SD}\]</span></p>
<p>Let‚Äôs start with the children-espresso-drinking study that used a 10-point excitement scale. <span class="math inline">\(M_1\)</span> refers to the mean excitement ratings of children who were drank espresso (a 5 out of 10), <span class="math inline">\(M_2\)</span> refers to the mean excitement ratings of children who drank milk (a 4 out of 10), and <span class="math inline">\(SD\)</span> refers to the standard deviation of all the children in the study (let‚Äôs assume this is 2). This leaves us with:</p>
<p><span class="math display">\[{d_{children.study}} = \frac{M_1- M_2}{SD} = \frac{5- 4}{2} = \frac{1}{2} = 0.5\]</span></p>
<p>A Cohen‚Äôs <em>d</em> of 0.50 means that children who drank espresso had excitement scores that were, on average, 0.50 standard deviations higher than children who drank milk. It may not be a very intuitive way of thinking about difference scores (see Pros and cons of standardization), but it allows us to compare the size of the effect to studies using different measures.</p>
<p>For instance, let‚Äôs say that we ran a conceptual replication of the study with two changes: (1) we studied adults instead of children, and (2) we used a 100-point excitement scale instead of a 10-point scale. And imagine that, just as we found that espresso-drinking children were rated as 1-point higher on a 7-point excitement measure, espresso-drinking adults were rated 1-point higher on a <em>100-point</em> excitement scale. Intuitively, it is obvious that these effects are different. And, statistically, this becomes clear when we describe the effect in terms of standardized mean differences.</p>
<p>For the study with adults, let‚Äôs imagine that adults who drank espresso on average rated their excitement as a 50 (<span class="math inline">\(M_1\)</span>) out of 100 and adults who drank milk on average rated their excitement as a 49 (<span class="math inline">\(M_2\)</span>). To keep things simple, let‚Äôs also assume that variability in adults excitement levels are equal to that of children. If this is the case, a standard deviation of 2 in the children‚Äôs ratings on the 10-point scale is equivalent to a standard deviation of 20 in the adults‚Äô ratings on the 100-point scale (<span class="math inline">\(SD = 20\)</span>). Using the same formula as above, we would find:</p>
<p><span class="math display">\[{d_{adult.study}} = \frac{M_1- M_2}{SD} = \frac{50- 49}{20} = \frac{1}{20} =  0.05\]</span></p>
<p>A Cohen‚Äôs <em>d</em> of .05 means that adults who drank espresso had excitement scores that were, on average .05 standard deviations higher than the adults who drank milk. This is much smaller than the .50 difference in standard deviation observed among children. Indeed, social scientists often consider <em>d</em> = 0.50 to be a <em>large effect</em>, and a <em>d</em> = 0.05 to be negligible. These effect size interpretation norms are somewhat arbitrary and there are many exceptions, but you get the point: standardizing the measure of differences in excitement levels allowed us to communicate that the effect of espresso on children‚Äôs excitement levels larger than the effects on adults.</p>
<p>Cohen‚Äôs <em>d</em> is one of many standardized effect sizes that researchers can use. Just as Cohen‚Äôs <em>d</em> standardizes differences in group means, there are also ways of standardizing relationships between categorical variables (e.g., Odds Ratio), how well a predictor variable explains an outcome variable (e.g., Pearson‚Äôs <em>r</em>, R<sup>2</sup>, and <span class="math inline">\(\eta^2\)</span>), and more! For a review, see Fritz, Morris, and Richler (2012).</p>
<div id="pros-and-cons-of-standardizing-effect-sizes" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Pros and cons of standardizing effect sizes</h3>
<p>By now, you‚Äôre probably realizing that there are some pros and cons of standardizing effect sizes. Sure, it helps communicate that a 1-point change on a 10-point scale is not the same as a 1-point change on a 100-point scale. But, is it any better to say that the first change represents a 0.50 standard deviation difference and the second a 0.05 standard deviation difference? It‚Äôs a good question‚Äìone that researchers have argued about for a long time!</p>
<p>Proponents of effect size standardization argue that doing so allows us to more easily compare results across studies. Across studies, researchers use different measures; different study designs; and different populations. Standardization allows us to use a common language to describe estimated relationships in these varied contexts. This is helpful when we want to aggregate and compare effects across studies (via meta-analysis, see Chapter 17). And it is also helpful when planning new studies. When trying to figure out how many participants to run in a study, almost all programs use standardized effect sizes to determine, for example, how much data would be needed to reliably detect a specific standardized effect size.</p>
<!-- NC NOTE: ITS NICE TO BRING UP POWER ANALYSIS, BUT I'M NOT SURE HOW MUCH BACKGROUND THE READER WILL HAVE AT THIS POINT.-->
<!-- [STILL VERBATIM FROM MRM]  NC FOLLOW-UP: WHICH PART IS VERBATIM? -->
<p>Standardizing effect sizes, though, has limitations. For example, if two interventions produce the same absolute change in the same outcome measure, but are studied in different populations in which the variability on the outcome differs substantially, the interventions would produce different standardized mean differences.</p>
<!-- NC: I THINK THE ABOVE TEXT IS A BIT ABSTRACT. ADDING AN EXAMPLE BELOW. IF WE REALLY WANT TO DRIVE THE POINT HOME, A FIGURE COULD BE HELPFUL -->
<p>For example, let‚Äôs assume that espresso leads to the same absolute changes in feelings of excitement in adults and children. Furthermore, imagine that adults generally have more consistent excitement levels than children (e.g., that a randomly selected adults would generally be consistently calm, but that a randomly selected sample of children would consist of some kids nodding off and other kids bouncing off the walls with excitement). Quantitatively, this would often lead us to observe a smaller standard deviation in excitement levels in adults (e.g., let‚Äôs assume <span class="math inline">\(SD_{adults} = 1\)</span> ) vs.¬†children (e.g., let‚Äôs assume <span class="math inline">\(SD_{children} = 2\)</span>). In this scenario, even if the espresso led to the same 1-point absolute change in feelings of excitement among adults and children, the standardized effect size would look quite different.</p>
<p><span class="math display">\[{d_{adult.study}} = \frac{M_1- M_2}{SD} = \frac{5- 4}{1} = \frac{1}{1} =  1\]</span></p>
<p><span class="math display">\[{d_{children.study}} = \frac{M_1- M_2}{SD} = \frac{5- 4}{2} = \frac{1}{2} =  0.50\]</span></p>
<p>This example highlights some of the challenges with standardization. If we focused on the fact that both adults and children experienced a 1-point change in excitement levels, we would conclude that espresso leads to equal changes in excitement among adults and children. If we focused on the standardized effect sizes, however, we would conclude that the effect of espresso is twice as big for adults vs.¬†children.</p>
<p>So which is better: describing raw scores or standardized scores? In general our response is ‚ÄúWhy not both?‚Äù But if you wanted to pick one or the other, we recommend focusing on raw scores when working with measures that are (a) intuitive to understand (e.g., temperature), and/or used fairly consistently across studies (e.g., measuring blood pressure in terms of mmHg). When, however, working with measures that are (a) relatively unintuitive to understand (e.g.¬†changes on an arbitrary 7-point Likert-type scale) or (b) used inconsistently across studies (e.g., measuring excitement with a 10-point scale in one study and a 100-point scale in a different study), we recommend standardized effect sizes.</p>
</div>
</div>
<div id="variability-and-precision" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Variability and Precision</h2>
<!-- NC: I THINK IT MAY MAKE SENSE TO TALK ABOUT VARIABILITY AND PRECISION BEFORE MEASURES OF EFFECT SIZE. TWO REASONS. ONE: BECUASE OUR RUNNING EXAMPLE IN THE EFFECT SIZE SECTION CURRENTLY DISCUSSES SD A LOT. TWO: BECAUSE THIS SECTION MAKES A DISTINCTION BETWEEN FREQ VS. BAYESIAN THAT ISN'T CURRENTLY MADE IN THE EFFECT SIZE SECTION-->
<div id="standard-error-of-the-mean" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Standard error of the mean</h3>
<p>Talk about standard error with respect to SD of sampling distribution</p>
</div>
<div id="confidence-intervals" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Confidence intervals</h3>
<p>CIs for inference</p>
<p>Confidence intervals: 95% of these regions will contain the TRUE parameter Remember frequentists - there is a TRUE parameter</p>
<p><a href="https://istats.shinyapps.io/ExploreCoverage/" class="uri">https://istats.shinyapps.io/ExploreCoverage/</a></p>
<p>But this is not our typical interpretation, which is that 95% chance parameter is in this interval That‚Äôs the BAYESIAN interpretation</p>
<p>Bayesian Estimation</p>
<p>Find the posterior distribution of the parameter of interest You can take its mean Its HPD (highest posterior density)</p>
<p>Confidence in confidence intervals: <a href="https://link.springer.com/article/10.3758/s13423-015-0947-8" class="uri">https://link.springer.com/article/10.3758/s13423-015-0947-8</a></p>
</div>
<div id="visualizing-variability" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Visualizing variability</h3>
<p>Error bar: - standard deviation (why is this bad)? - SEM - CI</p>
<!-- ::: {.interactive} -->
<!-- ‚å®Ô∏è Interactive box: non-parametric simulations where you can shuffle data across groups a bunch of times and see what kind of distribution it produces by chance -->
<!-- ::: -->

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-dunn1997" class="csl-entry">
Dunn, P. M. (1997). James lind (1716-94) of edinburgh and the treatment of scurvy. <em>Archives of Disease in Childhood-Fetal and Neonatal Edition</em>, <em>76</em>(1), F64‚ÄìF65.
</div>
<div id="ref-kennedy2003" class="csl-entry">
Kennedy, M. (2003). How to make a perfect cuppa: Put milk in first. <em>How to Make a Perfect Cuppa: Put Milk in First</em>. <a href="https://www.theguardian.com/uk/2003/jun/25/science.highereducation">https://www.theguardian.com/uk/2003/jun/25/science.highereducation</a>
</div>
<div id="ref-peirce1884" class="csl-entry">
Peirce, C. S., &amp; Jastrow, J. (1884). On small differences in sensation. <em>Memoirs of the National Academy of Sciences</em>, <em>3</em>.
</div>
<div id="ref-salsburg2001" class="csl-entry">
Salsburg, D. (2001). <em>The lady tasting tea: How statistics revolutionized science in the twentieth century</em>. Macmillan.
</div>
</div>
<p style="text-align: center;">
<a href="3-ethics.html"><button class="btn btn-default">Previous</button></a>
<a href="5-inference.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<script src="toc/toc.js"></script>


</body>
</html>
