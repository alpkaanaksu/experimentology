<!DOCTYPE html>
<html>

<head>


<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Experimentology">

<title>Experimentology</title>

<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.21/datatables.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>



<link rel="stylesheet" type="text/css" href="/assets/index.page.c5e7dffa.css"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/src/index.page.client.jsx.df9edbd0.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/contents.b9575bfb.js"></head>

<body>




<div class="row">
<div class="col-sm-12">
<header class="_toc_1lnsy_1" id="toc"><a class="_book_title_1lnsy_24" href="/">Experimentology: An Open Science Approach to Experimental Psychology Methods</a><nav><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Preliminaries</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="1-experiments">Experiments</a><a class="_chapter_title_1lnsy_32" href="2-theories">Theories</a><a class="_chapter_title_1lnsy_32" href="3-replication">Replication and reproducibility</a><a class="_chapter_title_1lnsy_32" href="4-ethics">Ethics</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Statistics</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="5-estimation">Estimation</a><a class="_chapter_title_1lnsy_32" href="6-inference">Inference</a><a class="_chapter_title_1lnsy_32" href="7-models">Models</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Design</div><div class="_part_title_rest_1lnsy_32"> and Planning</div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="8-measurement">Measurement</a><a class="_chapter_title_1lnsy_32" href="9-design">Design of experiments</a><a class="_chapter_title_1lnsy_32" href="10-sampling">Sampling</a><a class="_chapter_title_1lnsy_32" href="11-strategy">Experimental strategy</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Execution</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="12-prereg">Preregistration</a><a class="_chapter_title_1lnsy_32" href="13-consent">Recruitment and Consent</a><a class="_chapter_title_1lnsy_32" href="14-collection">Data collection</a><a class="_chapter_title_1lnsy_32" href="15-management">Project management</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Analysis</div><div class="_part_title_rest_1lnsy_32"> and Reporting</div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="16-viz">Visualization</a><a class="_chapter_title_1lnsy_32" href="17-eda">Exploratory data analysis</a><a class="_chapter_title_1lnsy_32" href="18-writing">Writing</a><a class="_chapter_title_1lnsy_32" href="19-meta">Meta-analysis</a><a class="_chapter_title_1lnsy_32" href="20-conclusions">Conclusions</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Appendices</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="A-git">GitHub Tutorial</a><a class="_chapter_title_1lnsy_32" href="B-rmarkdown">R Markdown Tutorial</a><a class="_chapter_title_1lnsy_32" href="C-tidyverse">Tidyverse Tutorial</a><a class="_chapter_title_1lnsy_32" href="D-ggplot">ggplot Tutorial</a><a class="_chapter_title_1lnsy_32" href="E-instructors">Instructor’s guide</a></div></div></nav></header>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="header">
<h1 class="title">Experimentology</h1>
<h3 class="subtitle"><em>An Open Science Approach to Experimental Psychology Methods</em></h3>
<h4 class="author"><em>Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams</em></h4>
</div>
<div id="section" class="section level1 unlisted unnumbered">
<h1 class="unlisted unnumbered"></h1>


<p>How do we create generalizable theories of human behavior? Experiments provide us a tool for measuring causal effects, which provide the basis for building theories. If we design these experiments appropriately, we can even begin to estimate generalizable relationships between different psychological constructs. But how do you design, execute, and analyze data from such an experiment?</p>
<p>This book provides an introduction to the workflow of the experimental researcher in the psychological sciences. The organization is sequential, from the planning stages of the research process through design, data collection, analysis, and reporting. We introduce these concepts via narrative examples from a range of sub-disciplines, including cognitive, developmental, and social psychology. Throughout, we also illustrate the pitfalls that led to the “replication crisis” in psychology. Across chapters, the book will emphasize four themes of successful experimental research: transparency, precision, bias reduction, and generalizability. The book takes an open-science based approach, providing readers with tutorials and justifications of practices such as preregistration, data sharing, and reproducible workflows. The audience for the book is graduate students, advanced undergraduates, or highly-motivated self-learners with some domain knowledge in psychology and a basic grasp of linear regression. For relevant chapters, examples will be presented using code from R (the free statistical programming language), Git (a version control system), and the Open Science Framework (a data sharing/preregistration site), and appendices will provide tutorials on these tools. The author group has collaborated for years in both teaching and research contexts and has broad expertise in experimental methods pedagogy as well as meta-science, statistical analysis and meta-analysis, and ethics. Our hope is that this book provides a practical introduction to how to do robust and replicable work as an experimental psychologist.</p>
<div id="introduction" class="section level2 unnumbered">
<h2>Introduction</h2>
<p>Experimental Methods (Psych 251) is the foundational course for incoming graduate students in the Stanford psychology department. For the last ten years, one of us (Frank) has taught this course and most of us (Hawkins, Cachia, Hardwicke, Mathur, Williams) have TA’d, taken, or otherwise contributed to the course. The goal is to orient students to the nuts and bolts of doing behavioral experiments, including how to plan and design a solid experiment and how to avoid common pitfalls regarding design, measurement, and sampling. Almost all of students’ coursework both before and in graduate school deals with the content of their research, including theories and results in their areas of focus. In contrast, the course is sometimes the only one that deals with the <em>process</em> of research, from big questions about why we do experiments and what it means to make a causal inference all the way to the tiny details of organization, like what to name your directories and how to make sure you don’t lose your data in a computer crash.</p>
<p>This observation leads to our book’s title. <strong>Experimentology</strong> is not psychology, cognitive science, or any other body of content knowledge – but rather the set of practices, findings, and approaches that help to enable the construction of robust, precise, and generalizable experiments.</p>
<p>The centerpiece of the Experimental Methods course is a replication project, a model first described in <span class="citation">Frank &amp; Saxe (<a href="#ref-frank2012" role="doc-biblioref">2012</a>)</span> and later expanded on in <span class="citation">Hawkins et al. (<a href="#ref-hawkins2018" role="doc-biblioref">2018</a>)</span>. Each student chooses a published experiment in the literature and collects new data on a pre-registered version of the same experimental paradigm, comparing their result to the original publication. Over the course of the quarter, we walk through how to set up a replication experiment, how to pre-register confirmatory analyses, and how to write a reproducible report on the findings. The project provides numerous object lessons for teaching concepts like reliability and validity, which allow students to analyze choices that the original experimenters made – often choices that could have been made differently in hindsight!</p>
<p>At the end of the course, we reap the harvest of projects. The project presentations are a wonderful demonstration of both how much the students can accomplish in a quarter and also how tricky it can be to reproduce (redo calculations in the original data) and replicate (recover similar results in new data) the published literature. Often our replication rate for the course hovers just above 50%, an outcome that can be disturbing or distressing for students who assume that the published literature reports the absolute truth!</p>
<p>In this book, we will tell the story of the major shifts in psychology that have come about in the last ten years, including both the “replication crisis” narrative <span class="citation">(<a href="#ref-osc2015" role="doc-biblioref">Open Science Collaboration, 2015</a> et seq.)</span> and the positive methodological reforms that have resulted from it. Using this story as motivation, we will highlight the importance of transparency during all aspects of the experimental process from planning to dissemination of materials, data, and code.</p>
</div>
<div id="what-this-book-is-and-isnt-about" class="section level2 unnumbered">
<h2>What this book is and isn’t about</h2>
<p>This book is about the process of doing simple randomized psychology experiments. These will be typically be short studies conducted online or in a single visit to a lab, often with a convenience population. We won’t go into depth about the many fascinating methodological and statistical issues brought up by single-participant case studies, longitudinal research, field studies, or other methodological variants. Many of the concerns we raise are still important for these types of studies, but some of our advice won’t transfer to these critical but more unusual cases.<label for="tufte-sn-1" class="margin-toggle sidenote-number">1</label><input type="checkbox" id="tufte-sn-1" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">1</span> For example, it’s hard to do a full pilot study on a two year longitudinal intervention!</span></p>
<p>In our writing, we presuppose that readers have some background in psychology, at least at an introductory level. We also presuppose a basic undergraduate statistics background so that we can draw on concepts like <em>distribution</em>, <em>mean</em>, and <em>standard deviation</em>, and basic tools like the <em>t-test</em> and the <em>correlation coefficient</em>. Finally, our examples are written in the R statistical programming language, and for chapters on statistics and visualization especially (Chapters <a href="6-inference.html#inference">6</a>, <a href="7-models.html#models">7</a>, <a href="16-viz.html#viz">16</a>, <a href="17-eda.html#eda">17</a>, and <a href="19-meta.html#meta">19</a>), some familiarity with R will be helpful. None of these prerequisites are strictly necessary, however – a bit of googling will often be enough to fill in any gap. Specific R skills like tidyverse and ggplot are covered in the Appendices.</p>
<p>Each chapter of the book will start with a narrative case study in which we describe an experiment or series of experiments, using these to illustrate and motivate the specific issues that the chapter deals with, often with a focus on pitfalls or challenges in previous research. These will draw from a broad set of subfields. In addition to narrative examples that begin the chapters, we include several other instructional elements with specific examples. Throughout we share “accident reports,” short cases drawn from the published literature where a particular practice led to an error or faulty inference. We also include “ethics boxes” where we discuss ethical issues arising from the content of a chapter.</p>
</div>
<div id="how-to-use-this-book" class="section level2 unnumbered">
<h2>How to use this book</h2>
<p>Experimentology is organized into five main sections, mirroring the timeline of an experiment: 1) Preliminaries, 2) Statistical Foundations, 3) Design and Planning, 4) Execution, 5) Analysis and Reporting. We hope that organization makes it well-suited for teaching or for use as a reference book for self-study, and we provide a number of resources for instructors of a graduate course (Appendix <a href="E-instructors.html#instructors">E</a>).</p>
<p>We also hope that some readers will come to specific chapters of the book because of an interest in specific topics like measurement (Chapter <a href="8-measurement.html#measurement">8</a>) or sampling (Chapter <a href="10-sampling.html#sampling">10</a>) and will be able to use those chapters as standalone references. And finally, for those interested in the “replication crisis” and reforms that have taken place in the behavioral sciences in the wake of it, Chapters <a href="2-theories.html#theories">2</a>, <a href="3-replication.html#replication">3</a>, <a href="12-prereg.html#prereg">12</a>, and <a href="16-viz.html#conclusion">16.3</a> will be especially interesting.</p>
<p><label for="tufte-mn-1" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-1" class="margin-toggle" /><span class="marginnote"><span style="display: block;">This book has fun stuff going on in the margins!
<img src="images/dog.jpeg" /></span></span></p>
<p>We want to give you what you need to plan and execute your own study! Instead of enumerating different approaches, we try to provide a single coherent – and often quite opinionated – perspective, using marginal notes and references to give pointers to more advanced materials or alternative approaches.</p>
</div>
<div id="themes" class="section level2 unnumbered">
<h2>Themes</h2>
<p>We try to highlight four major cross-cutting themes for the book: <strong>transparency</strong>, <strong>precision</strong>, <strong>bias reduction</strong>, and <strong>generalizability</strong>.</p>
<ul>
<li><strong>Transparency</strong>: For experiments to be reproducible, other researchers need to be able to determine exactly what you did. Thus, every stage of the research process should be guided by a primary concern for transparency. For example, preregistration creates transparency into the researcher’s evolving expectations and thought processes; releasing open materials and analysis scripts creates transparency into the details of the procedure.</li>
<li><strong>Precision</strong>: We want researchers to start planning an experiment by thinking “what causal effect do I want to measure” and to make their planning, sampling, design, and analytic choices to maximize the precision of this measurement. A downstream consequence of this mindset is that we move away from a focus on dichotomized inference, like p-value significance, and towards analytic and meta-analytic models that focus on continuous effect sizes and confidence intervals (Cumming 2014).</li>
<li><strong>Bias reduction</strong>: Precision is not enough if the estimate is biased. In our samples, analyses, experimental designs, and in the literature, we need to think carefully about sources of bias in the quantity being estimated. This kind of thinking also reveals key weaknesses of dichotomous, “significance”-based reasoning.</li>
<li><strong>Generalizability</strong>: Complex behaviors are rarely universal across all settings and populations, and any given experiment can only hope to cover a small slice of the possible conditions where the behavior takes place (Yarkoni 2020). Behavioral scientists must therefore consider the generalizability of their findings at every stage of the process, from stimulus selection, sampling procedures, and analytic methods, to how findings are reported.</li>
</ul>
<p>Throughout we will return to the important relationships between these four concepts, and how the decisions made by the experimenter at every stage of design, data collection, and analysis bear on the inferences that can be made about the results. Importantly, discussions of reproducibility and replicability have often proceeded without consideration of issues like precision, bias reduction, and generalizability, leading to a number of deep critiques of the methodological reform movement that we will cover in some detail.</p>
</div>
<div id="the-software-toolkit-of-the-behavioral-researcher-and-of-this-book" class="section level2 unnumbered">
<h2>The software toolkit of the behavioral researcher (and of this book)</h2>
<p>We introduce and advocate for an approach to reproducible study planning, analysis, and writing. This approach depends on an ecosystem of open-source software tools.</p>
<ul>
<li>The R statistical programming language and the <a href="http://rstudio.org">R Studio</a> integrated development environment. R is a free and open platform for statistical programming. Because of its large userbase, almost all extent analysis and visualization methods are implemented in packages that can be downloaded from <a href="https://cran.r-project.org">CRAN</a>, the comprehensive R archive network,</li>
<li>The <code>tidyverse</code> family of R packages, which extend the basic functionality of R with simple tools for data wrangling, analysis, and visualization (including the <code>ggplot2</code> package).</li>
<li>Version control using <code>git</code> and <a href="http://github.com">GitHub</a>. Version control tools allow one or more users to collaborate on text documents like code, prose, and data, storing and integrating contributions over time. The GitHub provides a centralized hosting and project management platform for version-controlled projects, making it ideal for collaboration and dissemination.<br />
</li>
<li>While GitHub is an excellent real-time collaboration platform, it does not provide archival guarantees or the ability to provide time-stamped registrations of projects. For these functions, we use the <a href="http://osf.io">Open Science Framework</a>, a project management platform designed for scientific projects.</li>
</ul>





</div>
</div>



<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-frank2012" class="csl-entry">
Frank, M. C., &amp; Saxe, R. (2012). Teaching replication. <em>Perspectives on Psychological Science</em>, <em>7</em>, 595–599.
</div>
<div id="ref-hawkins2018" class="csl-entry">
Hawkins, R. X. D., Smith, E. N., Au, C., Arias, J. M., Catapano, R., Hermann, E., Keil, M., Lampinen, A., Raposo, S., Reynolds, J., Salehi, S., Salloum, J., Tan, J., &amp; Frank, M. C. (2018). Improving the replicability of psychological science through pedagogy. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(1), 7–18.
</div>
<div id="ref-osc2015" class="csl-entry">
Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. <em>Science</em>, <em>349</em>(6251).
</div>
</div>

</div>
</div>




<script type="module" src="/assets/src/index.page.client.jsx.df9edbd0.js"></script><script id="vite-plugin-ssr_pageContext" type="application/json">{"pageContext":{"_pageId":"/src/index","url":"/","body":"\n\n\n\n\u003cdiv class=\"row\">\n\u003cdiv class=\"col-sm-12\">\n\u003cdiv id=\"TOC\">\n\u003cul>\n\u003cli>\u003ca href=\"#part-preliminaries\" id=\"toc-part-preliminaries\">(PART) Preliminaries\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"1-experiments.html#experiments\" id=\"toc-experiments\">\u003cspan class=\"toc-section-number\">1\u003c/span> Experiments\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"2-theories.html#theories\" id=\"toc-theories\">\u003cspan class=\"toc-section-number\">2\u003c/span> Theories\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"3-replication.html#replication\" id=\"toc-replication\">\u003cspan class=\"toc-section-number\">3\u003c/span> Replication and reproducibility\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"4-ethics.html#ethics\" id=\"toc-ethics\">\u003cspan class=\"toc-section-number\">4\u003c/span> Ethics\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-statistics\" id=\"toc-part-statistics\">(PART) Statistics\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"5-estimation.html#estimation\" id=\"toc-estimation\">\u003cspan class=\"toc-section-number\">5\u003c/span> Estimation\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"6-inference.html#inference\" id=\"toc-inference\">\u003cspan class=\"toc-section-number\">6\u003c/span> Inference\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"7-models.html#models\" id=\"toc-models\">\u003cspan class=\"toc-section-number\">7\u003c/span> Models\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-design-and-planning\" id=\"toc-part-design-and-planning\">(PART) Design and Planning\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"8-measurement.html#measurement\" id=\"toc-measurement\">\u003cspan class=\"toc-section-number\">8\u003c/span> Measurement\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"9-design.html#design\" id=\"toc-design\">\u003cspan class=\"toc-section-number\">9\u003c/span> Design of experiments\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"10-sampling.html#sampling\" id=\"toc-sampling\">\u003cspan class=\"toc-section-number\">10\u003c/span> Sampling\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"11-strategy.html#strategy\" id=\"toc-strategy\">\u003cspan class=\"toc-section-number\">11\u003c/span> Experimental strategy\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-execution\" id=\"toc-part-execution\">(PART) Execution\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"12-prereg.html#prereg\" id=\"toc-prereg\">\u003cspan class=\"toc-section-number\">12\u003c/span> Preregistration\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"13-consent.html#consent\" id=\"toc-consent\">\u003cspan class=\"toc-section-number\">13\u003c/span> Recruitment and Consent\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"14-collection.html#collection\" id=\"toc-collection\">\u003cspan class=\"toc-section-number\">14\u003c/span> Data collection\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"15-management.html#management\" id=\"toc-management\">\u003cspan class=\"toc-section-number\">15\u003c/span> Project management\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-analysis-and-reporting\" id=\"toc-part-analysis-and-reporting\">(PART) Analysis and Reporting\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"16-viz.html#viz\" id=\"toc-viz\">\u003cspan class=\"toc-section-number\">16\u003c/span> Visualization\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"17-eda.html#eda\" id=\"toc-eda\">\u003cspan class=\"toc-section-number\">17\u003c/span> Exploratory data analysis\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"18-writing.html#writing\" id=\"toc-writing\">\u003cspan class=\"toc-section-number\">18\u003c/span> Writing\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"19-meta.html#meta\" id=\"toc-meta\">\u003cspan class=\"toc-section-number\">19\u003c/span> Meta-analysis\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"20-conclusions.html#conclusions\" id=\"toc-conclusions\">\u003cspan class=\"toc-section-number\">20\u003c/span> Conclusions\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#appendix-appendices\" id=\"toc-appendix-appendices\">(APPENDIX) Appendices\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"A-git.html#git\" id=\"toc-git\">\u003cspan class=\"toc-section-number\">21\u003c/span> GitHub Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"B-rmarkdown.html#rmarkdown\" id=\"toc-rmarkdown\">\u003cspan class=\"toc-section-number\">22\u003c/span> R Markdown Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"C-tidyverse.html#tidyverse\" id=\"toc-tidyverse\">\u003cspan class=\"toc-section-number\">23\u003c/span> Tidyverse Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"D-ggplot.html#ggplot\" id=\"toc-ggplot\">\u003cspan class=\"toc-section-number\">24\u003c/span> ggplot Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"E-instructors.html#instructors\" id=\"toc-instructors\">\u003cspan class=\"toc-section-number\">25\u003c/span> Instructor’s guide\u003c/a>\u003c/li>\n\u003c/ul>\n\u003c/div>\n\u003c/div>\n\u003c/div>\n\u003cdiv class=\"row\">\n\u003cdiv class=\"col-sm-12\">\n\u003cdiv id=\"header\">\n\u003ch1 class=\"title\">Experimentology\u003c/h1>\n\u003ch3 class=\"subtitle\">\u003cem>An Open Science Approach to Experimental Psychology Methods\u003c/em>\u003c/h3>\n\u003ch4 class=\"author\">\u003cem>Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams\u003c/em>\u003c/h4>\n\u003c/div>\n\u003cdiv id=\"section\" class=\"section level1 unlisted unnumbered\">\n\u003ch1 class=\"unlisted unnumbered\">\u003c/h1>\n\u003c!-- ## Summary {-} -->\n\u003c!-- biblio-style: apalike -->\n\u003cp>How do we create generalizable theories of human behavior? Experiments provide us a tool for measuring causal effects, which provide the basis for building theories. If we design these experiments appropriately, we can even begin to estimate generalizable relationships between different psychological constructs. But how do you design, execute, and analyze data from such an experiment?\u003c/p>\n\u003cp>This book provides an introduction to the workflow of the experimental researcher in the psychological sciences. The organization is sequential, from the planning stages of the research process through design, data collection, analysis, and reporting. We introduce these concepts via narrative examples from a range of sub-disciplines, including cognitive, developmental, and social psychology. Throughout, we also illustrate the pitfalls that led to the “replication crisis” in psychology. Across chapters, the book will emphasize four themes of successful experimental research: transparency, precision, bias reduction, and generalizability. The book takes an open-science based approach, providing readers with tutorials and justifications of practices such as preregistration, data sharing, and reproducible workflows. The audience for the book is graduate students, advanced undergraduates, or highly-motivated self-learners with some domain knowledge in psychology and a basic grasp of linear regression. For relevant chapters, examples will be presented using code from R (the free statistical programming language), Git (a version control system), and the Open Science Framework (a data sharing/preregistration site), and appendices will provide tutorials on these tools. The author group has collaborated for years in both teaching and research contexts and has broad expertise in experimental methods pedagogy as well as meta-science, statistical analysis and meta-analysis, and ethics. Our hope is that this book provides a practical introduction to how to do robust and replicable work as an experimental psychologist.\u003c/p>\n\u003cdiv id=\"introduction\" class=\"section level2 unnumbered\">\n\u003ch2>Introduction\u003c/h2>\n\u003cp>Experimental Methods (Psych 251) is the foundational course for incoming graduate students in the Stanford psychology department. For the last ten years, one of us (Frank) has taught this course and most of us (Hawkins, Cachia, Hardwicke, Mathur, Williams) have TA’d, taken, or otherwise contributed to the course. The goal is to orient students to the nuts and bolts of doing behavioral experiments, including how to plan and design a solid experiment and how to avoid common pitfalls regarding design, measurement, and sampling. Almost all of students’ coursework both before and in graduate school deals with the content of their research, including theories and results in their areas of focus. In contrast, the course is sometimes the only one that deals with the \u003cem>process\u003c/em> of research, from big questions about why we do experiments and what it means to make a causal inference all the way to the tiny details of organization, like what to name your directories and how to make sure you don’t lose your data in a computer crash.\u003c/p>\n\u003cp>This observation leads to our book’s title. \u003cstrong>Experimentology\u003c/strong> is not psychology, cognitive science, or any other body of content knowledge – but rather the set of practices, findings, and approaches that help to enable the construction of robust, precise, and generalizable experiments.\u003c/p>\n\u003cp>The centerpiece of the Experimental Methods course is a replication project, a model first described in \u003cspan class=\"citation\">Frank &amp; Saxe (\u003ca href=\"#ref-frank2012\" role=\"doc-biblioref\">2012\u003c/a>)\u003c/span> and later expanded on in \u003cspan class=\"citation\">Hawkins et al. (\u003ca href=\"#ref-hawkins2018\" role=\"doc-biblioref\">2018\u003c/a>)\u003c/span>. Each student chooses a published experiment in the literature and collects new data on a pre-registered version of the same experimental paradigm, comparing their result to the original publication. Over the course of the quarter, we walk through how to set up a replication experiment, how to pre-register confirmatory analyses, and how to write a reproducible report on the findings. The project provides numerous object lessons for teaching concepts like reliability and validity, which allow students to analyze choices that the original experimenters made – often choices that could have been made differently in hindsight!\u003c/p>\n\u003cp>At the end of the course, we reap the harvest of projects. The project presentations are a wonderful demonstration of both how much the students can accomplish in a quarter and also how tricky it can be to reproduce (redo calculations in the original data) and replicate (recover similar results in new data) the published literature. Often our replication rate for the course hovers just above 50%, an outcome that can be disturbing or distressing for students who assume that the published literature reports the absolute truth!\u003c/p>\n\u003cp>In this book, we will tell the story of the major shifts in psychology that have come about in the last ten years, including both the “replication crisis” narrative \u003cspan class=\"citation\">(\u003ca href=\"#ref-osc2015\" role=\"doc-biblioref\">Open Science Collaboration, 2015\u003c/a> et seq.)\u003c/span> and the positive methodological reforms that have resulted from it. Using this story as motivation, we will highlight the importance of transparency during all aspects of the experimental process from planning to dissemination of materials, data, and code.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"what-this-book-is-and-isnt-about\" class=\"section level2 unnumbered\">\n\u003ch2>What this book is and isn’t about\u003c/h2>\n\u003cp>This book is about the process of doing simple randomized psychology experiments. These will be typically be short studies conducted online or in a single visit to a lab, often with a convenience population. We won’t go into depth about the many fascinating methodological and statistical issues brought up by single-participant case studies, longitudinal research, field studies, or other methodological variants. Many of the concerns we raise are still important for these types of studies, but some of our advice won’t transfer to these critical but more unusual cases.\u003clabel for=\"tufte-sn-1\" class=\"margin-toggle sidenote-number\">1\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-1\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">1\u003c/span> For example, it’s hard to do a full pilot study on a two year longitudinal intervention!\u003c/span>\u003c/p>\n\u003cp>In our writing, we presuppose that readers have some background in psychology, at least at an introductory level. We also presuppose a basic undergraduate statistics background so that we can draw on concepts like \u003cem>distribution\u003c/em>, \u003cem>mean\u003c/em>, and \u003cem>standard deviation\u003c/em>, and basic tools like the \u003cem>t-test\u003c/em> and the \u003cem>correlation coefficient\u003c/em>. Finally, our examples are written in the R statistical programming language, and for chapters on statistics and visualization especially (Chapters \u003ca href=\"6-inference.html#inference\">6\u003c/a>, \u003ca href=\"7-models.html#models\">7\u003c/a>, \u003ca href=\"16-viz.html#viz\">16\u003c/a>, \u003ca href=\"17-eda.html#eda\">17\u003c/a>, and \u003ca href=\"19-meta.html#meta\">19\u003c/a>), some familiarity with R will be helpful. None of these prerequisites are strictly necessary, however – a bit of googling will often be enough to fill in any gap. Specific R skills like tidyverse and ggplot are covered in the Appendices.\u003c/p>\n\u003cp>Each chapter of the book will start with a narrative case study in which we describe an experiment or series of experiments, using these to illustrate and motivate the specific issues that the chapter deals with, often with a focus on pitfalls or challenges in previous research. These will draw from a broad set of subfields. In addition to narrative examples that begin the chapters, we include several other instructional elements with specific examples. Throughout we share “accident reports,” short cases drawn from the published literature where a particular practice led to an error or faulty inference. We also include “ethics boxes” where we discuss ethical issues arising from the content of a chapter.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"how-to-use-this-book\" class=\"section level2 unnumbered\">\n\u003ch2>How to use this book\u003c/h2>\n\u003cp>Experimentology is organized into five main sections, mirroring the timeline of an experiment: 1) Preliminaries, 2) Statistical Foundations, 3) Design and Planning, 4) Execution, 5) Analysis and Reporting. We hope that organization makes it well-suited for teaching or for use as a reference book for self-study, and we provide a number of resources for instructors of a graduate course (Appendix \u003ca href=\"E-instructors.html#instructors\">E\u003c/a>).\u003c/p>\n\u003cp>We also hope that some readers will come to specific chapters of the book because of an interest in specific topics like measurement (Chapter \u003ca href=\"8-measurement.html#measurement\">8\u003c/a>) or sampling (Chapter \u003ca href=\"10-sampling.html#sampling\">10\u003c/a>) and will be able to use those chapters as standalone references. And finally, for those interested in the “replication crisis” and reforms that have taken place in the behavioral sciences in the wake of it, Chapters \u003ca href=\"2-theories.html#theories\">2\u003c/a>, \u003ca href=\"3-replication.html#replication\">3\u003c/a>, \u003ca href=\"12-prereg.html#prereg\">12\u003c/a>, and \u003ca href=\"16-viz.html#conclusion\">16.3\u003c/a> will be especially interesting.\u003c/p>\n\u003cp>\u003clabel for=\"tufte-mn-1\" class=\"margin-toggle\">⊕\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-mn-1\" class=\"margin-toggle\">\u003cspan class=\"marginnote\">\u003cspan style=\"display: block;\">This book has fun stuff going on in the margins!\n\u003cimg src=\"images/dog.jpeg\"/>\u003c/span>\u003c/span>\u003c/p>\n\u003cp>We want to give you what you need to plan and execute your own study! Instead of enumerating different approaches, we try to provide a single coherent – and often quite opinionated – perspective, using marginal notes and references to give pointers to more advanced materials or alternative approaches.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"themes\" class=\"section level2 unnumbered\">\n\u003ch2>Themes\u003c/h2>\n\u003cp>We try to highlight four major cross-cutting themes for the book: \u003cstrong>transparency\u003c/strong>, \u003cstrong>precision\u003c/strong>, \u003cstrong>bias reduction\u003c/strong>, and \u003cstrong>generalizability\u003c/strong>.\u003c/p>\n\u003cul>\n\u003cli>\u003cstrong>Transparency\u003c/strong>: For experiments to be reproducible, other researchers need to be able to determine exactly what you did. Thus, every stage of the research process should be guided by a primary concern for transparency. For example, preregistration creates transparency into the researcher’s evolving expectations and thought processes; releasing open materials and analysis scripts creates transparency into the details of the procedure.\u003c/li>\n\u003cli>\u003cstrong>Precision\u003c/strong>: We want researchers to start planning an experiment by thinking “what causal effect do I want to measure” and to make their planning, sampling, design, and analytic choices to maximize the precision of this measurement. A downstream consequence of this mindset is that we move away from a focus on dichotomized inference, like p-value significance, and towards analytic and meta-analytic models that focus on continuous effect sizes and confidence intervals (Cumming 2014).\u003c/li>\n\u003cli>\u003cstrong>Bias reduction\u003c/strong>: Precision is not enough if the estimate is biased. In our samples, analyses, experimental designs, and in the literature, we need to think carefully about sources of bias in the quantity being estimated. This kind of thinking also reveals key weaknesses of dichotomous, “significance”-based reasoning.\u003c/li>\n\u003cli>\u003cstrong>Generalizability\u003c/strong>: Complex behaviors are rarely universal across all settings and populations, and any given experiment can only hope to cover a small slice of the possible conditions where the behavior takes place (Yarkoni 2020). Behavioral scientists must therefore consider the generalizability of their findings at every stage of the process, from stimulus selection, sampling procedures, and analytic methods, to how findings are reported.\u003c/li>\n\u003c/ul>\n\u003cp>Throughout we will return to the important relationships between these four concepts, and how the decisions made by the experimenter at every stage of design, data collection, and analysis bear on the inferences that can be made about the results. Importantly, discussions of reproducibility and replicability have often proceeded without consideration of issues like precision, bias reduction, and generalizability, leading to a number of deep critiques of the methodological reform movement that we will cover in some detail.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"the-software-toolkit-of-the-behavioral-researcher-and-of-this-book\" class=\"section level2 unnumbered\">\n\u003ch2>The software toolkit of the behavioral researcher (and of this book)\u003c/h2>\n\u003cp>We introduce and advocate for an approach to reproducible study planning, analysis, and writing. This approach depends on an ecosystem of open-source software tools.\u003c/p>\n\u003cul>\n\u003cli>The R statistical programming language and the \u003ca href=\"http://rstudio.org\">R Studio\u003c/a> integrated development environment. R is a free and open platform for statistical programming. Because of its large userbase, almost all extent analysis and visualization methods are implemented in packages that can be downloaded from \u003ca href=\"https://cran.r-project.org\">CRAN\u003c/a>, the comprehensive R archive network,\u003c/li>\n\u003cli>The \u003ccode>tidyverse\u003c/code> family of R packages, which extend the basic functionality of R with simple tools for data wrangling, analysis, and visualization (including the \u003ccode>ggplot2\u003c/code> package).\u003c/li>\n\u003cli>Version control using \u003ccode>git\u003c/code> and \u003ca href=\"http://github.com\">GitHub\u003c/a>. Version control tools allow one or more users to collaborate on text documents like code, prose, and data, storing and integrating contributions over time. The GitHub provides a centralized hosting and project management platform for version-controlled projects, making it ideal for collaboration and dissemination.\u003cbr />\n\u003c/li>\n\u003cli>While GitHub is an excellent real-time collaboration platform, it does not provide archival guarantees or the ability to provide time-stamped registrations of projects. For these functions, we use the \u003ca href=\"http://osf.io\">Open Science Framework\u003c/a>, a project management platform designed for scientific projects.\u003c/li>\n\u003c/ul>\n\u003c!-- ## Integrating this book into an experimental methods course {-} -->\n\u003c!-- The project-based approach (argument for doing replication/reproducibility study as part of learning methods)  -->\n\u003c!-- Each chapter ends with a mixture of discussion questions, exercises, and project milestones that can be integrated into course assignments.  -->\n\u003c!-- We include links to appendices, references, and recurring boxes with ethical content and ‘accident reports’ from documented problems in the literature.  -->\n\n\u003c/div>\n\u003c/div>\n\n\n\n\u003ch3>References\u003c/h3>\n\u003cdiv id=\"refs\" class=\"references csl-bib-body hanging-indent\" line-spacing=\"2\">\n\u003cdiv id=\"ref-frank2012\" class=\"csl-entry\">\nFrank, M. C., &amp; Saxe, R. (2012). Teaching replication. \u003cem>Perspectives on Psychological Science\u003c/em>, \u003cem>7\u003c/em>, 595–599.\n\u003c/div>\n\u003cdiv id=\"ref-hawkins2018\" class=\"csl-entry\">\nHawkins, R. X. D., Smith, E. N., Au, C., Arias, J. M., Catapano, R., Hermann, E., Keil, M., Lampinen, A., Raposo, S., Reynolds, J., Salehi, S., Salloum, J., Tan, J., &amp; Frank, M. C. (2018). Improving the replicability of psychological science through pedagogy. \u003cem>Advances in Methods and Practices in Psychological Science\u003c/em>, \u003cem>1\u003c/em>(1), 7–18.\n\u003c/div>\n\u003cdiv id=\"ref-osc2015\" class=\"csl-entry\">\nOpen Science Collaboration. (2015). Estimating the reproducibility of psychological science. \u003cem>Science\u003c/em>, \u003cem>349\u003c/em>(6251).\n\u003c/div>\n\u003c/div>\n\u003cp style=\"text-align: center;\">\n\u003ca href=\"1-experiments.html\">\u003cbutton class=\"btn btn-default\">Next\u003c/button>\u003c/a>\n\u003c/p>\n\u003c/div>\n\u003c/div>\n\n\n\n"}}</script></body>

</html>