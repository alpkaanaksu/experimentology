<!DOCTYPE html>
<html>

<head>


<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 14 Data collection | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 14 Data collection | Experimentology">

<title>Chapter 14 Data collection | Experimentology</title>

<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.21/datatables.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>



<link rel="stylesheet" type="text/css" href="/assets/index.page.c5e7dffa.css"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/src/index.page.client.jsx.df9edbd0.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/contents.b9575bfb.js"></head>

<body>




<div class="row">
<div class="col-sm-12">
<header class="_toc_1lnsy_1" id="toc"><a class="_book_title_1lnsy_24" href="/">Experimentology: An Open Science Approach to Experimental Psychology Methods</a><nav><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Preliminaries</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="1-experiments">Experiments</a><a class="_chapter_title_1lnsy_32" href="2-theories">Theories</a><a class="_chapter_title_1lnsy_32" href="3-replication">Replication and reproducibility</a><a class="_chapter_title_1lnsy_32" href="4-ethics">Ethics</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Statistics</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="5-estimation">Estimation</a><a class="_chapter_title_1lnsy_32" href="6-inference">Inference</a><a class="_chapter_title_1lnsy_32" href="7-models">Models</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Design</div><div class="_part_title_rest_1lnsy_32"> and Planning</div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="8-measurement">Measurement</a><a class="_chapter_title_1lnsy_32" href="9-design">Design of experiments</a><a class="_chapter_title_1lnsy_32" href="10-sampling">Sampling</a><a class="_chapter_title_1lnsy_32" href="11-strategy">Experimental strategy</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Execution</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="12-prereg">Preregistration</a><a class="_chapter_title_1lnsy_32" href="13-consent">Recruitment and Consent</a><a class="_chapter_title_1lnsy_32" href="14-collection">Data collection</a><a class="_chapter_title_1lnsy_32" href="15-management">Project management</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Analysis</div><div class="_part_title_rest_1lnsy_32"> and Reporting</div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="16-viz">Visualization</a><a class="_chapter_title_1lnsy_32" href="17-eda">Exploratory data analysis</a><a class="_chapter_title_1lnsy_32" href="18-writing">Writing</a><a class="_chapter_title_1lnsy_32" href="19-meta">Meta-analysis</a><a class="_chapter_title_1lnsy_32" href="20-conclusions">Conclusions</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Appendices</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="A-git">GitHub Tutorial</a><a class="_chapter_title_1lnsy_32" href="B-rmarkdown">R Markdown Tutorial</a><a class="_chapter_title_1lnsy_32" href="C-tidyverse">Tidyverse Tutorial</a><a class="_chapter_title_1lnsy_32" href="D-ggplot">ggplot Tutorial</a><a class="_chapter_title_1lnsy_32" href="E-instructors">Instructor’s guide</a></div></div></nav></header>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="collection" class="section level1" number="14">
<h1><span class="header-section-number">Chapter 14</span> Data collection</h1>
<div class="box learning_goals"><div class="Collapsible"><span id="collapsible-trigger-1654141393439" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1654141393439" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="apple-whole" class="svg-inline--fa fa-apple-whole " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M336 128c-32 0-80.02 16.03-112 32.03c-32.01-16-79.1-32.02-111.1-32.03C32 128 .4134 210.5 .0033 288c-.5313 99.97 63.99 224 159.1 224c32 0 48-16 64-16c16 0 32 16 64 16c96 0 160.4-122.8 159.1-224C447.7 211.6 416 128 336 128zM320 32V0h-32C243.8 0 208 35.82 208 80v32h32C284.2 112 320 76.18 320 32z"></path></svg>Learning goals<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M169.4 278.6C175.6 284.9 183.8 288 192 288s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25s-32.75-12.5-45.25 0L192 210.8L54.63 73.38c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25L169.4 278.6zM329.4 265.4L192 402.8L54.63 265.4c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25l160 160C175.6 476.9 183.8 480 192 480s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25S341.9 252.9 329.4 265.4z"></path></svg></span><div id="collapsible-content-1654141393439" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1654141393439"><div class="Collapsible__contentInner">
<ul>
<li>Review best practices for online and in person data collection</li>
<li>Implement data integrity checks, manipulation checks, and pilot testing</li>
</ul>
</div></div></div></div>
<p>You have selected your measure and manipulation and planned your sample. Your preregistration is set. You have gone through your recruitment and ethics. Now it’s time to think about the nuts and bolts of collecting data.</p>
<p>While the details of data collection may vary from context to context and sample to sample, this chapter will highlight some general best practices for the data collection process. We organize these practices around two goals. The first section is participant-centric: we review some concerns regarding how to provide a positive experience for participants in both in-person and online experiments. Then in the second section, we discuss the data collection process from the perspective of the experimenter, covering some best practices</p>
<div class="box case_study"><div class="Collapsible"><span id="collapsible-trigger-1654141393439" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1654141393439" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="microscope" class="svg-inline--fa fa-microscope " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M160 320h12v16c0 8.875 7.125 16 16 16h40c8.875 0 16-7.125 16-16V320H256c17.62 0 32-14.38 32-32V64c0-17.62-14.38-32-32-32V16C256 7.125 248.9 0 240 0h-64C167.1 0 160 7.125 160 16V32C142.4 32 128 46.38 128 64v224C128 305.6 142.4 320 160 320zM464 448h-1.25C493.2 414 512 369.2 512 320c0-105.9-86.13-192-192-192v64c70.63 0 128 57.38 128 128s-57.38 128-128 128H48C21.5 448 0 469.5 0 496C0 504.9 7.125 512 16 512h480c8.875 0 16-7.125 16-16C512 469.5 490.5 448 464 448zM104 416h208c4.375 0 8-3.625 8-8v-16c0-4.375-3.625-8-8-8h-208C99.63 384 96 387.6 96 392v16C96 412.4 99.63 416 104 416z"></path></svg>Case study<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M169.4 278.6C175.6 284.9 183.8 288 192 288s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25s-32.75-12.5-45.25 0L192 210.8L54.63 73.38c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25L169.4 278.6zM329.4 265.4L192 402.8L54.63 265.4c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25l160 160C175.6 476.9 183.8 480 192 480s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25S341.9 252.9 329.4 265.4z"></path></svg></span><div id="collapsible-content-1654141393439" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1654141393439"><div class="Collapsible__contentInner"><p class="title">The rise of online data collection</p>
<p></p>
<p>Since the rise of experimental psychology laboratories in university settings during the period after World War 2 <span class="citation">(<a href="#ref-benjamin-jr2000" role="doc-biblioref">Benjamin Jr, 2000</a>)</span>, experiments have typically been conducted by recruiting participants from what has been referred to as the “subject pool.” This term denotes a group of people who can be recruited for experiments, typically students from introductory psychology courses <span class="citation">(<a href="#ref-sieber1989" role="doc-biblioref">Sieber &amp; Saks, 1989</a>)</span> recruited via the requirement that students complete a certain quantity of experiments as part of their course work.<label for="tufte-sn-166" class="margin-toggle sidenote-number">166</label><input type="checkbox" id="tufte-sn-166" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">166</span> At various times, students have raised ethical concerns about these requirements as being coercive of participationin precisely the way that should be off limits for psychology experiments (see Chapter <a href="4-ethics.html#ethics">4</a>). As a result, most programs now provide some more or less onerous alternative to participation.</span> The ready availability of this convenience population led inevitably to the massive over-representation of US undergraduates in published psychology research, leading to persistent critiques of this practice for the generalizability of research <span class="citation">(<a href="#ref-sears1986" role="doc-biblioref">Sears, 1986</a>; <a href="#ref-henrich2012" role="doc-biblioref"><strong>henrich2012?</strong></a>)</span>.</p>
<p>Yet in the period 2005–2015, there has been a revolution in data collection from convenience populations. Instead of focusing on university undergraduates, increasingly, published psychology work uses convenience samples of online workers recruited from crowdsourcing sites like Amazon Mechanical Turk (AMT). Originally designed to distribute micropayments to workers for business purposes like retyping reciepts, these services have become marketplaces to connect researchers with research participants who are willing to complete surveys and experimental tasks for small payments. As of 2015, more than a third of studies in top social and personality psychology journals were conducted on crowdsourcing platforms (another third were still conducted with college undergraduates) <span class="citation">(<a href="#ref-anderson2019" role="doc-biblioref">C. A. Anderson et al., 2019</a>)</span> and this proportion is likely continuing to grow.</p>
<p>Online data collection</p>
<p><span class="citation">(<a href="#ref-buhrmester2016" role="doc-biblioref">Buhrmester et al., 2016</a>; <a href="#ref-mason2016" role="doc-biblioref"><strong>mason2016?</strong></a>)</span></p>
<p>Crump et al. (2013) show through a set of beautiful experiments designed in the web browser how online data collection can replicate effects initially found in the lab.</p>
</div></div></div></div>
<div id="the-participants-perspective" class="section level2" number="14.1">
<h2><span class="header-section-number">14.1</span> The participant’s perspective</h2>
<div id="data-collection-in-person" class="section level3" number="14.1.1">
<h3><span class="header-section-number">14.1.1</span> Data collection in person</h3>
</div>
<div id="data-collection-online" class="section level3" number="14.1.2">
<h3><span class="header-section-number">14.1.2</span> Data collection online</h3>
<p>Online data collection is increasingly ubiquitous in the behavioral sciences. Further, the web browser – alongside survey software like Qualtrics – can be a major aid to transparency in sharing experimental materials.</p>
<ul>
<li>Validating the process of collecting data online. We briefly review studies suggesting that for general data collection across many paradigms, online data collection is valid.</li>
<li>When is online not enough? We describe cases where in-person data collection is necessary, highlighting psychophysical and physiological measurement and social interaction as two common classes of experiments that still cannot be done effectively online.</li>
</ul>
<p>Class MTurk Guidelines
Intro
In this class we will be running our replication projects on Amazon’s Mechanical Turk (AMT/mTurk). mTurk is a platform on which Workers (or “Turkers”) can complete Human Intelligence Tasks (HITs) for monetary compensation. HITs are put up by Requesters. mTurk originally was set up to do large-scale tasks that require human intelligence (e.g. labeling photos, finding telephone numbers, etc), but has recently been used by social scientists to conduct (large-scale) online experiments.</p>
<p>In this class, all replication projects will be launched using a common class account. This saves you the hassle of applying for a personal Requester account (which lately has become not-as-straightforward…), and also simplifies funding logistics. We will be giving more detailed instructions in class on how to access the class account and launch HITs etc.</p>
<p>General notes to keep in mind:</p>
<p>Many Turkers multi-task and do tens of HITs for many hours a day, so design your study with this in mind. Include appropriate attention checks, manipulation checks, and exclusion criteria (depending on the original study design as well).
Amazon worker IDs are actually tied to their (public) Amazon account and thus constitute identifiable information. Keep Turk IDs and all other identifiable information private. Anonymize all data before pushing to your git project repo, especially if your repo is public. There are useful tools for quickly automatically anonymizing IDs so reach out to the TAs if you want help with this!
Do all analyses on anonymized data. (This is to prevent cases where others are unable to reproduce your analyses because it might rely somehow on identifiable information. If you start with anonymized data, your analyses would never use any of this information.)
Resources
Beginner:
A gentle guide to MTurk (Links to an external site.)
Guide to Mturk basics (Links to an external site.)
MTurkers are people (Links to an external site.) (&amp; the problem with common paradigms on MTurk)
Survey within MTurk platform (Links to an external site.)
Qualtrics Link (Links to an external site.)
Intermediate:
Turker Nation (Links to an external site.): Discussion board for Turkers
Creating a launch page to external site (Links to an external site.): advantage is that your study is embedded within MTurk, then opens a full page window for your task when required. Note launcher.html and task.html are separate.
Getting around the ridiculous extra 20% fee for 9+ participants (Links to an external site.)
MTurk fee structure (Links to an external site.) (Links to an external site.)
IRB
We have approval under protocol #IRB-23274Links to an external site.: “Reproducibility of psychological science and instruction.”</p>
<p>Before running your study, you will need to complete a short CITI human subjects training if you have not already. (See assignment).</p>
<p>Please include the following text on the first page / consent form of your study:</p>
<p>By answering the following questions, you are participating in a study being performed by cognitive scientists in the Stanford Department of Psychology. If you have questions about this research, please contact us at <a href="mailto:stanfordpsych251@gmail.com" class="email">stanfordpsych251@gmail.com</a>. You must be at least 18 years old to participate. Your participation in this research is voluntary. You may decline to answer any or all of the following questions. You may decline further participation, at any time, without adverse consequences. Your anonymity is assured; the researchers who have requested your participation will not receive any personal information about you. We have recently been made aware that your public Amazon.com profile can be accessed via your worker ID if you do not choose to opt out. If you would like to opt out of this feature, you may follow instructions available here (Links to an external site.).</p>
<p>Please include a short debriefing in your experiment, thanking the participant, explaining in 2-4 lines what your study was about, and asking them not to share this information with other potential participants.</p>
<p>Additional notes on MTurk
Communicating with participants</p>
<p>When you are running either Pilot B or your actual study, please keep this gmail window open and monitor traffic on it.
If you get complaints about your study, please address them courteously and quickly (ideally, within a few hours). Turkers can be very helpful if you are responsive. Always assure them that they will be paid for their work.
Payment policies</p>
<p>When in doubt as to technical issues, pay the Turker. The TAs can help you bonus those who had technical issues with the experiment or completion code!
If a Turker seems especially difficult, then please bring their complaint to the attention of the course team. Turkers can potentially complain to IRB so err on the side of doing this more frequently if you have issues.</p>
<div class="box ethical_considerations"><div class="Collapsible"><span id="collapsible-trigger-1654141393439" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1654141393439" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="leaf" class="svg-inline--fa fa-leaf " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M512 165.4c0 127.9-70.05 235.3-175.3 270.1c-20.04 7.938-41.83 12.46-64.69 12.46c-64.9 0-125.2-36.51-155.7-94.47c-54.13 49.93-68.71 107-68.96 108.1C44.72 472.6 34.87 480 24.02 480c-1.844 0-3.727-.2187-5.602-.6562c-12.89-3.098-20.84-16.08-17.75-28.96c9.598-39.5 90.47-226.4 335.3-226.4C344.8 224 352 216.8 352 208S344.8 192 336 192C228.6 192 151 226.6 96.29 267.6c.1934-10.82 1.242-21.84 3.535-33.05c13.47-65.81 66.04-119 131.4-134.2c28.33-6.562 55.68-6.013 80.93-.0054c56 13.32 118.2-7.412 149.3-61.24c5.664-9.828 20.02-9.516 24.66 .8282C502.7 76.76 512 121.9 512 165.4z"></path></svg>Ethical considerations<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M169.4 278.6C175.6 284.9 183.8 288 192 288s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25s-32.75-12.5-45.25 0L192 210.8L54.63 73.38c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25L169.4 278.6zM329.4 265.4L192 402.8L54.63 265.4c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25l160 160C175.6 476.9 183.8 480 192 480s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25S341.9 252.9 329.4 265.4z"></path></svg></span><div id="collapsible-content-1654141393439" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1654141393439"><div class="Collapsible__contentInner"><p class="title">Best practices for online research</p>
<p></p>
<p>The rise of Amazon Mechanical Turk was a</p>
<ul>
<li>Fair payment.</li>
<li>Good user experience for participants</li>
<li>Clear communication</li>
</ul>
</div></div></div></div>
</div>
</div>
<div id="ensuring-high-quality-data" class="section level2" number="14.2">
<h2><span class="header-section-number">14.2</span> Ensuring high quality data</h2>
<p>In the second section of this chapter, we review a few key practices for</p>
<div class="box accident_report"><div class="Collapsible"><span id="collapsible-trigger-1654141393440" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1654141393440" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="person-falling-burst" class="svg-inline--fa fa-person-falling-burst " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M256 41.84C256 96.45 228.1 146.5 183.5 175.4L183.7 175.8L240.5 255.1H311.1C327.1 255.1 341.3 263.1 350.4 275.2L393.6 332.8C404.2 346.9 401.3 366.1 387.2 377.6C373.1 388.2 353 385.3 342.4 371.2L303.1 319.1H222.6L314.9 462.6C324.5 477.5 320.2 497.3 305.4 506.9C290.5 516.5 270.7 512.2 261.1 497.4L100.5 249.2C97.57 258.4 95.1 268.1 95.1 278.2V351.1C95.1 369.7 81.67 383.1 63.1 383.1C46.33 383.1 31.1 369.7 31.1 351.1V278.2C31.1 213 71.65 154.5 132.1 130.3C168.3 115.8 191.1 80.79 191.1 41.84V32C191.1 14.33 206.3 0 223.1 0C241.7 0 255.1 14.33 255.1 32L256 41.84zM96 79.1C96 106.5 74.51 127.1 48 127.1C21.49 127.1 0 106.5 0 79.1C0 53.49 21.49 31.1 48 31.1C74.51 31.1 96 53.49 96 79.1zM464 286.1L424.7 322.2C423.1 319.3 421.3 316.4 419.2 313.6L382.1 265.3L384.2 247.6L365.8 244.8C351.2 231.5 332.1 223.1 311.1 223.1H292.6C292.5 223.7 292.5 223.4 292.4 223.2C290.1 216.8 293.5 210.1 298.9 206.4L364.5 161.3L325 92.18C321.8 86.49 322.3 79.39 326.4 74.27C330.5 69.14 337.3 67.03 343.6 68.93L419.7 92.05L449.1 18.09C451.6 11.1 457.4 8 464 8C470.6 8 476.4 11.1 478.9 18.09L508.3 92.05L584.4 68.93C590.7 67.03 597.5 69.14 601.6 74.27C605.7 79.39 606.2 86.49 602.1 92.18L563.5 161.3L629.1 206.4C634.5 210.1 637 216.8 635.6 223.2C634.1 229.6 628.9 234.4 622.4 235.4L543.8 247.6L549.4 327C549.8 333.6 546.3 339.7 540.4 342.6C534.5 345.4 527.4 344.4 522.6 339.9L464 286.1z"></path></svg>Accident report<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M169.4 278.6C175.6 284.9 183.8 288 192 288s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25s-32.75-12.5-45.25 0L192 210.8L54.63 73.38c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25L169.4 278.6zM329.4 265.4L192 402.8L54.63 265.4c-12.5-12.5-32.75-12.5-45.25 0s-12.5 32.75 0 45.25l160 160C175.6 476.9 183.8 480 192 480s16.38-3.125 22.62-9.375l160-160c12.5-12.5 12.5-32.75 0-45.25S341.9 252.9 329.4 265.4z"></path></svg></span><div id="collapsible-content-1654141393440" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1654141393440"><div class="Collapsible__contentInner"><p class="title">Does data quality vary throughout the semester?</p>
<p></p>
<p>Every lab that collects empirical data repeatedly using the same population builds up lore about how that population varies. One infant development lab famously repainted their walls a particularly bright shade of blue and claimed that their studies did not yield significant findings (even replicating highly robust paradigms) until they went back to a more neutral color. …</p>
<p>The ManyLabs studies were a series of large-scale, collaborative studies that involved the same experimental protocol being run at a variety of different sites.</p>
</div></div></div></div>
<div id="run-pilot-studies" class="section level3" number="14.2.1">
<h3><span class="header-section-number">14.2.1</span> Run pilot studies</h3>
<p>A <strong>pilot study</strong> is a small study conducted before you collect your main sample. Smooth and successful data collection is typically difficult without piloting, at least the first time you do an experiment of a given type. Fundamentally, experiments induce a particular experience in their participants, and careful attention to the nature of that experience<label for="tufte-sn-167" class="margin-toggle sidenote-number">167</label><input type="checkbox" id="tufte-sn-167" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">167</span> Even if the experience is somewhat tedious, like searching for a T amongst Ls for hundreds of trials!</span> requires iterative development.</p>
<p>Pilot studies cannot tell you about expected effect size (as we discussed in Chapter <a href="10-sampling.html#sampling">10</a>). They also cannot tell you about the significance of your main result. What they <em>can</em> do is tell you about whether your paradigm works. They can reveal:
* if your code crashes under certain circumstances
* if your instructions confuse a substantial portion of your participants
* if you have a very high dropout rate
* if your data collection procedure fails to log variables of interest
* if participants are disgruntled by the end of the experiment</p>
<p>We recommend that all experimenters do – at the very minimum – two pilot studies before they launch their experiment.</p>
<p>The first pilot study, <strong>pilot A</strong><label for="tufte-sn-168" class="margin-toggle sidenote-number">168</label><input type="checkbox" id="tufte-sn-168" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">168</span> Good name, right?</span>, is a test with non-naive participants. Your parents can do this experiment, or in a pinch you can run yourself a bunch of times (though this isn’t preferable because you’re likely to miss a lot of aspects of the experience that you are habituated to, especially if you’ve been debugging the software). The goal of pilot A is to ensure that your experiment is comprehensible, that participants can complete it, and that the data are logged appropriately. This last goal means that you must <em>analyze</em> the data from pilot A, at least to the point of checking that the relevant data about each trial is logged.<label for="tufte-sn-169" class="margin-toggle sidenote-number">169</label><input type="checkbox" id="tufte-sn-169" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">169</span> At a minimum, for each trial you need to know a subject ID, a trial ID, the state of any manipulation (condition, trial type, etc.), and the value for the measure.</span></p>
<p>The second pilot study, <strong>pilot B</strong>, consists of a test of a small set of naive participants. Pilot size will depend on the costliness of running the experiment (in time, money, and opportunity cost) as well as your worries about the paradigm. If we’re talking about a short online survey experiment, then running a pilot of 10–20 people is reasonable. A more extensive laboratory study might be better served by piloting just two or three people. The goal of this second study is to understand properties of the participant experience: for example, were they confused? Did they withdraw before the study finished? You won’t have the numbers to make robust statistical inferences about these questions, but even a small number of pilots can tell you that your dropout rate is likely too high: if 5 of 10 pilot participants withdraw you may need to reconsider aspects of your design. It’s critical for pilot B that you debrief more extensively with your participants. This debriefing often takes the form of an interview questionnaire after the study is over (“what did you think the study was about?” and “is there any way we could improve the experience of being in the study?” can be helpful questions).</p>
<p>Piloting is often an iterative process. We frequently launch studies for a pilot B, then recognise from the data or from participant feedback that they can be improved. We make tweaks and pilot again. Be careful not to overfit to small differences in pilot data – the samples are small and so inferences will not be robust. The process should be more like workshopping a manuscript to remove typos and make it read better than doing a study.</p>
<p>In the case of especially expensive experiments, it can be a dilemma whether to run a larger pilot to identify difficulties since such a pilot will be costly. In these cases, one possibility can be to preregister a contingent strategy. For example, in a planned sample of 100 participants, you could preregister running 20 as a pilot sample with the stipulation that you will look only at their dropout rate and not at any condition differences in the target measure. Then the registration could state that if the dropout rate is lower than 25%, you will collect the next 80 participants and analyze the whole dataset including the initial pilot. This sort of registration can help you split the difference between cautious piloting and conservation of rare or costly data.</p>
</div>
<div id="keep-consistent-data-collection-records" class="section level3" number="14.2.2">
<h3><span class="header-section-number">14.2.2</span> Keep consistent data collection records</h3>
<p>Important to put checks in place on your data collection pipeline early.</p>
</div>
<div id="measure-participant-compliance" class="section level3" number="14.2.3">
<h3><span class="header-section-number">14.2.3</span> Measure participant compliance</h3>
<p>Data collection in the field: An opinionated discussion of common pitfalls of field experiments in psychology.</p>
<ul>
<li>Blinding and randomization. Fieldwork makes it harder to maintain these critical principles of experimental design, potentially leading to bias.</li>
<li>Reasoning about and combatting selection bias.</li>
</ul>
<p><a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00998/full" class="uri">https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00998/full</a></p>
</div>
</div>
<div id="chapter-summary-data-collection" class="section level2" number="14.3">
<h2><span class="header-section-number">14.3</span> Chapter summary: Data collection</h2>
<p>In this brief chapter, we reviewed the process of data collection from two perspectives. From the particpant’s perspective, we emphasized fair payment, a good “user experience”, nad clear communication as the three key factors ensuring that they</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-anderson2019" class="csl-entry">
Anderson, C. A., Allen, J. J., Plante, C., Quigley-McBride, A., Lovett, A., &amp; Rokkum, J. N. (2019). The MTurkification of social and personality psychology. <em>Personality and Social Psychology Bulletin</em>, <em>45</em>(6), 842–850.
</div>
<div id="ref-benjamin-jr2000" class="csl-entry">
Benjamin Jr, L. T. (2000). The psychology laboratory at the turn of the 20th century. <em>American Psychologist</em>, <em>55</em>(3), 318.
</div>
<div id="ref-buhrmester2016" class="csl-entry">
Buhrmester, M., Kwang, T., &amp; Gosling, S. D. (2016). <em>Amazon’s mechanical turk: A new source of inexpensive, yet high-quality data?</em>
</div>
<div id="ref-sears1986" class="csl-entry">
Sears, D. O. (1986). College sophomores in the laboratory: Influences of a narrow data base on social psychology’s view of human nature. <em>Journal of Personality and Social Psychology</em>, <em>51</em>(3), 515.
</div>
<div id="ref-sieber1989" class="csl-entry">
Sieber, J. E., &amp; Saks, M. J. (1989). A census of subject pool characteristics and policies. <em>American Psychologist</em>, <em>44</em>(7), 1053.
</div>
</div>

</div>
</div>




<script type="module" src="/assets/src/index.page.client.jsx.df9edbd0.js"></script><script id="vite-plugin-ssr_pageContext" type="application/json">{"pageContext":{"_pageId":"/src/index","url":"/14-collection","body":"\n\n\n\n\u003cdiv class=\"row\">\n\u003cdiv class=\"col-sm-12\">\n\u003cdiv id=\"TOC\">\n\u003cul>\n\u003cli>\u003ca href=\"#part-preliminaries\" id=\"toc-part-preliminaries\">(PART) Preliminaries\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"1-experiments.html#experiments\" id=\"toc-experiments\">\u003cspan class=\"toc-section-number\">1\u003c/span> Experiments\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"2-theories.html#theories\" id=\"toc-theories\">\u003cspan class=\"toc-section-number\">2\u003c/span> Theories\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"3-replication.html#replication\" id=\"toc-replication\">\u003cspan class=\"toc-section-number\">3\u003c/span> Replication and reproducibility\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"4-ethics.html#ethics\" id=\"toc-ethics\">\u003cspan class=\"toc-section-number\">4\u003c/span> Ethics\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-statistics\" id=\"toc-part-statistics\">(PART) Statistics\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"5-estimation.html#estimation\" id=\"toc-estimation\">\u003cspan class=\"toc-section-number\">5\u003c/span> Estimation\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"6-inference.html#inference\" id=\"toc-inference\">\u003cspan class=\"toc-section-number\">6\u003c/span> Inference\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"7-models.html#models\" id=\"toc-models\">\u003cspan class=\"toc-section-number\">7\u003c/span> Models\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-design-and-planning\" id=\"toc-part-design-and-planning\">(PART) Design and Planning\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"8-measurement.html#measurement\" id=\"toc-measurement\">\u003cspan class=\"toc-section-number\">8\u003c/span> Measurement\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"9-design.html#design\" id=\"toc-design\">\u003cspan class=\"toc-section-number\">9\u003c/span> Design of experiments\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"10-sampling.html#sampling\" id=\"toc-sampling\">\u003cspan class=\"toc-section-number\">10\u003c/span> Sampling\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"11-strategy.html#strategy\" id=\"toc-strategy\">\u003cspan class=\"toc-section-number\">11\u003c/span> Experimental strategy\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-execution\" id=\"toc-part-execution\">(PART) Execution\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"12-prereg.html#prereg\" id=\"toc-prereg\">\u003cspan class=\"toc-section-number\">12\u003c/span> Preregistration\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"13-consent.html#consent\" id=\"toc-consent\">\u003cspan class=\"toc-section-number\">13\u003c/span> Recruitment and Consent\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"14-collection.html#collection\" id=\"toc-collection\">\u003cspan class=\"toc-section-number\">14\u003c/span> Data collection\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"15-management.html#management\" id=\"toc-management\">\u003cspan class=\"toc-section-number\">15\u003c/span> Project management\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#part-analysis-and-reporting\" id=\"toc-part-analysis-and-reporting\">(PART) Analysis and Reporting\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"16-viz.html#viz\" id=\"toc-viz\">\u003cspan class=\"toc-section-number\">16\u003c/span> Visualization\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"17-eda.html#eda\" id=\"toc-eda\">\u003cspan class=\"toc-section-number\">17\u003c/span> Exploratory data analysis\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"18-writing.html#writing\" id=\"toc-writing\">\u003cspan class=\"toc-section-number\">18\u003c/span> Writing\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"19-meta.html#meta\" id=\"toc-meta\">\u003cspan class=\"toc-section-number\">19\u003c/span> Meta-analysis\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"20-conclusions.html#conclusions\" id=\"toc-conclusions\">\u003cspan class=\"toc-section-number\">20\u003c/span> Conclusions\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"#appendix-appendices\" id=\"toc-appendix-appendices\">(APPENDIX) Appendices\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"A-git.html#git\" id=\"toc-git\">\u003cspan class=\"toc-section-number\">21\u003c/span> GitHub Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"B-rmarkdown.html#rmarkdown\" id=\"toc-rmarkdown\">\u003cspan class=\"toc-section-number\">22\u003c/span> R Markdown Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"C-tidyverse.html#tidyverse\" id=\"toc-tidyverse\">\u003cspan class=\"toc-section-number\">23\u003c/span> Tidyverse Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"D-ggplot.html#ggplot\" id=\"toc-ggplot\">\u003cspan class=\"toc-section-number\">24\u003c/span> ggplot Tutorial\u003c/a>\u003c/li>\n\u003cli>\u003ca href=\"E-instructors.html#instructors\" id=\"toc-instructors\">\u003cspan class=\"toc-section-number\">25\u003c/span> Instructor’s guide\u003c/a>\u003c/li>\n\u003c/ul>\n\u003c/div>\n\u003c/div>\n\u003c/div>\n\u003cdiv class=\"row\">\n\u003cdiv class=\"col-sm-12\">\n\u003cdiv id=\"collection\" class=\"section level1\" number=\"14\">\n\u003ch1>\u003cspan class=\"header-section-number\">Chapter 14\u003c/span> Data collection\u003c/h1>\n\u003cdiv class=\"box learning_goals\">\n\u003cul>\n\u003cli>Review best practices for online and in person data collection\u003c/li>\n\u003cli>Implement data integrity checks, manipulation checks, and pilot testing\u003c/li>\n\u003c/ul>\n\u003c/div>\n\u003cp>You have selected your measure and manipulation and planned your sample. Your preregistration is set. You have gone through your recruitment and ethics. Now it’s time to think about the nuts and bolts of collecting data.\u003c/p>\n\u003cp>While the details of data collection may vary from context to context and sample to sample, this chapter will highlight some general best practices for the data collection process. We organize these practices around two goals. The first section is participant-centric: we review some concerns regarding how to provide a positive experience for participants in both in-person and online experiments. Then in the second section, we discuss the data collection process from the perspective of the experimenter, covering some best practices\u003c/p>\n\u003cdiv class=\"box case_study\">\n\u003cp>(TITLE) The rise of online data collection\u003c/p>\n\u003cp>Since the rise of experimental psychology laboratories in university settings during the period after World War 2 \u003cspan class=\"citation\">(\u003ca href=\"#ref-benjamin-jr2000\" role=\"doc-biblioref\">Benjamin Jr, 2000\u003c/a>)\u003c/span>, experiments have typically been conducted by recruiting participants from what has been referred to as the “subject pool.” This term denotes a group of people who can be recruited for experiments, typically students from introductory psychology courses \u003cspan class=\"citation\">(\u003ca href=\"#ref-sieber1989\" role=\"doc-biblioref\">Sieber &amp; Saks, 1989\u003c/a>)\u003c/span> recruited via the requirement that students complete a certain quantity of experiments as part of their course work.\u003clabel for=\"tufte-sn-166\" class=\"margin-toggle sidenote-number\">166\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-166\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">166\u003c/span> At various times, students have raised ethical concerns about these requirements as being coercive of participationin precisely the way that should be off limits for psychology experiments (see Chapter \u003ca href=\"4-ethics.html#ethics\">4\u003c/a>). As a result, most programs now provide some more or less onerous alternative to participation.\u003c/span> The ready availability of this convenience population led inevitably to the massive over-representation of US undergraduates in published psychology research, leading to persistent critiques of this practice for the generalizability of research \u003cspan class=\"citation\">(\u003ca href=\"#ref-sears1986\" role=\"doc-biblioref\">Sears, 1986\u003c/a>; \u003ca href=\"#ref-henrich2012\" role=\"doc-biblioref\">\u003cstrong>henrich2012?\u003c/strong>\u003c/a>)\u003c/span>.\u003c/p>\n\u003cp>Yet in the period 2005–2015, there has been a revolution in data collection from convenience populations. Instead of focusing on university undergraduates, increasingly, published psychology work uses convenience samples of online workers recruited from crowdsourcing sites like Amazon Mechanical Turk (AMT). Originally designed to distribute micropayments to workers for business purposes like retyping reciepts, these services have become marketplaces to connect researchers with research participants who are willing to complete surveys and experimental tasks for small payments. As of 2015, more than a third of studies in top social and personality psychology journals were conducted on crowdsourcing platforms (another third were still conducted with college undergraduates) \u003cspan class=\"citation\">(\u003ca href=\"#ref-anderson2019\" role=\"doc-biblioref\">C. A. Anderson et al., 2019\u003c/a>)\u003c/span> and this proportion is likely continuing to grow.\u003c/p>\n\u003cp>Online data collection\u003c/p>\n\u003cp>\u003cspan class=\"citation\">(\u003ca href=\"#ref-buhrmester2016\" role=\"doc-biblioref\">Buhrmester et al., 2016\u003c/a>; \u003ca href=\"#ref-mason2016\" role=\"doc-biblioref\">\u003cstrong>mason2016?\u003c/strong>\u003c/a>)\u003c/span>\u003c/p>\n\u003cp>Crump et al. (2013) show through a set of beautiful experiments designed in the web browser how online data collection can replicate effects initially found in the lab.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"the-participants-perspective\" class=\"section level2\" number=\"14.1\">\n\u003ch2>\u003cspan class=\"header-section-number\">14.1\u003c/span> The participant’s perspective\u003c/h2>\n\u003cdiv id=\"data-collection-in-person\" class=\"section level3\" number=\"14.1.1\">\n\u003ch3>\u003cspan class=\"header-section-number\">14.1.1\u003c/span> Data collection in person\u003c/h3>\n\u003c/div>\n\u003cdiv id=\"data-collection-online\" class=\"section level3\" number=\"14.1.2\">\n\u003ch3>\u003cspan class=\"header-section-number\">14.1.2\u003c/span> Data collection online\u003c/h3>\n\u003cp>Online data collection is increasingly ubiquitous in the behavioral sciences. Further, the web browser – alongside survey software like Qualtrics – can be a major aid to transparency in sharing experimental materials.\u003c/p>\n\u003cul>\n\u003cli>Validating the process of collecting data online. We briefly review studies suggesting that for general data collection across many paradigms, online data collection is valid.\u003c/li>\n\u003cli>When is online not enough? We describe cases where in-person data collection is necessary, highlighting psychophysical and physiological measurement and social interaction as two common classes of experiments that still cannot be done effectively online.\u003c/li>\n\u003c/ul>\n\u003cp>Class MTurk Guidelines\nIntro\nIn this class we will be running our replication projects on Amazon’s Mechanical Turk (AMT/mTurk). mTurk is a platform on which Workers (or “Turkers”) can complete Human Intelligence Tasks (HITs) for monetary compensation. HITs are put up by Requesters. mTurk originally was set up to do large-scale tasks that require human intelligence (e.g. labeling photos, finding telephone numbers, etc), but has recently been used by social scientists to conduct (large-scale) online experiments.\u003c/p>\n\u003cp>In this class, all replication projects will be launched using a common class account. This saves you the hassle of applying for a personal Requester account (which lately has become not-as-straightforward…), and also simplifies funding logistics. We will be giving more detailed instructions in class on how to access the class account and launch HITs etc.\u003c/p>\n\u003cp>General notes to keep in mind:\u003c/p>\n\u003cp>Many Turkers multi-task and do tens of HITs for many hours a day, so design your study with this in mind. Include appropriate attention checks, manipulation checks, and exclusion criteria (depending on the original study design as well).\nAmazon worker IDs are actually tied to their (public) Amazon account and thus constitute identifiable information. Keep Turk IDs and all other identifiable information private. Anonymize all data before pushing to your git project repo, especially if your repo is public. There are useful tools for quickly automatically anonymizing IDs so reach out to the TAs if you want help with this!\nDo all analyses on anonymized data. (This is to prevent cases where others are unable to reproduce your analyses because it might rely somehow on identifiable information. If you start with anonymized data, your analyses would never use any of this information.)\nResources\nBeginner:\nA gentle guide to MTurk (Links to an external site.)\nGuide to Mturk basics (Links to an external site.)\nMTurkers are people (Links to an external site.) (&amp; the problem with common paradigms on MTurk)\nSurvey within MTurk platform (Links to an external site.)\nQualtrics Link (Links to an external site.)\nIntermediate:\nTurker Nation (Links to an external site.): Discussion board for Turkers\nCreating a launch page to external site (Links to an external site.): advantage is that your study is embedded within MTurk, then opens a full page window for your task when required. Note launcher.html and task.html are separate.\nGetting around the ridiculous extra 20% fee for 9+ participants (Links to an external site.)\nMTurk fee structure (Links to an external site.) (Links to an external site.)\nIRB\nWe have approval under protocol #IRB-23274Links to an external site.: “Reproducibility of psychological science and instruction.”\u003c/p>\n\u003cp>Before running your study, you will need to complete a short CITI human subjects training if you have not already. (See assignment).\u003c/p>\n\u003cp>Please include the following text on the first page / consent form of your study:\u003c/p>\n\u003cp>By answering the following questions, you are participating in a study being performed by cognitive scientists in the Stanford Department of Psychology. If you have questions about this research, please contact us at \u003ca href=\"mailto:stanfordpsych251@gmail.com\" class=\"email\">stanfordpsych251@gmail.com\u003c/a>. You must be at least 18 years old to participate. Your participation in this research is voluntary. You may decline to answer any or all of the following questions. You may decline further participation, at any time, without adverse consequences. Your anonymity is assured; the researchers who have requested your participation will not receive any personal information about you. We have recently been made aware that your public Amazon.com profile can be accessed via your worker ID if you do not choose to opt out. If you would like to opt out of this feature, you may follow instructions available here (Links to an external site.).\u003c/p>\n\u003cp>Please include a short debriefing in your experiment, thanking the participant, explaining in 2-4 lines what your study was about, and asking them not to share this information with other potential participants.\u003c/p>\n\u003cp>Additional notes on MTurk\nCommunicating with participants\u003c/p>\n\u003cp>When you are running either Pilot B or your actual study, please keep this gmail window open and monitor traffic on it.\nIf you get complaints about your study, please address them courteously and quickly (ideally, within a few hours). Turkers can be very helpful if you are responsive. Always assure them that they will be paid for their work.\nPayment policies\u003c/p>\n\u003cp>When in doubt as to technical issues, pay the Turker. The TAs can help you bonus those who had technical issues with the experiment or completion code!\nIf a Turker seems especially difficult, then please bring their complaint to the attention of the course team. Turkers can potentially complain to IRB so err on the side of doing this more frequently if you have issues.\u003c/p>\n\u003cdiv class=\"box ethical_considerations\">\n\u003cp>(TITLE) Best practices for online research\u003c/p>\n\u003cp>The rise of Amazon Mechanical Turk was a\u003c/p>\n\u003cul>\n\u003cli>Fair payment.\u003c/li>\n\u003cli>Good user experience for participants\u003c/li>\n\u003cli>Clear communication\u003c/li>\n\u003c/ul>\n\u003c/div>\n\u003c/div>\n\u003c/div>\n\u003cdiv id=\"ensuring-high-quality-data\" class=\"section level2\" number=\"14.2\">\n\u003ch2>\u003cspan class=\"header-section-number\">14.2\u003c/span> Ensuring high quality data\u003c/h2>\n\u003cp>In the second section of this chapter, we review a few key practices for\u003c/p>\n\u003cdiv class=\"box accident_report\">\n\u003cp>(TITLE) Does data quality vary throughout the semester?\u003c/p>\n\u003cp>Every lab that collects empirical data repeatedly using the same population builds up lore about how that population varies. One infant development lab famously repainted their walls a particularly bright shade of blue and claimed that their studies did not yield significant findings (even replicating highly robust paradigms) until they went back to a more neutral color. …\u003c/p>\n\u003cp>The ManyLabs studies were a series of large-scale, collaborative studies that involved the same experimental protocol being run at a variety of different sites.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"run-pilot-studies\" class=\"section level3\" number=\"14.2.1\">\n\u003ch3>\u003cspan class=\"header-section-number\">14.2.1\u003c/span> Run pilot studies\u003c/h3>\n\u003cp>A \u003cstrong>pilot study\u003c/strong> is a small study conducted before you collect your main sample. Smooth and successful data collection is typically difficult without piloting, at least the first time you do an experiment of a given type. Fundamentally, experiments induce a particular experience in their participants, and careful attention to the nature of that experience\u003clabel for=\"tufte-sn-167\" class=\"margin-toggle sidenote-number\">167\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-167\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">167\u003c/span> Even if the experience is somewhat tedious, like searching for a T amongst Ls for hundreds of trials!\u003c/span> requires iterative development.\u003c/p>\n\u003cp>Pilot studies cannot tell you about expected effect size (as we discussed in Chapter \u003ca href=\"10-sampling.html#sampling\">10\u003c/a>). They also cannot tell you about the significance of your main result. What they \u003cem>can\u003c/em> do is tell you about whether your paradigm works. They can reveal:\n* if your code crashes under certain circumstances\n* if your instructions confuse a substantial portion of your participants\n* if you have a very high dropout rate\n* if your data collection procedure fails to log variables of interest\n* if participants are disgruntled by the end of the experiment\u003c/p>\n\u003cp>We recommend that all experimenters do – at the very minimum – two pilot studies before they launch their experiment.\u003c/p>\n\u003cp>The first pilot study, \u003cstrong>pilot A\u003c/strong>\u003clabel for=\"tufte-sn-168\" class=\"margin-toggle sidenote-number\">168\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-168\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">168\u003c/span> Good name, right?\u003c/span>, is a test with non-naive participants. Your parents can do this experiment, or in a pinch you can run yourself a bunch of times (though this isn’t preferable because you’re likely to miss a lot of aspects of the experience that you are habituated to, especially if you’ve been debugging the software). The goal of pilot A is to ensure that your experiment is comprehensible, that participants can complete it, and that the data are logged appropriately. This last goal means that you must \u003cem>analyze\u003c/em> the data from pilot A, at least to the point of checking that the relevant data about each trial is logged.\u003clabel for=\"tufte-sn-169\" class=\"margin-toggle sidenote-number\">169\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-169\" class=\"margin-toggle\">\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">169\u003c/span> At a minimum, for each trial you need to know a subject ID, a trial ID, the state of any manipulation (condition, trial type, etc.), and the value for the measure.\u003c/span>\u003c/p>\n\u003cp>The second pilot study, \u003cstrong>pilot B\u003c/strong>, consists of a test of a small set of naive participants. Pilot size will depend on the costliness of running the experiment (in time, money, and opportunity cost) as well as your worries about the paradigm. If we’re talking about a short online survey experiment, then running a pilot of 10–20 people is reasonable. A more extensive laboratory study might be better served by piloting just two or three people. The goal of this second study is to understand properties of the participant experience: for example, were they confused? Did they withdraw before the study finished? You won’t have the numbers to make robust statistical inferences about these questions, but even a small number of pilots can tell you that your dropout rate is likely too high: if 5 of 10 pilot participants withdraw you may need to reconsider aspects of your design. It’s critical for pilot B that you debrief more extensively with your participants. This debriefing often takes the form of an interview questionnaire after the study is over (“what did you think the study was about?” and “is there any way we could improve the experience of being in the study?” can be helpful questions).\u003c/p>\n\u003cp>Piloting is often an iterative process. We frequently launch studies for a pilot B, then recognise from the data or from participant feedback that they can be improved. We make tweaks and pilot again. Be careful not to overfit to small differences in pilot data – the samples are small and so inferences will not be robust. The process should be more like workshopping a manuscript to remove typos and make it read better than doing a study.\u003c/p>\n\u003cp>In the case of especially expensive experiments, it can be a dilemma whether to run a larger pilot to identify difficulties since such a pilot will be costly. In these cases, one possibility can be to preregister a contingent strategy. For example, in a planned sample of 100 participants, you could preregister running 20 as a pilot sample with the stipulation that you will look only at their dropout rate and not at any condition differences in the target measure. Then the registration could state that if the dropout rate is lower than 25%, you will collect the next 80 participants and analyze the whole dataset including the initial pilot. This sort of registration can help you split the difference between cautious piloting and conservation of rare or costly data.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"keep-consistent-data-collection-records\" class=\"section level3\" number=\"14.2.2\">\n\u003ch3>\u003cspan class=\"header-section-number\">14.2.2\u003c/span> Keep consistent data collection records\u003c/h3>\n\u003cp>Important to put checks in place on your data collection pipeline early.\u003c/p>\n\u003c/div>\n\u003cdiv id=\"measure-participant-compliance\" class=\"section level3\" number=\"14.2.3\">\n\u003ch3>\u003cspan class=\"header-section-number\">14.2.3\u003c/span> Measure participant compliance\u003c/h3>\n\u003cp>Data collection in the field: An opinionated discussion of common pitfalls of field experiments in psychology.\u003c/p>\n\u003cul>\n\u003cli>Blinding and randomization. Fieldwork makes it harder to maintain these critical principles of experimental design, potentially leading to bias.\u003c/li>\n\u003cli>Reasoning about and combatting selection bias.\u003c/li>\n\u003c/ul>\n\u003cp>\u003ca href=\"https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00998/full\" class=\"uri\">https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00998/full\u003c/a>\u003c/p>\n\u003c/div>\n\u003c/div>\n\u003cdiv id=\"chapter-summary-data-collection\" class=\"section level2\" number=\"14.3\">\n\u003ch2>\u003cspan class=\"header-section-number\">14.3\u003c/span> Chapter summary: Data collection\u003c/h2>\n\u003cp>In this brief chapter, we reviewed the process of data collection from two perspectives. From the particpant’s perspective, we emphasized fair payment, a good “user experience”, nad clear communication as the three key factors ensuring that they\u003c/p>\n\n\u003c/div>\n\u003c/div>\n\u003ch3>References\u003c/h3>\n\u003cdiv id=\"refs\" class=\"references csl-bib-body hanging-indent\" line-spacing=\"2\">\n\u003cdiv id=\"ref-anderson2019\" class=\"csl-entry\">\nAnderson, C. A., Allen, J. J., Plante, C., Quigley-McBride, A., Lovett, A., &amp; Rokkum, J. N. (2019). The MTurkification of social and personality psychology. \u003cem>Personality and Social Psychology Bulletin\u003c/em>, \u003cem>45\u003c/em>(6), 842–850.\n\u003c/div>\n\u003cdiv id=\"ref-benjamin-jr2000\" class=\"csl-entry\">\nBenjamin Jr, L. T. (2000). The psychology laboratory at the turn of the 20th century. \u003cem>American Psychologist\u003c/em>, \u003cem>55\u003c/em>(3), 318.\n\u003c/div>\n\u003cdiv id=\"ref-buhrmester2016\" class=\"csl-entry\">\nBuhrmester, M., Kwang, T., &amp; Gosling, S. D. (2016). \u003cem>Amazon’s mechanical turk: A new source of inexpensive, yet high-quality data?\u003c/em>\n\u003c/div>\n\u003cdiv id=\"ref-sears1986\" class=\"csl-entry\">\nSears, D. O. (1986). College sophomores in the laboratory: Influences of a narrow data base on social psychology’s view of human nature. \u003cem>Journal of Personality and Social Psychology\u003c/em>, \u003cem>51\u003c/em>(3), 515.\n\u003c/div>\n\u003cdiv id=\"ref-sieber1989\" class=\"csl-entry\">\nSieber, J. E., &amp; Saks, M. J. (1989). A census of subject pool characteristics and policies. \u003cem>American Psychologist\u003c/em>, \u003cem>44\u003c/em>(7), 1053.\n\u003c/div>\n\u003c/div>\n\u003cp style=\"text-align: center;\">\n\u003ca href=\"13-consent.html\">\u003cbutton class=\"btn btn-default\">Previous\u003c/button>\u003c/a>\n\u003ca href=\"15-management.html\">\u003cbutton class=\"btn btn-default\">Next\u003c/button>\u003c/a>\n\u003c/p>\n\u003c/div>\n\u003c/div>\n\n\n\n"}}</script></body>

</html>