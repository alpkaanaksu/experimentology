
<!DOCTYPE html>
<html>
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 5 Estimation | Experimentology" />
<meta property="og:type" content="book" />




<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 5 Estimation | Experimentology">

<title>Chapter 5 Estimation | Experimentology</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<link rel="stylesheet" type="text/css" href="/assets/src/index.page.client.jsx.01c18f4f.css"></head>
<body>



<div class="row">
<div class="col-sm-12">
<div id="island_0"><header class="_toc_1lnsy_1" id="toc"><a class="_book_title_1lnsy_24" href="/">Experimentology: An Open Science Approach to Experimental Psychology Methods</a><nav><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Preliminaries</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="1-experiments">Experiments</a><a class="_chapter_title_1lnsy_32" href="2-theories">Theories</a><a class="_chapter_title_1lnsy_32" href="3-replication">Replication</a><a class="_chapter_title_1lnsy_32" href="4-ethics">Ethics</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Statistics</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="5-estimation">Estimation</a><a class="_chapter_title_1lnsy_32" href="6-inference">Inference</a><a class="_chapter_title_1lnsy_32" href="7-models">Models</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Design</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="8-measurement">Measurement</a><a class="_chapter_title_1lnsy_32" href="9-design">Design</a><a class="_chapter_title_1lnsy_32" href="10-sampling">Sampling</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Execution</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="11-prereg">Preregistration</a><a class="_chapter_title_1lnsy_32" href="12-collection">Data collection</a><a class="_chapter_title_1lnsy_32" href="13-management">Project management</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Reporting</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="14-writing">Writing</a><a class="_chapter_title_1lnsy_32" href="15-viz">Visualization</a><a class="_chapter_title_1lnsy_32" href="16-meta">Meta-analysis</a><a class="_chapter_title_1lnsy_32" href="17-conclusions">Conclusions</a></div></div><div class="_part_1lnsy_16"><div class="_part_title_1lnsy_24"><div class="_part_title_first_1lnsy_59">Appendices</div><div class="_part_title_rest_1lnsy_32"></div></div><div class="_dropdown_1lnsy_16"><a class="_chapter_title_1lnsy_32" href="A-git">GitHub</a><a class="_chapter_title_1lnsy_32" href="B-rmarkdown">R Markdown</a><a class="_chapter_title_1lnsy_32" href="C-tidyverse">Tidyverse</a><a class="_chapter_title_1lnsy_32" href="D-ggplot">ggplot</a><a class="_chapter_title_1lnsy_32" href="E-instructors">Instructor’s guide</a></div></div></nav></header></div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="estimation" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Estimation</h1>
<div id="island_1"><div class="box learning_goals"><div class="Collapsible"><span id="collapsible-trigger-1663429564130" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1663429564130" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="apple-whole" class="svg-inline--fa fa-apple-whole " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M224 112c-8.8 0-16-7.2-16-16V80c0-44.2 35.8-80 80-80h16c8.8 0 16 7.2 16 16V32c0 44.2-35.8 80-80 80H224zM0 288c0-76.3 35.7-160 112-160c27.3 0 59.7 10.3 82.7 19.3c18.8 7.3 39.9 7.3 58.7 0c22.9-8.9 55.4-19.3 82.7-19.3c76.3 0 112 83.7 112 160c0 128-80 224-160 224c-16.5 0-38.1-6.6-51.5-11.3c-8.1-2.8-16.9-2.8-25 0c-13.4 4.7-35 11.3-51.5 11.3C80 512 0 416 0 288z"></path></svg>Learning goals<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M246.6 470.6c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 402.7 361.4 265.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3l-160 160zm160-352l-160 160c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 210.7 361.4 73.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3z"></path></svg></span><div id="collapsible-content-1663429564130" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1663429564130"><div class="Collapsible__contentInner">
<ul>
<li>Use parameter estimation to compute a causal effect via an experiment</li>
<li>Discuss differences between frequentist and Bayesian estimation</li>
<li>Reason about standardized effect sizes and their strengths and weaknesses</li>
</ul>
</div></div></div></div></div>
<p>In the first section of this book, our goal was to set up some of the theoretical ideas that motivate our approach to experimental design and planning. We introduced our key thesis, namely that experiments are about measuring causal effects. We also began to discuss some of our key themes, including precision of measurement, reduction of bias, and generalization across populations.</p>
<p>In this next section of the book – treating statistical topics – we will integrate these ideas with an analytic toolkit for <strong>estimating</strong> effects, <strong>quantifying the size and precision</strong> of these estimates (this chapter), making <strong>inferences</strong> about the evidence for such effects (Chapter <a href="6-inference.html#inference">6</a>), and making <strong>models</strong> for estimation and inference in more complex settings (Chapter <a href="7-models.html#models">7</a>). Although this book is not a statistics text, we hope that these chapters provide some practical foundations for beginning the statistical analysis of your experimental data.</p>
<div id="island_2"><div class="box case_study"><div class="Collapsible"><span id="collapsible-trigger-1663429564131" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1663429564131" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="microscope" class="svg-inline--fa fa-microscope " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M168 32c0-17.7 14.3-32 32-32h16c17.7 0 32 14.3 32 32h8c17.7 0 32 14.3 32 32V288c0 17.7-14.3 32-32 32h-8c0 17.7-14.3 32-32 32H200c-17.7 0-32-14.3-32-32h-8c-17.7 0-32-14.3-32-32V64c0-17.7 14.3-32 32-32l8 0zM32 448H320c70.7 0 128-57.3 128-128s-57.3-128-128-128V128c106 0 192 86 192 192c0 49.2-18.5 94-48.9 128H480c17.7 0 32 14.3 32 32s-14.3 32-32 32H320 32c-17.7 0-32-14.3-32-32s14.3-32 32-32zm80-64H304c8.8 0 16 7.2 16 16s-7.2 16-16 16H112c-8.8 0-16-7.2-16-16s7.2-16 16-16z"></path></svg>Case study<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M246.6 470.6c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 402.7 361.4 265.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3l-160 160zm160-352l-160 160c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 210.7 361.4 73.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3z"></path></svg></span><div id="collapsible-content-1663429564131" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1663429564131"><div class="Collapsible__contentInner"><p class="title">The Lady Tasting Tea</p>

<p>The birth of modern statistical inference came from a single, epochal act of mansplaining.<label for="tufte-sn-45" class="margin-toggle sidenote-number">45</label><input type="checkbox" id="tufte-sn-45" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">45</span> An important piece of context for the work of Ronald Fisher, Karl Pearson, and other early pioneers of statistical inference is that they were all strong proponents of eugenics. Fisher was the founding Chairman of the Cambridge Eugenics Society. Pearson was perhaps even worse, an avowed Social Darwinist who believed fervently in Eugenic legislation. These views are repugnant.</span> Sir Ronald Fisher was apparently at a party when a lady declared that she could tell the difference when tea was added to milk vs. milk to tea. Rather than taking her at her word, Fisher devised an experimental and data analysis procedure to test her claim.</p>
<p>The basic schema of the experiment was that the lady would have to judge a set of new cups of tea and sort them into milk-first vs. tea-first sets. Her data would then be analyzed to determine whether her level of correct choice exceeded that expected by chance. While this process now sounds like a quotidian experiment that might be done on a cooking reality show, it seems unremarkable only because it literally established the way science was done for the next century.</p>
<p>One important and unusual element of the experiment was its treatment of potential design confounds such which cup of tea was prepared first, which cup of tea was presented first, or the material that the cups were made out of. Prior experimental practice would have been to try to equate all of the cups as closely as possible, decreasing the influence of confounds. Fisher recognized that this strategy was insufficient. Only by randomizing all other aspects of the experiment could he make strong causal inferences about the treatment (milk then tea vs. tea then milk). We discussed the causal power of random assignment in Chapter <a href="1-experiments.html#experiments">1</a> – this experiment is a key touchstone in the popularization of randomized experiments!<label for="tufte-sn-46" class="margin-toggle sidenote-number">46</label><input type="checkbox" id="tufte-sn-46" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">46</span> Randomized experiments were not invented by Fisher. Perhaps the earliest example of a (somewhat) randomized experiment was a trial of scurvy treatments in the 1700s <span class="citation">(<a href="#ref-dunn1997" role="doc-biblioref">Dunn, 1997</a>)</span>. <span class="citation">Peirce &amp; Jastrow (<a href="#ref-peirce1884" role="doc-biblioref">1884</a>)</span> also report a strikingly modern use of randomized stimulus presentation (via shuffling cards). Nevertheless, Fisher’s statistical work popularized randomized experiments throughout the sciences, in part by integrating them with a set of analytic methods.</span></p>
</div></div></div></div></div>
<div id="estimating-a-quantity" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Estimating a quantity</h2>
<p>If experiments are about estimating effects, how do we actually use our experimental data to make these estimates? With apologies to Fisher, for our example we’ll design a slightly more modern version of his experiment using a Likert scale (1–7 ratings) and a between-participants design (so each participant gets only one cup of tea). Each of these elements will be discussed in more detail in future chapters.</p>
<p>Our causal theory is that the tea quality is affected by milk-tea ordering, so we’ll test that by rating tea quality both milk-first and tea-first. We’ll do this as a field trial in an English tea cafe: when people order tea with milk, we’ll randomly present it milk-first or tea-first and then elicit a rating on a Likert scale from 1 (terrible) to 7 (delicious). We’ll do this for 48 customers and then take a look at the data.<label for="tufte-sn-47" class="margin-toggle sidenote-number">47</label><input type="checkbox" id="tufte-sn-47" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">47</span> Right now we’re going to assume that our ratings are just simple numerical values and not worry about the fact that they come from a rating scale. This is what people often do, though it can cause problems in certain cases. If you’re curious about Likert scales, we’ll talk a bit more about them in Chapter <a href="8-measurement.html#measurement">8</a>.</span></p>
<p>Eventually, we’ll want to estimate the effect of milk-first preparation on quality ratings (our effect of interest). But for now, our goal will be to estimate the quality of the tea when it is milk-first [the better way, according to some data; <span class="citation">Kennedy (<a href="#ref-kennedy2003" role="doc-biblioref">2003</a>)</span>]. More formally, we want to use our <strong>sample</strong> of 24 milk-first tea judgments to estimate a <strong>population parameter</strong> that we can’t directly observe, namely the true perceived quality of all possible milk-first cups.</p>
<p>We’ll try to go easy on notation but some amount will make things clearer. We will use <span class="math inline">\(\theta_{\textrm{milk-first}}\)</span> (“theta”) to denote the parameter we want to estimate (the <strong>population parameter</strong>) and <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}\)</span>, its <strong>sample estimate</strong>.<label for="tufte-sn-48" class="margin-toggle sidenote-number">48</label><input type="checkbox" id="tufte-sn-48" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">48</span> Statisticians use “hats” like this to denote estimates from a specific sample. One way to remember this is that the “person in the hat” is wearing a hat to dress up as the actual quantity. Feel free to ignore this mnemonic; it helps us.</span></p>
<div id="maximum-likelihood-estimation" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Maximum likelihood estimation</h3>
<p>OK, you are probably saying, if we want our estimate of milk-first quality, shouldn’t we just take the average rating across the 24 cups of milk-first tea? The answer is yes. But let’s unpack that choice: taking the sample mean as our estimate <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}\)</span> is an example of an estimation approach called <strong>maximum likelihood estimation</strong>. In general terms, maximum likelihood estimation is a two-step process.</p>
<p>First, we assume a <strong>model</strong> for how the data were generated. This model is specified in terms of certain population parameters. In our example, the “model” is as simple as they come: we just assume there is some average level of tea quality and that the measurements vary around it.</p>
<p>Second, we try to find the values of the population parameters that make our observed data as likely as possible. For example, if our sample mean is <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}} = 4.5\)</span>, what underlying value of <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}\)</span> would make these data most likely to occur? Well, suppose the underlying parameter were <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}=2.5\)</span>. Then it would be pretty unlikely that our sample mean would be so much bigger. So <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}=2.5\)</span> is a poor guess for the population parameter based on these data. Conversely, if the parameter were <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}=6.5\)</span>, it would be a bit unlikely that our sample mean would be so much <em>smaller</em>. The value of <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}\)</span> that makes these data most likely is just 4.5 itself: the sample mean! That is why the sample mean in this case is the maximum likelihood estimate.</p>
</div>
<div id="estimating-variation-in-ratings" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Estimating variation in ratings</h3>
<p>Let’s visualize our 24 milk-first tea ratings. Since ratings on our scale are discrete, Figure <a href="5-estimation.html#fig:estimation-milk-first">5.1</a> shows them as a histogram. Our estimate of the mean, <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}\)</span>, is shown as a blue dashed line.</p>
<div id="island_3"><div class="box code"><div class="Collapsible"><span id="collapsible-trigger-1663429564132" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1663429564132" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="code" class="svg-inline--fa fa-code " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M392.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6zm80.6 120.1c-12.5 12.5-12.5 32.8 0 45.3L562.7 256l-89.4 89.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l112-112c12.5-12.5 12.5-32.8 0-45.3l-112-112c-12.5-12.5-32.8-12.5-45.3 0zm-306.7 0c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3l112 112c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l89.4-89.4c12.5-12.5 12.5-32.8 0-45.3z"></path></svg>Code<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M246.6 470.6c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 402.7 361.4 265.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3l-160 160zm160-352l-160 160c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 210.7 361.4 73.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3z"></path></svg></span><div id="collapsible-content-1663429564132" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1663429564132"><div class="Collapsible__contentInner">
<p>In this chapter and the subsequent statistics and visualization chapters of the book, we’ll try to facilitate understanding and using these concepts in practice by giving the R code we use in our examples in these code boxes. We’ll assume that you have some knowledge of base R and the Tidyverse – go ahead and take a look at Appendix <a href="C-tidyverse.html#tidyverse">C</a> if you haven’t already.</p>
<p>Since we’re going to be working with lots of data from the tea tasting example, we wrote a function called <code>make_tea_data</code> that creates a <code>tibble</code> with some (made up) data from our modern tea-tasting experiment.</p>
<pre><code>tea_data &lt;- make_tea_data(n_total, sigma)</code></pre>
<p>Here’s what the first few rows of those data look like:</p>
<table><thead><tr><th style="text-align: left;">
condition
</th><th style="text-align: right;">
rating
</th></tr></thead><tbody><tr><td style="text-align: left;">
milk first
</td><td style="text-align: right;">
6
</td></tr><tr><td style="text-align: left;">
milk first
</td><td style="text-align: right;">
4
</td></tr><tr><td style="text-align: left;">
milk first
</td><td style="text-align: right;">
5
</td></tr><tr><td style="text-align: left;">
milk first
</td><td style="text-align: right;">
5
</td></tr><tr><td style="text-align: left;">
milk first
</td><td style="text-align: right;">
5
</td></tr><tr><td style="text-align: left;">
milk first
</td><td style="text-align: right;">
4
</td></tr></tbody></table>
</div></div></div></div></div>
<div class="figure"><span style="display: block;" id="fig:estimation-milk-first"></span>
<p class="caption marginnote shownote">
Figure 5.1: Ratings of the quality of milk-first tea, with the best fitting normal distribution shown in blue (mean shown by the dashed line).
</p>
<img src="experimentology_files/figure-html/estimation-milk-first-1.png" alt="Ratings of the quality of milk-first tea, with the best fitting normal distribution shown in blue (mean shown by the dashed line)." width="\linewidth" />
</div>
<p>Our observations are clustered around the mean, but they also show some variation. Some are higher and some are lower. Variation of this type is a feature of every data set. This variation can be summarized via a <strong>probability distribution</strong>, a mathematical entity that describes the properties of possible datasets. The only probability distribution we’ll discuss here is the ubiquitous <strong>normal distribution</strong> (also sometimes called a “Gaussian distribution”). A normal distribution has two <strong>parameters</strong>, a <strong>mean</strong> and a <strong>standard deviation</strong>. These two parameters define the shape of the curve. The mean describes where its center goes, and the standard deviation describes how wide it is.</p>
<p>The blue curve shown in Figure <a href="5-estimation.html#fig:estimation-milk-first">5.1</a> is the normal distribution that is closest to the data in our milk-first condition. Its mean is of course <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}\)</span>, the parameter we just estimated. But to plot this curve, we also had to estimate the standard deviation. It turns out that the standard deviation is just exactly what its name says: the average deviation between the mean and any given observation. We won’t discuss how to estimate the standard deviation for your sample here; you can do this computation easily in any software package. What’s important for now is just that the standard deviation gives us a way to describe the width of the normal distribution.</p>
</div>
<div id="bayesian-estimation" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Bayesian estimation</h3>
<p>The maximum likelihood estimation example above describes a common approach to estimating values, where the researcher completely puts aside their prior expectations about what these values might be. Often this approach makes sense, especially when we have no prior expectations about the values we are estimating. But sometimes we <em>do</em> have relevant beliefs about the value. For example, before we perform our tea experiment, we don’t know exactly what <span class="math inline">\(\theta_{\textrm{milk-first}}\)</span> will be, but it seems a bit unlikely that tea would be consistently rated as either horrible (1) or perfect (7). We have what you might call <em>weak prior expectations</em> about the kinds of ratings we’ll receive.</p>
<p>These kind of expectations are most useful when we have a very small amount of data. For example, if our very first participant in the experiment rated their tea as terrible, we wouldn’t want to jump to the conclusion that the tea was actually bad. Instead, we might speculate that the participant was having a bad day or just brushed their teeth. On the other hand, if all of our participants gave bad ratings to their tea, the data would be more persuasive; in that case, we might want to tell the cafe that they are serving substandard tea. With a little data, our prior expectations should moderate our conclusions; as we get more, we should put greater weight on the data.</p>
<p>How do we quantify this tradeoff between our prior expectations and our current observations? We can do this via <strong>Bayesian estimation</strong> of <span class="math inline">\(\widehat{\theta}_{\textrm{milk-first}}\)</span>. Bayesian estimation provides a principled framework for integrating prior beliefs and data. These estimation techniques can be very helpful in cases where data are sparse or prior beliefs are strong.</p>
<p>In Bayesian estimation, we observe some data <span class="math inline">\(d\)</span>, consisting of the set of correct and incorrect responses in the experiment. Now we can use <strong>Bayes’ rule</strong>, a tool from basic probability theory, to estimate this number. Bayes’ rule says:</p>
<p><span class="math display">\[
\color{purple}{p(\theta_{\textrm{milk-first}} | \text{data})} = \frac{\color{red}{p(\text{data} | \theta_{\textrm{milk-first}} )} \color{blue}{p(\theta_{\textrm{milk-first}} )}}{\color{black}{p(\text{data})}}.
\]</span></p>
<p>Each part of this equation has a name, and it’s worth becoming familiar with them. The thing we want to compute (<span class="math inline">\(p(\theta_{\textrm{milk-first}} |\text{data})\)</span>) is called the <strong>posterior probability</strong> – it tell us what we should believe about the population parameter on tea quality, given the data we observed.<label for="tufte-sn-49" class="margin-toggle sidenote-number">49</label><input type="checkbox" id="tufte-sn-49" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">49</span> We’re making the posterior <span style="color: purple;">purple</span> to indicate the combination of likelihood (<span style="color: red;">red</span>) and prior (<span style="color: blue;">blue</span>).</span></p>
<p>The first part of the numerator is <span class="math inline">\(p(\text{data}|H)\)</span>, the probability of the data we observed given our hypothesis about the participant’s ability. This part is called the <strong>likelihood</strong>.<label for="tufte-sn-50" class="margin-toggle sidenote-number">50</label><input type="checkbox" id="tufte-sn-50" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">50</span> Speaking informally, “likelihood” is just a synonym for probability, but this is a technical meaning for the term, which can get a bit confusing.</span> This term tells us about the relationship between our hypothesis and the data we observed – so if we think the tea is of high quality (say <span class="math inline">\(\theta_{\textrm{milk-first}} = 6.5\)</span>) then the probability of a bunch of low accuracy observations will be fairly low.</p>
<p>The second term in the numerator, <span class="math inline">\(p(\theta_{\textrm{milk-first}} )\)</span>, is called the <strong>prior</strong>. This term encodes our beliefs about the likely distribution of tea quality. Intuitively, if we think that the tea is likely of high quality, we should require more evidence to convince us that it’s bad. In contrast, if we think it’s probably bad, a few examples of low ratings might serve to convince us.</p>
<div class="figure"><span style="display: block;" id="fig:inference-bayes-demo"></span>
<p class="caption marginnote shownote">
Figure 5.2: Examples of Bayesian inference about tea ratings under two different priors (panels) and a small sample size. Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior.
</p>
<img src="experimentology_files/figure-html/inference-bayes-demo-1.png" alt="Examples of Bayesian inference about tea ratings under two different priors (panels) and a small sample size. Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior." width="\linewidth" />
</div>
<p>Figure <a href="5-estimation.html#fig:inference-bayes-demo">5.2</a> gives an example of the combination of prior and data. In this example, we look at what difference the prior makes after observing 3 ratings. If we go in assuming that the tea is likely to be bad, we are biased downward in our highest posterior probability estimate of 4.7; if we go in that tea is likely to be good, we end up biased upwards to 5.2.<label for="tufte-sn-51" class="margin-toggle sidenote-number">51</label><input type="checkbox" id="tufte-sn-51" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">51</span> Note that this prior is operating only over on ratings – estimates on tea quality. Later on when we talk about comparing milk-first and tea-first cups, we can consider putting a prior on tea discrimination.</span></p>
<div class="figure"><span style="display: block;" id="fig:inference-bayes-demo2"></span>
<p class="caption marginnote shownote">
Figure 5.3: Bayesian inference about tea ratings under two different priors with the full dataset.
</p>
<img src="experimentology_files/figure-html/inference-bayes-demo2-1.png" alt="Bayesian inference about tea ratings under two different priors with the full dataset." width="\linewidth" />
</div>
<p>Contrast that figure with Figure <a href="5-estimation.html#fig:inference-bayes-demo2">5.3</a>, which runs the same Bayesian estimation but with the full dataset of 24 observations. Now the posterior distribution is much more peaked. The prior also makes much less difference to our highest-probability estimates. With the low prior, our estimate is 4.4; with the high prior it is 4.5 also!</p>
<p>Bayesian estimation is most important when you have strong beliefs and not a lot of data. That can be a case where you have just a few participants in your experiment, but it’s also good – and perhaps more common – to use Bayesian methods when you have a lot of data, but maybe not that much data about particular units that you care about. For example, you might have a large dataset about the effects of an educational intervention but not that much data about how it affects a particular subgroup. In general, though, Bayesian estimates and maximum likelihood estimates will exactly coincide either under a flat prior (a prior that makes any value equally likely) or as you get infinite data.</p>
</div>
</div>
<div id="estimating-and-comparing-effects" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Estimating and comparing effects</h2>
<p>We’ve now covered estimating a single parameter (the mean in just the milk-first group) using both frequentist and Bayesian methods. But recall that what we really wanted to do was to estimate the causal effect we were interested in, namely the milk-first vs. tea-first effect.<label for="tufte-sn-52" class="margin-toggle sidenote-number">52</label><input type="checkbox" id="tufte-sn-52" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">52</span> This method doesn’t have to be used only with a causal effect, it can be any between-group difference. Currently this effect just happens to be causal because our experiment uses random assignment.</span> In this section, we’ll discuss how to estimate the effect, and then how to use <strong>effect size</strong> measures to compare effects across experiments (as well as some of the pros and cons of doing so).</p>
<div id="estimating-the-treatment-effect" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Estimating the treatment effect</h3>
<p>Let’s refer to the causal effect we care about as our <strong>treatment effect</strong>. In practice, estimating <span class="math inline">\(\beta\)</span> is going to be a pretty straightforward extension to what we did before.</p>
<p>In the maximum likelihood framework, we could posit that ratings in each group (milk-first and tea-first) follow a normal distribution, but that these normal distributions might have different means and standard deviations. Extending the notation introduced above, let’s term the parameters for the tea-first group <span class="math inline">\(\theta_{\textrm{tea-first}}\)</span> and <span class="math inline">\(\sigma\)</span>. To estimate the treatment effect, we are positing a <strong>model</strong> in which the milk-first ratings are normally distributed with mean <span class="math inline">\(\theta_{\textrm{milk-first}} = \theta_{\textrm{tea-first}} + \beta\)</span> and with standard deviation <span class="math inline">\(\sigma\)</span>.<label for="tufte-sn-53" class="margin-toggle sidenote-number">53</label><input type="checkbox" id="tufte-sn-53" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">53</span> For simplicity, we’re assuming that the standard deviations in each tea group are equal.</span></p>
<p>As in the one-sample case (i.e., estimating the mean of just the milk-first group), maximum likelihood estimation would then proceed by finding the value of <span class="math inline">\(\beta\)</span> that makes the data most likely under the assumed model. As you’d probably expect, this estimate <span class="math inline">\(\widehat{\beta}\)</span> turns out to be simply the difference in sample means, <span class="math inline">\(\theta_{\textrm{milk-first}} - \theta_{\textrm{tea-first}}\)</span>.</p>
<p>In the Bayesian framework, we would again specify a prior <span class="math inline">\(p(\beta)\)</span> that encodes our prior beliefs about the size and direction of the treatment effect. If we have no prior beliefs at all, then we could specify a flat prior, <span class="math inline">\(p(\beta) \propto 1\)</span>. If we believe the treatment effect is likely to favor milk-first pouring (<span class="math inline">\(\beta>0\)</span>), we could specify a normal prior centered at some positive value (e.g., <span class="math inline">\(\beta=0.5\)</span>); the standard deviation of this prior would encode how certain we are about our prior beliefs. And if we have no prior beliefs about the direction of the treatment effect, but we think it is unlikely to be very large, we could specify a normal prior centered at 0, which has the effect of “shrinking” the estimates closer to 0.<label for="tufte-sn-54" class="margin-toggle sidenote-number">54</label><input type="checkbox" id="tufte-sn-54" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">54</span> The measures of variability that we discuss here account for statistical uncertainty reflecting the fact that we have only a finite sample size. If the sample size were infinite, there would be no uncertainty of this kind. Of course, this is only one kind of uncertainty! A more holistic view of the overall credibility of an estimate should also account for other things outside of the model, like study design issues and bias.</span></p>
<p>As in our example above, maximum likelihood estimates and Bayesian estimates are going to be pretty similar if we have a lot of data. They will only diverge when we have strong priors or relatively little data. The reason we are setting up these two different frameworks, however, is that they will provide very different inferential tools in the next chapter.</p>
</div>
<div id="measures-of-effect-size" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Measures of effect size</h3>
<p>Once we have measured something, we need to make a decision about how to describe this effect to the world. Sometimes we are working with fairly intuitive relationships that are easy to describe. A researcher might say, for example, that people who received milk-first tea drank the tea, on average, 5 minutes quicker than people who received tea-first tea (i.e., that <span class="math inline">\(\widehat{\beta} = 5\)</span> minutes). Time is measured in units like minutes and seconds and so we all have a shared understanding of what 5 minutes means.</p>
<p>But what about our participants’ ratings of tea quality, which were provided on an arbitrary 7-point rating scale that we devised? What does it mean to that participants who drank milk-first tea rated it 1 point higher than participants who drank tea-first tea (i.e., that <span class="math inline">\(\widehat{\beta} = 1\)</span> point)? And how is this difference comparable to, for instance, a 1-point change on a scale that has similar anchors (“terrible” and “delicious”) but uses a 100-point rating system?</p>
<p>To provide a common language for describing these relationships, some researchers use <em>standardized effect sizes.</em> A common standardized effect size is Cohen’s <em>d</em>, which provides a standardized estimate of the difference between two means. There are many different ways to calculate Cohen’s <em>d</em> <span class="citation">(<a href="#ref-lakens2013" role="doc-biblioref">Lakens, 2013</a>)</span>, but all approaches are usually some variant of the following formula:</p>
<p><span class="math display">\[
d = \frac{\theta_{\textrm{milk-first}} - \theta_{\textrm{tea-first}}}{\sigma_{\text{pooled}}}
\]</span></p>
<p>where the difference between means (<span class="math inline">\(\theta_{\textrm{tea-first}}\)</span> and <span class="math inline">\(\theta_{\textrm{milk-first}}\)</span>) is divided by the pooled standard deviation <span class="math inline">\(\sigma_{\text{pooled}}\)</span>.<label for="tufte-sn-55" class="margin-toggle sidenote-number">55</label><input type="checkbox" id="tufte-sn-55" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">55</span> We’re dropping the hats here because we’re now working with a whole bunch of estimates, so everything would have a hat!</span> Intuitively, what you’re doing is taking the study effect (<span class="math inline">\(\beta\)</span>) and dividing it – scaling it – by the variation we saw between individuals in the study.</p>
<p>Let’s compute this measure for our tea-drinking study. We can just plug in the estimates we made earlier in the chapter and compute the standard deviation of our observed data:</p>
<p><span class="math display">\[d = \frac{\theta_{\textrm{milk-first}} - \theta_{\textrm{tea-first}}}{\sigma_{\text{pooled}}} = \frac{4.5- 3.5}{1.25} = \frac{1}{1.25} = 0.80\]</span>
In other words, the effect size of the difference between the two conditions is .8 standard deviations.</p>
<p>We previously said that people who drank milk-first tea had quality ratings that were, on average, 1 point higher on a 7-point scale (<span class="math inline">\(\widehat{\beta} = 1\)</span> point). Cohen’s <em>d</em> translates the arbitrary units of our rating scale into a <strong>unit-less</strong> effect size that is measured in terms of the variation in the data. You may find yourself wondering: “why would I ever describe things in terms of standard deviations?” The key benefit is that it allows us to compare the size of the effect to studies that use different measures.</p>
<p>Let’s say that we ran a replication of our tea study with two changes: (1) we studied patrons in a US cafe instead of a UK cafe, and (2) we used a 100-point quality rating scale instead of a 7-point scale. Imagine that, just as we found that participants in the UK rated the milk-first tea 1-point higher on a 7-point quality scale, US participants rated the milk-first tea 1-point higher on a <em>100-point</em> quality scale. It seems clear that these effects are different because of the difference in scale. But how different?</p>
<p>It might at first seem reasonable just to normalize by the length of the scale. So maybe the UK experimental participants showed a 1/7 rating effect and the US participants showed a 1/100 rating effect. The trouble with this move is that it presupposes that participants from two different populations are using two different scales in exactly the same way! For example, maybe US participants made very clumpy judgments that were mostly centered around 50 (perhaps because of a lack of milk tea experience). Standardized effect sizes get around this kind of issue by scaling according to the variability of the data.</p>
<p>Let’s compute the effect size for the cross-cultural replication. We’ll imagine that participants who drank milk-first tea gave an average rating of 50/100 and participants who drank tea-first tea rated it 49 on average. But if their variability was also relatively lower, perhaps the standard deviation of their ratings was only 5. Using the formula above, we find</p>
<p><span class="math display">\[{d_{US}} = \frac{\theta_{\text{tea-first}} - \theta_{\text{milk-first}}}{\sigma_{\text{pooled}}} = \frac{50 - 49}{5} = \frac{1}{5}=  0.2\]</span></p>
<p>A Cohen’s <em>d</em> of .2 means that US cafe patrons rated their tea .2 standard deviations higher when it was milk-first, much smaller than the .8 standard deviation difference in the UK patrons.</p>
<p>There are no hard and fast rules for interpreting what makes a big effect or a small effect, but people often refer back to standard suggested by <span class="citation">Cohen (<a href="#ref-cohen1992" role="doc-biblioref">1992</a>)</span>. On those standards, <span class="math inline">\(d = 0.8\)</span> is a “large effect”, and <span class="math inline">\(d = 0.2\)</span> is a “small effect.” But these effect size interpretation norms are somewhat arbitrary. More broadly, though US and UK patrons had the same raw score change in quality ratings (<span class="math inline">\(\widehat{\beta} = 1\)</span>), standardizing the differences allowed us to communicate that the difference was much larger among the UK patrons.</p>
<p>Cohen’s <em>d</em> is one of many standardized effect sizes that researchers can use. Just as Cohen’s <em>d</em> standardizes differences in group means, there are also ways of standardizing relationships between categorical variables (e.g., odds ratio), how well a predictor variable explains an outcome variable (e.g., Pearson’s <em>r</em>, <span class="math inline">\(r^2\)</span>, or <span class="math inline">\(\eta^2\)</span>), and more. We’ll be using effect sizes throughout the book, but in most cases – for example, sample size planning in Chapter <a href="10-sampling.html#sampling">10</a> and meta-analysis in Chapter <a href="16-meta.html#meta">16</a> – we’ll be using Cohen’s <em>d</em> as our example.<label for="tufte-sn-56" class="margin-toggle sidenote-number">56</label><input type="checkbox" id="tufte-sn-56" class="margin-toggle" /><span class="sidenote"><span class="sidenote-number">56</span> If you’d like to learn more about other varieties of effect size, take a look at <span class="citation">Fritz et al. (<a href="#ref-fritz2012" role="doc-biblioref">2012</a>)</span>.</span></p>
</div>
<div id="pros-and-cons-of-standardizing-effect-sizes" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Pros and cons of standardizing effect sizes</h3>
<p>By now, you’re probably realizing that there are some pros and cons of standardizing effect sizes. Sure, it helps communicate that a 1-point change on a 7-point scale is not the same as a 1-point change on a 100-point scale. But is it any better to say that the first change represents a 0.80 standard deviation difference and the second a 0.08 standard deviation difference?</p>
<p>Proponents of effect size standardization argue that effect sizes allow us to compare results across studies more easily. Across studies, researchers use different measures, different study designs, and different populations. Standardization allows us to use a common language to describe estimated relationships in these varied contexts. This is helpful when we want to aggregate and compare effects across studies via meta-analysis. And it is also helpful when planning new studies. When trying to figure out how many participants to run in a study, almost all techniques use standardized effect sizes to determine how much data would be needed to reliably detect an effect.</p>
<p>Standardizing effect sizes, though, has limitations. For example, if two interventions produce the same absolute change in the same outcome measure, but are studied in different populations in which the variability on the outcome differs substantially, the interventions would produce different standardized mean differences.</p>
<p>For example, imagine we conducted our tea experiment again, but this time with (decaf) tea, and focusing on children. Maybe milk-first tea tastes the same amount better than tea-first tea for kids and for adults. But it’s pretty well known that kids are more variable in their responding. This higher level of variability would lead us to observe a smaller effect size in kids vs. adults. Recall that our UK adult SD was 1.25, and our effect size was <span class="math inline">\(d = .8\)</span>. Imagine that children’s SD is 2.5. In this scenario, even if tea led to the same 1-point absolute change in feelings of excitement among adults and children, the standardized effect size for kids would look half as big:</p>
<p><span class="math display">\[{d_{kids}} = \frac{\theta_{\text{tea-first}} - \theta_{\text{milk-first}}}{\sigma_{\text{pooled}}} = \frac{5- 4}{2.5} = \frac{1}{2.5} =  .4\]</span></p>
<p>This example highlights some of the challenges with standardization. If we focused on the fact that both adults and children experienced a 1-point change in excitement levels (<span class="math inline">\(\widehat{\beta} = 1\)</span>), we would conclude that milk-first tea is equally tasty for adults and kids. If we focused on the standardized effect sizes, however, we would conclude that the effect of tea is twice as big for adults.</p>
<p>So which is better: describing raw measures or standardized effect sizes? In general our response is “Why not both?” But if you wanted to pick one or the other, we recommend focusing on raw scores when working with measures that yield measurements that are likely to be comparable across studies already. If your study uses standard units such as milliseconds (e.g., for reaction times) or counts (e.g., for a study tracking an outcome like utterances), these measurements are already comparable across studies. Reporting raw measurements can allow you to check whether your measurements make sense – for example, a reaction time of 70 milliseconds is inhumanly fast, while a reaction time of 10 seconds might be extremely slow (at least, for many speeded tasks).</p>
<p>In contrast, we recommend using standardized effect sizes for cases where the measurement is relatively unlikely to be comparable with other studies in its original form, or unlikely to be meaningful on its own. For example, reporting the effect of an intervention on raw math test scores is only meaningful if the reader knows how many items are on the test, how difficult it is, and so forth. In such a case where there it is hard to be “calibrated” to the measurement, standardization with respect to variability via effect sizes may be the best we can do.</p>
</div>
</div>
<div id="chapter-summary-estimation" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Chapter summary: Estimation</h2>
<p>In this chapter, we introduced the idea of estimating both individual measurements and treatment effects from observed data. These ideas are simple but they lay the foundations for drawing inferences, where we move from estimates within a particular sample to inferences about the population. Further, we set up the distinction between Bayesian and frequentist approaches, which we will expand in the next chapter since these traditions provide different inferential tools.</p>
<div id="island_4"><div class="box readings"><div class="Collapsible"><span id="collapsible-trigger-1663429564133" class="Collapsible__trigger is-closed" aria-expanded="false" aria-disabled="false" aria-controls="collapsible-content-1663429564133" role="button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="book" class="svg-inline--fa fa-book " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M96 0C43 0 0 43 0 96V416c0 53 43 96 96 96H384h32c17.7 0 32-14.3 32-32s-14.3-32-32-32V384c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H384 96zm0 384H352v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"></path></svg>Readings<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="angles-down" class="svg-inline--fa fa-angles-down " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M246.6 470.6c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 402.7 361.4 265.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3l-160 160zm160-352l-160 160c-12.5 12.5-32.8 12.5-45.3 0l-160-160c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L224 210.7 361.4 73.4c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3z"></path></svg></span><div id="collapsible-content-1663429564133" class="Collapsible__contentOuter" style="height: 0px; -webkit-transition: height 300ms ease; ms-transition: height 300ms ease; transition: height 300ms ease; overflow: hidden;" role="region" aria-labelledby="collapsible-trigger-1663429564133"><div class="Collapsible__contentInner">
<ul>
<li><p>A great narrative introduction to the history and practice of statistics: Salsburg, D. (2001). <em>The lady tasting tea: How statistics revolutionized science in the twentieth century</em>. Macmillan.</p></li>
<li><p>An open source statistics textbook that follows a similar approach as Chapters <a href="5-estimation.html#estimation">5</a> – <a href="7-models.html#models">7</a>: Poldrack, R. (2022). <em>Statistical thinking for the 21st century</em>. Available free online at <a href>https://statsthinking21.org</a>.</p></li>
</ul>
</div></div></div></div></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-cohen1992" class="csl-entry">
Cohen, J. (1992). A power primer. <em>Psychological Bulletin</em>, <em>112</em>(1), 155.
</div>
<div id="ref-dunn1997" class="csl-entry">
Dunn, P. M. (1997). James lind (1716-94) of edinburgh and the treatment of scurvy. <em>Archives of Disease in Childhood-Fetal and Neonatal Edition</em>, <em>76</em>(1), F64–F65.
</div>
<div id="ref-fritz2012" class="csl-entry">
Fritz, C. O., Morris, P. E., &amp; Richler, J. J. (2012). Effect size estimates: Current use, calculations, and interpretation. <em>Journal of Experimental Psychology: General</em>, <em>141</em>(1), 2.
</div>
<div id="ref-kennedy2003" class="csl-entry">
Kennedy, M. (2003). How to make a perfect cuppa: Put milk in first. <em>How to Make a Perfect Cuppa: Put Milk in First</em>. <a href="https://www.theguardian.com/uk/2003/jun/25/science.highereducation">https://www.theguardian.com/uk/2003/jun/25/science.highereducation</a>
</div>
<div id="ref-lakens2013" class="csl-entry">
Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs. <em>Frontiers in Psychology</em>, <em>4</em>, 863.
</div>
<div id="ref-peirce1884" class="csl-entry">
Peirce, C. S., &amp; Jastrow, J. (1884). On small differences in sensation. <em>Memoirs of the National Academy of Sciences</em>, <em>3</em>.
</div>
</div>

</div>
</div>



<script type="module" src="/assets/src/index.page.client.jsx.8c839eb7.js"></script><script id="vite-plugin-ssr_pageContext" type="application/json">{"pageContext":{"_pageId":"/src/index","islands":[{"id":"island_0","name":"TOC","props":{}},{"id":"island_1","name":"Box","props":{"title":"!undefined","type":"learning_goals","content":"\n\u003cul>\n\u003cli>Use parameter estimation to compute a causal effect via an experiment\u003c/li>\n\u003cli>Discuss differences between frequentist and Bayesian estimation\u003c/li>\n\u003cli>Reason about standardized effect sizes and their strengths and weaknesses\u003c/li>\n\u003c/ul>\n"}},{"id":"island_2","name":"Box","props":{"title":"The Lady Tasting Tea","type":"case_study","content":"\n\n\u003cp>The birth of modern statistical inference came from a single, epochal act of mansplaining.\u003clabel for=\"tufte-sn-45\" class=\"margin-toggle sidenote-number\">45\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-45\" class=\"margin-toggle\" />\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">45\u003c/span> An important piece of context for the work of Ronald Fisher, Karl Pearson, and other early pioneers of statistical inference is that they were all strong proponents of eugenics. Fisher was the founding Chairman of the Cambridge Eugenics Society. Pearson was perhaps even worse, an avowed Social Darwinist who believed fervently in Eugenic legislation. These views are repugnant.\u003c/span> Sir Ronald Fisher was apparently at a party when a lady declared that she could tell the difference when tea was added to milk vs. milk to tea. Rather than taking her at her word, Fisher devised an experimental and data analysis procedure to test her claim.\u003c/p>\n\u003cp>The basic schema of the experiment was that the lady would have to judge a set of new cups of tea and sort them into milk-first vs. tea-first sets. Her data would then be analyzed to determine whether her level of correct choice exceeded that expected by chance. While this process now sounds like a quotidian experiment that might be done on a cooking reality show, it seems unremarkable only because it literally established the way science was done for the next century.\u003c/p>\n\u003cp>One important and unusual element of the experiment was its treatment of potential design confounds such which cup of tea was prepared first, which cup of tea was presented first, or the material that the cups were made out of. Prior experimental practice would have been to try to equate all of the cups as closely as possible, decreasing the influence of confounds. Fisher recognized that this strategy was insufficient. Only by randomizing all other aspects of the experiment could he make strong causal inferences about the treatment (milk then tea vs. tea then milk). We discussed the causal power of random assignment in Chapter \u003ca href=\"1-experiments.html#experiments\">1\u003c/a> – this experiment is a key touchstone in the popularization of randomized experiments!\u003clabel for=\"tufte-sn-46\" class=\"margin-toggle sidenote-number\">46\u003c/label>\u003cinput type=\"checkbox\" id=\"tufte-sn-46\" class=\"margin-toggle\" />\u003cspan class=\"sidenote\">\u003cspan class=\"sidenote-number\">46\u003c/span> Randomized experiments were not invented by Fisher. Perhaps the earliest example of a (somewhat) randomized experiment was a trial of scurvy treatments in the 1700s \u003cspan class=\"citation\">(\u003ca href=\"#ref-dunn1997\" role=\"doc-biblioref\">Dunn, 1997\u003c/a>)\u003c/span>. \u003cspan class=\"citation\">Peirce &amp; Jastrow (\u003ca href=\"#ref-peirce1884\" role=\"doc-biblioref\">1884\u003c/a>)\u003c/span> also report a strikingly modern use of randomized stimulus presentation (via shuffling cards). Nevertheless, Fisher’s statistical work popularized randomized experiments throughout the sciences, in part by integrating them with a set of analytic methods.\u003c/span>\u003c/p>\n"}},{"id":"island_3","name":"Box","props":{"title":"!undefined","type":"code","content":"\n\u003cp>In this chapter and the subsequent statistics and visualization chapters of the book, we’ll try to facilitate understanding and using these concepts in practice by giving the R code we use in our examples in these code boxes. We’ll assume that you have some knowledge of base R and the Tidyverse – go ahead and take a look at Appendix \u003ca href=\"C-tidyverse.html#tidyverse\">C\u003c/a> if you haven’t already.\u003c/p>\n\u003cp>Since we’re going to be working with lots of data from the tea tasting example, we wrote a function called \u003ccode>make_tea_data\u003c/code> that creates a \u003ccode>tibble\u003c/code> with some (made up) data from our modern tea-tasting experiment.\u003c/p>\n\u003cpre>\u003ccode>tea_data &lt;- make_tea_data(n_total, sigma)\u003c/code>\u003c/pre>\n\u003cp>Here’s what the first few rows of those data look like:\u003c/p>\n\u003ctable>\u003cthead>\u003ctr>\u003cth style=\"text-align: left;\">\ncondition\n\u003c/th>\u003cth style=\"text-align: right;\">\nrating\n\u003c/th>\u003c/tr>\u003c/thead>\u003ctbody>\u003ctr>\u003ctd style=\"text-align: left;\">\nmilk first\n\u003c/td>\u003ctd style=\"text-align: right;\">\n6\n\u003c/td>\u003c/tr>\u003ctr>\u003ctd style=\"text-align: left;\">\nmilk first\n\u003c/td>\u003ctd style=\"text-align: right;\">\n4\n\u003c/td>\u003c/tr>\u003ctr>\u003ctd style=\"text-align: left;\">\nmilk first\n\u003c/td>\u003ctd style=\"text-align: right;\">\n5\n\u003c/td>\u003c/tr>\u003ctr>\u003ctd style=\"text-align: left;\">\nmilk first\n\u003c/td>\u003ctd style=\"text-align: right;\">\n5\n\u003c/td>\u003c/tr>\u003ctr>\u003ctd style=\"text-align: left;\">\nmilk first\n\u003c/td>\u003ctd style=\"text-align: right;\">\n5\n\u003c/td>\u003c/tr>\u003ctr>\u003ctd style=\"text-align: left;\">\nmilk first\n\u003c/td>\u003ctd style=\"text-align: right;\">\n4\n\u003c/td>\u003c/tr>\u003c/tbody>\u003c/table>\n"}},{"id":"island_4","name":"Box","props":{"title":"!undefined","type":"readings","content":"\n\u003cul>\n\u003cli>\u003cp>A great narrative introduction to the history and practice of statistics: Salsburg, D. (2001). \u003cem>The lady tasting tea: How statistics revolutionized science in the twentieth century\u003c/em>. Macmillan.\u003c/p>\u003c/li>\n\u003cli>\u003cp>An open source statistics textbook that follows a similar approach as Chapters \u003ca href=\"5-estimation.html#estimation\">5\u003c/a> – \u003ca href=\"7-models.html#models\">7\u003c/a>: Poldrack, R. (2022). \u003cem>Statistical thinking for the 21st century\u003c/em>. Available free online at \u003ca href>https://statsthinking21.org\u003c/a>.\u003c/p>\u003c/li>\n\u003c/ul>\n"}}]}}</script></body>
</html>
