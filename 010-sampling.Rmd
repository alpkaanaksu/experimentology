# Sampling {#sampling}

::: {.box .learning_goals}
* Learn how to choose an appropriate sample size
* Generalize notion of sample size to other axes of generalizability 
* Reason about limitations of different samples
:::

As we keep reminding you, experiments are designed to yield measurements of a causal effect. But a causal effect of what, and on whom? These are questions that are often given surprisingly little air time in our papers. Titles in our top journals read "Daxy thinking promotes fribbles," "Doing fonzy improves smoodling," or "Blicket practice produces more foozles than smonkers."^[Titles changed to protect the original authors. These researchers might very well have said more specific things in the text of their paper.] Each of these uses **generic language** to state a claim that is implied to be generally true [@dejesus2019],^[Generic language is a fascinating linguistic phenomenon. When we say things like "mosquitoes transmit malaria," we don't mean that *all* mosquitos do it, only something like "it's a valid and diagnostic generalization about mosquitoes in contrast to other relevant insects or other creatures that they are spreaders of malaria" [@tessler2019].] but for each of these, we could reasonably ask "doing fonzy improves smoodling *for whom*?" Is it everyone? Or a particular set of people? And similarly, we might want to ask "*how much* and *what kind* of fonzy reading?" These are questions about the **generalizability of research**.^[Imagine for a second what a non-generic version of one of these titles might look like: "Reading one particular selection of fonzy for fifteen minutes in the lab improved 36 college students' smoodling scores on a questionnaire." It seems pretty clear that we wouldn't let the authors get away with a fully general version of their claim: "Doing [*any*] fonzy improves smoodling [*for anyone*]." That's just a bad generalization.]

We've already run into generalizability in our treatment of statistical estimation and inference. When we estimated a particular quantity (say, the effect of fonzy), we did so in our own sample. But we then used inferential tools to reason about how this **sample**'s estimate related to the **population** as a whole. How do we link up these statistical tools for generalization to the scientific questions we have about the generalizability of our findings? That's the question of this chapter. 

The first key set of decisions in experiment planning is what population to sample from and how to sample. We'll start by talking about the basics of **sampling theory**: different ways of sampling and the generalizations they do and don't license. In this context, we also discuss **stimulus sampling**, a pervasive and under-appreciated challenge to the generalizability of behavioral research. A second set of key decisions is about **sample size** planning. We'll start with classic **power analysis** but then introduce several other ways that an experimenter can plan and justify their sample size. In the final section, we'll consider some of the broader issues that come up in sampling, including several sampling biases that can lead to biases in the experimental effect. We'll end with a discussion of some broader questions about generalizability in behavioral research. 

::: {.box .case_study}
(TITLE) Is everyone as bad at describing smells as I am? 

Since Darwin, scientists have assumed that smell is a vestigial sense in humans -- one that we don’t even bother to encode in language. In English we don't even have consistent words for odors. We can say something is "stinky," "fragrant, or maybe "musty," but beyond these, all our words for smells are about the *source* of the smell, not the qualities of it. Bananas, roses, and skunks all have distinctive smells, but we don't have any vocabulary for naming what is common or uncommon about them. And when we make up ad-hoc vocabulary, it's typically quite inconsistent [@majid2014]. The same situation applies across many languages.

So, would it be a good generalization about human beings -- all people -- that olfaction as a sense is de-emphasized relative to vision? This inference has a classic sample-to-population structure. We notice that, within several samples of participants using widely-spoken languages, we observe limited and inconsistent vocabulary for smells, as well as poor discrimination. We use these samples to license an inference to the population -- in this case, the entire human population. 

```{r sampling-majid2014, fig.margin=TRUE, fig.cap="Data from Majid and Burenhult (2014) on the consistency of color and odor naming in English and Jahai speakers. Higher values indicate more consistent descriptions. Pie charts indicate the type of language being used."}
knitr::include_graphics("images/sampling/majid2014.png")
```

But these inferences about the universal lack of olfactory vocabulary are likely based on choosing the wrong sample. Multiple hunter-gatherer groups appear to have large vocabularies for consistent smell description. For example, the Jahai, a hunter-gatherer group on the Malay Peninsula, have a vocabulary that includes at least twelve words for distinct odors, for example /cŋεs/, which names odors with a "stinging smell" like gasoline, smoke, or bat droppings. When Jahai speakers are asked to name odors, they produce shorter and much more consistent descriptions than English speakers -- in fact, their smell descriptions were as consistent as their color descriptions (Figure \@ref(fig:sampling-majid2014)). Further studies implicate the hunter-gatherer lifestyle as a factor: while several hunter-gatherer groups show good odor naming, nearby horticulturalist groups don't [@majid2018].

Generalizations about humans are tricky. If you want to estimate the average odor naming ability, you could take a random sample of humans and evaluate their odor naming. Most of the individuals in the sample would likely speak English, Mandarin, Hindi, or Spanish. Almost certainly, none of them would speak Jahai, which spoken by only a little more than a thousand people and is listed as [Threatened](https://www.ethnologue.com/language/jhi) by Ethnologue. Your estimate of low odor naming stability would be a good guess for the majority of the world's population. 

On the other hand, it's more complicated to jump from a statistical generalization about average ability to a richer claim, like "as humans evolved, they lost olfactory ability and gained visual ability." Such claims about *what humans are like* require much more care and much stronger evidence [@piantadosi2014]. From a sampling perspective, human behavior and cognition show immense and complex **heterogeneity** -- variability of individuals and variability across clusters. As a result, naive random samples will have very high variance, leading to problematic generalizations. Put simply, if we want to know what people in general are like, we can't just choose a bunch of English speakers on a college campus in the United States. 
:::

## Sampling theory

But we can only measure that effect in a finite number of participants 

The question we consider in this chapter are: for what **population** do we want to estimate the causal effect, and what **sampling** strategy should we pursue in order to make that measurement. 

### Generalization and the goals of sampling


The goal of sampling is generalization: but who do we want to generalize to?

  - Ubiquitous convenience sampling
  - The WEIRD framework (and its weaknesses)
  - Representative sampling and stratification for variance reduction
  - Ethical implications of representation in experimental samples


### Beyond participants: sampling items 

  - What if your effect is generalizable across participants but not across stimuli (Clark 1973).



## Sample planning 

### Classic power analysis

Sample size planning

  - Classic power analysis 
  - Smallest effect size of interest (SESOI analysis)
  - Precision-based sample size planning (Bland 2009; Lash and Kaufman 2015) (malcolmbarrett.shinyapps.io/precisely)
  - Simulation based 
  - Sequential analysis (Schönbrodt et al. 2017)

### Other approaches to sample size planning

sample calculations for within/between subjects
http://daniellakens.blogspot.com/2016/11/why-within-subject-designs-require-less.html
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6640316/

### Repeated measures designs: more people or more items? 

DeBolt and Oakes
Westfall

## Issues in sampling 

### Sampling biases

- Attrition/survivorship bias (connection to directed acyclic graphs [DAGs] as described earlier)
  - Selection bias (connection to DAGs again)


### Heterogeneity and stratification

Where sampling goes wrong:


### Limitations statements



## Summary: Sampling



:::{.box .exercises}
1. Form an argument about this controversial position: We want to understand human cognition generally, but it’s a more efficient research strategy to start by studying certain features of cognition (perception, for example) in WEIRD convenience populations and then later check our generalizations in non-WEIRD groups. 

2. Form an argument about this controversial position: The most influential experiments aren’t generalizations of some number to a population, they are demonstration experiments that show that some particular effect is possible under some circumstances (think Milgram’s conformity studies, where people apparently shocked a confederate at an experimenter’s prompting), so often specific population sampling is secondary.

3. Form an argument about this controversial position: Nothing you learn from US college undergraduates is likely to generalize to the US population as a whole, so we should dramatically decrease the use of this convenience population. 

4. Form an argument about this controversial position: We can’t ever make generalizations about the human mind because so much of the historical human population is simply inaccessible to us (we can’t do experiments on ancient Greek psychology). Psychological samples are also sampling a particular moment in time.
:::