# (PART) Preliminaries {-}

# Experiments {#experiments}

::: {.learning-goals}
üçé Learning goals

* Define ‚Äúexperiment‚Äù, 
* Reason about why researchers run experiments.
* Articulate the role of randomization in experiments.
* Consider constraints on the generalizability of experiments.
:::

Welcome to Experimentology! This is a book all about the art of running experiments in psychology. We‚Äôll tell you all about things like designing good experiments; analyzing data; and even how to keep yourself organized throughout the process. But before we jump in, let‚Äôs start with a fundamental question: why should we do an experiment in the first place.

## Experiments as a Tool for Understanding the World

<<<<<<< Updated upstream
If you‚Äôre reading this book, there‚Äôs probably something about psychology you want to understand. How is it that we experience emotions like happiness and sadness? How is language developed and acquired? Why do humans sometimes work together and other times destroy one another? These are questions that people have pondered for centuries. And through experiments, psychologists hope to turn mere speculation into understanding.

For example, many of us have at one point wondered: does money make people happier? This is a question about **causality**. ^[Defining causality is one of the trickiest and oldest problems in philosophy, and we won't attempt to solve it here! But from a psychological perspective, we're fond of @lewis1973's "counterfactual" analysis of causality. On this view, the claim that, in some situation, if people *hadn't* been given more money, they  *wouldn't* have experienced an increase in happiness.] We are asking if increases in money cause increases in happiness. To visually convey this question, researchers often use **causal graphical models** [@pearl1998]. Figure \@ref(fig:intro-money1) shows an example of such model: Money (X) causes happiness (Y) because there is an arrow pointing from the former to the latter. Researchers may then go a step further and test this question via an experiment, wherein they **manipulate** one variable (money) and then see if there is any change in a **measure** (happiness).
=======
Scientists reason about causal relationships all the time, and it can be helpful to have a way to write down how we think a causal system is structured. For that we use a tool called **directed acyclic graphs** [DAGs; @pearl1998]. Figure \@ref(fig:intro-money1) shows an example of a DAG for money and happiness; The arrow represents our idea about the potential causal link between two variables: money and happiness. The direction of the arrow tells us which way the causal relationship goes. 

How could we test the hypothesized effect of money on happiness? Intuitively, you might consider starting with an **observational study**: you would survey peopled about how much money they made and how happy they were. This would give you a pair of measurements for each participant: [money, happiness].
>>>>>>> Stashed changes

```{r intro-money1, fig.margin=TRUE, fig.cap="The hypothesized causal effect of money on happiness."}
knitr::include_graphics("images/intro/money1.png")
```

<<<<<<< Updated upstream
Running an experiment on money and happiness would require‚Ä¶well a lot of money! But researchers may be willing to pay this price because it‚Äôs hard to answer questions about causality without experiments. For example, imagine that you didn‚Äôt run an experiment, and instead went out into the world and surveyed peopled about how much money they make and how happy they are. (This is often called an observational study.) Imagine you then found that money and happiness were correlated‚Äîpeople with more money tended to be happier. Can you conclude that money causes an increase in happiness? Not necessarily!

‚ÄúCorrelation does not equal causation,‚Äù is a common mantra in psychology. We repeat it time and time again because there are at least three reasons why two variables can be correlated (Figure \@ref(fig:intro-money2)). In the previous example, one could indeed observe a correlation if money makes people happier (X causes Y). However, one would still observe that correlation if the opposite were true: if being happy causes people to make more money (Y causes X). Even more puzzling, it‚Äôs possible that there is a correlation but no causal relationship between money and happiness in either direction. Instead, a third variable‚Äîoften referred to as a **confound**‚Äîmay be causing increases in money and happiness to co-occur. For example, maybe having more friends (Z) causes people to both be happier and make more money. In this scenario, happiness and money would be correlated even though one does not cause the other.
=======
Imagine you found that money and happiness were related--or statistically **correlated** to one another: people with more money tended to be happier. Could you conclude that money causes happiness? Not necessarily. The presence of a correlation does not necessarily mean that there is a causal relationship! There are many alternative causal models that can explain why two variables can be correlated, and only one of them is the causal relationship from money to happiness that we are interested in.

To describe this situation, we can once again use DAGs (see Figure \@ref(fig:intro-money2)). You could observe a correlation if money makes people happier (DAG #1), but you would still observe that correlation if the opposite were true: if being happy causes people to make more money (DAG #2). Even more puzzling, there could be a correlation but no causal relationship between money and happiness in either direction. Instead, a third variable‚Äîoften referred to as a **confound**‚Äîmay be causing increases in money and happiness to co-occur. For example, maybe having more friends causes people to both be happier and make more money (DAG #3). In this scenario, happiness and money would be correlated even though one does not cause the other. Another way of thinking about this confound is as something that **biases** our estimated casual effect. The correlation is an estimate of the causal effect of  money on happiness. But the estimate might be biased upward by the friendship confound; in fact, that bias could be so strong that we might conclude there *was* a causal relationship when there wasn't any.

The state of affairs summarized in Figure \@ref(fig:intro-money2) is why we say "correlation doesn't imply causation." A correlation between two variables *is consistent with* a causal relationship between them, but it's also consistent with other relationships as well.^[People sometimes ask whether *causation implies correlation* (the opposite direction). The short answer is "no." A causal relationship between two variables often means that they will be correlated in the data, but not always. For example, imagine you measured the speed of a car and the pressure on the gas pedal. In general, pressure and speed will be correlated, consistent with the causal relationship between the two. But now imagine you only measured these two variables when someone was driving the car up a hill -- now the speed would be constant but the pressure might be increasing, reflecting the driver's attempts to keep their speed up. So there would be no correlation between the two variables in that dataset, despite the continued causal relationship.]
>>>>>>> Stashed changes

```{r intro-money1, fig.margin=TRUE, fig.cap="Three reasons why money and happiness can be correlated."}
knitr::include_graphics("images/intro/money2.png")
```

<<<<<<< Updated upstream
Running an experiment where one manipulates money and then measures happiness brings us one step closer to understanding the world. But experiments need at least one more thing to be effective: **randomization**.
=======
## Experiments help us answer causal questions

Imagine that you (a) created an exact replica of our world, (b) gave \$1,000 to everybody in the replica world, and then (c) found a few years later that everyone was happier than their matched self in the original world. This experiment would provide strong evidence that money makes people happier. Let's think through why.

Think about a particular person in the replica world -- if they are happier, what could explain that difference? Since we have replicated the world exactly but made only one change -- money -- then that change is the only factor that could explain the resulting difference in happiness. We can say that we **held all variables constant** except for money, which we **manipulated** experimentally, observing its effect on some **measure**. This idea -- holding all variables constant except for the specific experimental manipulation -- is the basic logic that underpins the experimental method [as articulated by @mill1859].^[Another way to reason about why we can infer causality here follows the counterfactual logic we described in an earlier footnote. If the definition of causality is counterfactual ("what would have happend if the cause had been different"), then this experiment fulfills that definition. In our impossible experiment, we can literally *see* the counterfactual: if the person had \$1,000 more, here's how much happier they would be!] 
>>>>>>> Stashed changes

## Randomization

<<<<<<< Updated upstream
Earlier, we mentioned that the number of friends a person has is a potential confound when studying whether money increases happiness. This can continue to be a problem in experiments, particularly if we do not use randomization. For example, imagine that friends‚Äînot money‚Äîincreases happiness. You run an experiment where you manipulate money, but the group you give cash to has more friends than the group that does not receive cash. In this scenario, the group that received cash would have higher levels of happiness. However, it's because they had more friends‚Äînot because they received money.

Experimenters typically address this issue through randomization. If you randomly pick who gets to receive money, the money and no-money groups will, on average, have a similar number of friends. Thus, randomization helps us control for the known confound of friends. Impressively, randomization also helps us control for *unknown* confounds. For example, you can imagine that there are many things that might increase happiness other than money: owning a dog, exercising regularly, reading *Experimentology*. Fret not! With randomization, the money and no-money groups will, on average, be equal in all these things.

To speak metaphorically, randomization is a critical ingredient in the recipe of experimental psychology. Without it, the cake simply doesn‚Äôt rise. There is a caveat, though: randomization doesn‚Äôt always work. *On average*, randomization will ensure that your money and no-money groups will be equal with respect to confounds like number of puppies and friends. But just as you can flip a coin and sometimes get heads 9 out of 10 times, sometimes you use randomization and still get more dog owners in one condition that the other. Like many concepts we‚Äôll discuss in this book, randomization won‚Äôt guarantee a perfect experiment. But it‚Äôs our best bet at accurately estimating causal relationships.
=======
If we were talking about experiments with cake baking, it would be easy to see that we could hold all of the ingredients constant and just vary one thing (like baking temperature). This would provide a strict experimental test of the effect of baking temperature. But how we can "hold something constant" when we're talking about people?  People aren't cakes; no two people are alike and even if you "hold the ingredients constant" they don't come out the same! If we choose one person to give money to and another, we are comparing two *different* people, not two instances of the same person with everything held constant. It doesn't work to  *make* the first person have more or fewer friends so they match the second person -- that's not holding anything constant, instead it's another (big, difficult, and potentially unethical) intervention that might itself cause lots of effects on happiness. 

You may be wondering: why don‚Äôt we just ask people how many friends they have and use this information to split them into equal groups? You could do that, but this only allows you to control for the confounds you know of. For example, you may split people equally based on their number of friends but not their education attainment. If educational attainment impacts both money and happiness, you run back into issues with confounds. You may then try to split people by both their number of friends and education. But perhaps there‚Äôs another confound you‚Äôve missed: sleep quality! Similarly, it  doesn't work to select people who have the same number of friends -- that only holds the friends variable constant and not everything *else* that's different between the two people. So what do we do instead?

```{r intro-money3, fig.margin=TRUE, fig.cap="In principle, experiments allows us to \"snip away\" the friend confound by holding it constant (though in practice, it can be tough to figure out how to hold something constant when you are talking about people as your unit of study)."}
knitr::include_graphics("images/intro/money3-drawing.png")
```

The answer is **randomization**. If you randomly split a large roomful of people into two groups, the groups will, on average, have a similar number of friends. Similarly, if you randomly pick who in your experiment gets to receive money, you will find that the money and no-money groups, on average, have a similar number of friends. In other words, through randomization, the confounding role of friends is controlled. But the most important thing is that it's not *just* the role of friends that's controlled; educational attainment, sleep quality, and all the other confounds are controlled as well. If you randomly split a large group of people into groups, the groups will, on average, be equal in every way (Figure \@ref(fig:intro-money4)).

```{r intro-money4, fig.margin=TRUE, fig.cap="If you randomly split a large group of people into groups, the groups will, on average, be equal in every way."}
knitr::include_graphics("images/intro/money4-drawing.png")
```

Randomization is a powerful tool, but there is a caveat: it doesn‚Äôt work every time. *On average*, randomization will ensure that your money and no-money groups will be equal with respect to confounds like number of friends, education attainment, and sleep quality. But just as you can flip a coin and sometimes get heads 9 out of 10 times, sometimes you use randomization and still get more highly-educated people in one condition that the other. When you randomize, you guarantee that on average all confounds are controlled and hence these do not bias your estimate.  

In sum, randomization is a remarkably simple and effective way of holding everything constant besides a manipulated variable. In doing so, randomization allows experimental psychologists to make unbiased estimates of causal relationships. Importantly, randomization works both when you do have control of every aspect of the experimental subjects -- like when you are baking a cake -- and even when you don't -- like when you are doing experiments about people. 
>>>>>>> Stashed changes

## Generalizability 

When we are asking questions about psychology, it‚Äôs important to think about who we are trying to study. Do we want to know if money increases happiness in all people? In people who live in materialistic societies? In people whose basic needs are not being met? We call the group we are trying to study our **population-of-interest**, and the people who actually participate in our experiment our **sample**.

People often forget the distinction between samples and populations. They may wish to make a conclusion about all people (their population-of-interest) but run their experiment with U.S. college students (their sample).^[Unfortunately, psychologists pervasively mistakenly assume that research on U.S. college samples generalizes to the rest of the world. To highlight this issue, Henrich et al. (2010) coined the acronym WEIRD. This catchy name describes the oddness of making generalizations about all of humanity from experiments on a sample that is quite unusual because it is Western, Educated, Industrialized, Rich, and Democratic. Henrich and colleagues argue that seemingly ‚Äúfundamental‚Äù psychological like visual perception, spatial cognition, and social reasoning all differ pervasively across populations ‚Äì hence, any generalization from an effect estimated with a WEIRD subpopulation is unwarranted.] This is not always a problem, but often times causal relationships are different for different populations. For example, in the early 2000‚Äôs, some researchers found that gratitude interventions‚Äîlike writing about something nice somebody did for you‚Äîincreased happiness in studies conducted in Western countries. Based on these findings, some psychologists believed that gratitude interventions could increase happiness in all people. But it seems they were wrong. A few years later, @layous2013culture ran a gratitude experiment in two locations: the U.S. and South Korea. Surprisingly, the gratitude intervention decreased happiness in the South Korean sample‚Äîwhich they attributed to feelings of indebtedness that people in South Korea more prominently experienced when reflecting on gratitude.

<<<<<<< Updated upstream
In the previous example, we would say that the findings obtained with the U.S. sample do not generalize to people in South Korea. Unfortunately, these generalizability issues do not end with our sample of participants. For example, the way that researchers design their experimental manipulations can also limit the generalizability of their conclusion. For instance, giving somebody \$1,000 cash may have a different effect on happiness than giving them a \$1,000 gift card to a coffee shop located several towns over. Participants in both scenarios received the cash-equivalent of \$1,000, but the way that this was done mattered. As we'll see in Chapters @ref(models) and @ref(design), this issue has consequences for both our statistical analyses and our experimental designs [@yarkoni2020].
=======
In the early 2000‚Äôs, some researchers found that gratitude interventions -- like writing a brief essay about something nice that somebody did for you -- increased happiness in studies conducted in Western countries. Based on these findings, some psychologists believed that gratitude interventions could increase happiness in all people. But it seems they were wrong. A few years later, @layous2013culture ran a gratitude experiment in two locations: the U.S. and South Korea. Surprisingly, the gratitude intervention *decreased* happiness in the South Korean sample. The researchers attributed this negative effect to feelings of indebtedness that people in South Korea more prominently experienced when reflecting on gratitude. In this example, we would say that the findings obtained with the U.S. sample do not **generalize** to people in South Korea. 
>>>>>>> Stashed changes

Questions of generalizability are pervasive, but the first step is to simply acknowledge and reason about them. For example, @simons2017 has argued that all papers should have a Constraints on Generality statement, wherein people discuss whether they expect their findings to generalize across different samples, experimental stimuli, procedures, and historical and temporal features. This idea reminds us experimenters to be humble: experiments are a powerful tool for understanding how the world works, but there are often limits to what they can teach us. 


## Experiments: Chapter summary

In this chapter, we defined an experiment as a combination of a manipulation and a measure. We discussed how, when combined with randomization, experiments allow us to make strong causal inferences about psychology. Nonetheless, we highlighted that there are limits to the power of experiments: that there are often constraints to the generalizability of the sample, experimental stimuli, procedure, and historical features. Nonetheless, one thing was hopefully clear: experiments are an extremely useful tool in the psychologist‚Äôs toolbelt.

Throughout the chapter, we relied on a relatively simple causal hypothesis: does money increase happiness. However, often in psychology, we seek to not just test simple hypotheses‚Äîbut to build theories about how the world works. For example, we might want to build a theory that explains how social, cognitive, and physiological processes come together to shape peoples‚Äô happiness. We‚Äôll talk more about this theory building practice in Chapter 2. 

::: {.exercise}
Imagine that you run a survey and find that people who spend more time playing violent video games tend to be more aggressive (i.e., that there is a positive correlation between violent video games and aggression). Following Figure \@ref(fig:intro-money2), list three reasons why these variables may be correlated
::: 

::: {.exercise}
Imagine that you wanted to run an experiment that tests whether playing violent video games causes increases in aggression. What would be your manipulation and what would be your measure? How would you control for a potential confound, like age?
::: 

::: {.exercise}
Imagine that Dr. Brock O‚Äôlee wanted to know if humans prefer vegetables over meat. He randomly assigns 30 U.S. pre-schoolers to be served either asparagus or chicken tenders and then asks them how much they enjoyed their meal. He finds that they enjoyed the meat more and subsequently writes a paper declaring that humans prefer meat over vegetables.

List some constraints on the generalizability of this study. Do you believe that results would differ if he sampled (a) a different age group, (b) a different world region, and (c) different vegetables and meats? Do you believe the results will differ in the same study is re-run in 50 years?
::: 
