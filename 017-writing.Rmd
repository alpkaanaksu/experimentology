<!-- # (PART) Reporting and contextualizing {-} -->

# Writing {#writing}

::: {.learning-goals}
üçé Learning goals: 

* Write clearly by being concise, using structure, and adjusting to your audience.
* Write reproducibly by interleaving writing and analysis code.
* Write responsibly by acknowledging limitations, correcting errors, and calibrating your conclusions.
:::

All of the effort you put into designing and running an effective experiment may be wasted if you cannot clearly communicate what you did^[Clarity of communication was a founding principle of modern science. Early protoscientists conducting alchemical experiments often made their work deliberately obscure - even writing in cryptic codes - so that others could not discover the 'powerful secrets of nature'. Pioneers of scientific methodology, like Francis Bacon and Robert Boyle, pushed instead for transparency and clarity. Notoriously, Issac Newton (originally an alchemist and later a scientist), continued to deliberately write in an obscure fashion in order to 'protect' his work. For more details, see chapter 1 of @heard2016.]. Scientists usually share their research by writing journal articles. Writing is a powerful tool - though you contribute to the conversation only once, it enables you to speak to a potentially infinite number of readers. So its important to get it right! In this chapter, you will learn how to communicate your research accurately, transparently, and professionally, by writing clearly, reproducibily, and responsibly.

## Writing clearly

What is the purpose of writing? ‚ÄúTelepathy, of course‚Äù says Stephen King [@king2000]. The goal of writing is to transfer information from your mind to the reader's mind as effectively as possible. Unfortunately, for most of us writing clearly does not come naturally; it is craft we need to work at. 

One of the most effective ways to learn to write clearly is to read and, unsurprisingly, writing. Just as you learned to talk by imitating the speech of your parents and teachers, you can learn to write by imitating what you read. Unfortunately, many scientific articles are not clearly written, so you will need to be selective. Fortunately, as a reader, you will know good writing when you see it ‚Äî you will feel like the writer is seamlessly transferring ideas from their mind to yours. When you come across writing like that, try to find more work by the same author and read that too. The more you read, the more you will develop a sense of what works well, and what does not. You may pick up bad habits as well as good ones (we sure have), but over time, your writing will improve if you make a conscious effort to weed out the bad, and keep ahold of the good. 

There are no strict rules of clear writing, but there is some generally accepted guidance and conventions [@zinsser2006; @heard2006; @gernsbacher2018] that we will share with you here. 

### Use words wisely

* **Be explicit**. Avoid vagueness and ambiguity. The more you leave the meaning of your writing to your reader's imagination the greater the danger that different readers will imagine different things! So be direct and specific.

* **Be concrete**. Concrete examples make abstract ideas easier to grasp. Diagrams can also be helpful; for example, it may be clearer to illustrate a complex series of exclusion criteria using a flow chart rather than text. You can also use videos and screen capture software to directly demonstrate experimental tasks or researcher interactions with participants [@heycke2019].

* **Be consistent**. Referring to the same concept using different words can be confusing. It may not be clear if you are using a synonym or referring to a different idea. For example, in everyday conversation, "replication" and "reproducibility" may sound like two different ways to refer to the same thing, but in scientific writing, these two concepts have different technical definitions, so we should not use them interchangeably. Define each technical term once and then use the same term throughout the manuscript.

* **Be concise**. Its much easier to hear someone shouting your name in an empty field than in a dense forest. Maximise the signal to noise ratio in your writing by omitting needless words and removing clutter [@zinsser2006]. For example, say *we investigated* rather than *we performed an investigation of* and say *if* rather than *in the event that*. Don't try to convey everything you know about a topic ‚Äî a research report is not an essay. Include only what you need to acheive the purpose of the article and exclude everything else.

* **Use active voice**. Scientists have a peculiar habit of reporting their research in a way that avoids referring to themselves. For example, scientists sometimes write "the data were analysed" or, worse, "an analysis of the data was carried out". These are examples of 'passive voice'. Its usually better to use 'active voice', where you clearly identify the relevant actor. In this example, you can say "we analyzed the data". √üScientists might use passive voice because it feels more objective, but that's just an illusion. Moreover, passive voice is often long-winded and ambiguous ‚Äî the reader is left uncertain as to who or what analyzed the data. Was it the researchers? A statistician they recruited? Artificial intelligence? Another common example of passive voice is the phrase "it is believed that" which leaves the reader unsure about who is doing the believing. Active voice - "we believe that" or "scientists believe that" - is much clearer.

* **Adjust to your audience**. Most of us adjust our conversation style depending on who we're talking to and the same principle applies to good writing. Knowing your audience is more difficult with writing, because we cannot see the reader's reactions and adjust accordingly. Nevertheless, we can make some educated guesses about who our readers might be. For example, if you are writing a review article for an interdisciplinary journal, you may need to pay more attention to explaining complex topics for a novice readership compared to writing a research article for a domain-specific journal.

* **Check your understanding**. Unclear writing can be a symptom of unclear thinking. If an idea doesn't make sense in your head, how will it ever make sense on the page? In fact, trying to communicate something in writing is an excellent way to probe your understanding and expose logical gaps in your arguments. So if you are finding it difficult to write clearly, stop and ask yourself *do I know what want to say*? If the problem is unclear thinking, then you need to address that first, for example by consulting a textbook or colleague/advisor. Importantly, you must resist the temptation to mask unclear thinking in unclear writing. Sometimes, your thinking will be unclear simply because *nobody* understands the topic you are addressing. Indeed, we should expect that to happen; the whole point of research is to expand the frontiers of human knowledge, so naturally, you will find yourself working on the faultline of what is and what is not well understood. If you have unresolveable uncertainty about something, say so explicitly, don't hide it in bad writing.

* **Use acronyms sparingly**. Its tempting to replace lengthy terminology with short acronyms ‚Äî why say "cognitive dissonance theory" when you can say "CDT"? Unfortunately, acronyms can increase the reader's cognitive burden and cause misunderstandings^[@barnett2020 found that acronyms are widely used in research articles and argued that they undermine clear communication. Here is one example of text Barnett and Doubleday extracted from a 2019 publication to illustrate the point: "Applying PROBAST showed that ADO, B-AE-D, B-AE-D-C, extended ADO, updated ADO, updated BODE, and a model developed by Bertens et al were derived in studies assessed as being at low risk of bias.‚Äô]. For example, if you shorten "odds ratio" to "OR", the reader has to take the extra step of translating "OR" back to "odds ratio" every time they encounter it. The problem multiplies as you introduce more acronyms into your article. Worse, for some readers, "OR" tends to mean "operating room", not "odds ratio". Acronyms can be useful, but usually when they are widely used and understood. For example, "magnetic resonance imaging" ("MRI") and "deoxyribonucleic acid" (DNA). At a minimum, be sure to define all acronyms, even when they are likely to be familiar to most readers.

* **Have fun**. Scientific writing has a reputation for being dry, dull, and soulless. Whilst its true that scientific writing is more constrained than fiction, there are still ways to surprise and entertain your reader with metaphor, alliteration, and even humour. As long as your writing is clear and accurate, we see no reason why you cannot also make it enjoyable. Enjoyable articles are easier to read and more fun to write.

### Use structure

Without structure, your reader will be left adrift in an ocean of complexity. Structure gives readers anchor points to hold on to and signposts to navigate by.^[Structure helps writers as well as readers. Try starting the writing process with section headings as a skeleton structure, then flesh it out, layer by layer. In each section, make a list of the key points you want to convey, each representing the first sentence of a new paragraph. Then add the content of each paragraph and you'll be well on your way to having a full first draft of your article.] Academic writing is usually organised into a hierarchy of meaningful units: sections, paragraphs, and sentences, sprinkled with cross-references. We provide guidance on each of these below.

```{r imrad, fig.cap="Conventional structure of a research article. The main body of the article consists of Introduction, Methods, Results, and Discussion (IMRaD) sections. The body is preceded by the abstract ‚Äî a summary that also follows the IMRaD structure, though not necessarily with explcit sub-headings. The abstract and the body are sandwiched in-between the front matter and back matter sections. The front matter contains the title, author names and author note. Sometimes the front matter includes  conflicts of interest and funding statements, and author contributions, though sometimes they are in the back matter. The back matter includes acknowledgements and references. Reproduced from Hardwicke (2022; https://osf.io/nw93u/) under a CC-BY license.", fig.margin=TRUE}
knitr::include_graphics("images/writing/imrad.png")
```

* **Section structure**. A scientific paper is not like a novel - rather than reading from beginning to end, readers typically jump between sections to efficiently extract the information most relevant to them. This is possible because research articles typically follow the same^[Some journals mix things up a bit, for example, putting the methods section at the end of the article or combining the results and discussion sections; however, most psychology journals tend to follow the guidance of the American Psychological Association, which recommends IMRaD.] conventional structure (see Figure \@ref(imrad)). The main body of the article includes four main sections: Introduction, Methods, Results, and Discussion (IMRaD)^[In the old old days, there were few conventions - scientists would share their latest findings by writing letters to each other. But as the number of scientists and studies increased, this approach became unsustainable. The IMRaD structure gained traction in the 1800s and became dominant in the mid-1900s as scientific productivity rapidly expanded in the post-war era. We think IMRaD style articles are a big improvement, even if it is nice to receive a letter every now and again.]. This structure has a narrative logic: what's the knowledge gap? (introduction); how did you address it (methods); what did you find (results); what do the results mean? (discussion).

* **Hourglass structure**. Imagine that the breadth of focus in the body of your article has an 'hourglass' structure (see Figure \@ref(imrad)). The start of the introduction should have a broad focus ‚Äî provide the reader with the general context of your study. From there, the focus of the introduction should get increasingly narrow until you are describing the specific knowledge gap or problem you will address and (briefly) how you are going to address it. The methods and results sections are at the center of the hourglass because they are tightly focused on your study alone. In the discussion section, the focus shifts in the opposite direction, from narrow to broad. Begin by summarising the results of your study, discuss limitations, then integrate the findings with existing literature and describe practical and theoretical implications.
  
*  **Paragraph structure**. Each paragraph should focus on conveying one main message. 'P-E-E-L' (Point-Explain-Evidence-Link) is a useful paragraphing structure, particularly in the introduction and discussion sections. Firstly, state the paragraph's message succinctly in the first sentence (P). The core of the paragraph is dedicated to further explaining the point and providing evidence (E-E; you can also include a third 'E' ‚Äî an example). At the end of the paragraph, take a couple of sentences to remind the reader of your point and set up a link to the next paragraph. Think of it like a relay race where the baton (your message) is passed seamlessly between paragraphs.
  
* **Sentence structure**. Long, complex sentences can be confusing and difficult to process. On the other hand, if you only use short sentences your writing may come across as monotonous and robotic. Try varying the sentence length to give your writing a more natural rhythm. Just avoid trying to cram too much information into the same sentence. You can also use sentence structure as a scaffold to support the reader's thinking. Start sentences with something the reader already knows before introducing new information. For example, rather than writing "We performed a between-subjects t-test comparing performance in the experimental and control groups to address the cognitive dissonance hypothesis", write "To address the cognitive dissonance hypothesis, we compared performance in the experimental group and control group using a between-subjects t-test".

* **Cross-referencing**. Research articles are often packed with complex information and its easy for readers to get lost. A 'cross reference' is a helpful signpost that tells readers where they can find relevant additional information without disrupting the flow of the your writing. For example, you can refer the reader to data visualizations by cross referencing to figures or tables (e.g., "see Figure 1"), or additional methodological information in the supplementary information (e.g., "see Supplementary Information A"). You can also cross reference your research aims/hypotheses to remind readers how different methods, results, and inferences relate back to your research goals. For example, you could add separate sub-headings in your results section to address hypotheses A, B, C, etc.

## Drafting

* **Get feedback**. It can be difficult to judge if our own writing has achieved its telepathic goal. If possible, try to get feedback from somebody in your target audience. 

* **The reader is (usually) right**. Its tempting to blame the reader when your writing to convey its message. Criticism can sting, especially after spending many hours writing. But if a reader has gone to the effort of sharing feedback with you, its probably a fair assumption that they've made a reasonable effort to understand your writing. In this case, it is your writing, rather than the reader, that is at fault, and you need to fix it.

* **Rewrite**. Think of the article you are writing as a garden. Your first draft may be an unruly mess of intertwined fronds and branches. Several rounds of pruning and sculpting will be needed before your writing reaches its most effective form. You'll be amazed how often you find words to omit, terms you can define more precisely, or elaborate sentence structures you can simplify. ^[On the other hand, don't be paralyzed by perfectionism. At some point its time to send the article to your co-authors for a fresh set of eyes.] 

## Writing reproducibly

In chapters \@ref(replication) you learned how research results are sometimes not reproducible ‚Äî that is, they cannot be recreated by repeating the original analyses on the original data. Fortunately, there are number of tools and techniques available that you can use to write reproducible research reports. The basic idea is to create an unbroken chain that links every single part of the data analysis pipeline, from the raw data through to the final numbers reported in your research article. This enables you to trace the provenance of every number and recreate (reproduce) it from scratch.

### Why write reproducible papers?

There are at least three reasons to write reproducible reports:

1. **Accuracy**. Data analysis is an error-prone activity. Without safeguards in place, it can be easy to accidentally overwrite data, mislabel experimental conditions, or copy and paste the wrong statistics. One study found that nearly half of around 30,000 published psychology papers contained statistical reporting errors; 10% of reported p-values were inconsistent with other reported details of the statistical test, and 1.6% were "grossly" inconsistent (the difference between the p-value and the test statistic meant that one value implied statistical significance and the other did not) [@nuijten2016]. You can reduce opportunities for error by adopting a reproducible analysis workflow that avoids error-prone manual actions, like copying and pasting.

2. **Transparency**. Technical information about data analysis can be difficult to communicate in writing ‚Äî written prose is often ambiguous and its possible to leave out important details [@hardwicke2018b]. By contrast, a reproducible workflow documents the entire analysis pipeline from raw data to research report exactly as it was performed (\@ref(fig:chain)). This directly communicates to other researchers the exact origin of any reported values allowing them to assess, verify, and repeat the analysis process.

3. **Efficiency**. Data analysis often involves repeating the same steps. For example, you may run your analysis and realize you forgot to perform the data exclusions. You may produce a graph and decide you'd prefer a different colour scheme. Or perhaps you want to output the same results table in a pdf document to submit to a journal and in a Powerpoint slide for a presentation. In a reproducible workflow, all of the analysis steps are scripted, and can be easily re-run at the click of a button. You (and others) can re-use parts of your code in other projects, rather than having to re-write everything from scratch.

### Principles of reproducible writing

Here we outline some general principles of reproducible writing. To learn how to implement these principles in practice, please see Appendix \@ref(rmarkdown).

* **Never break the chain**. Every step of the analysis pipeline should be linked together programmatically (i.e., by computer code). This allows everything to be re-run from scratch without any requiring any manual actions.

* **Script everything**. Try to ensure that each step of the analysis pipeline is executed by computer code rather than manual actions, like copy and paste. This ensures that every step is documented in its most literal form, ensuring it can be reproduced. Imagine, for example, that you decided to recode a variable in your dataset. You could use the 'find and replace' function in Excel, but this action would not be documented ‚Äî you might even forget that you did it! A better option would be to write an R script.

* **Use literate programming**. The meaning of a chunk of computer code is not always obvious to another user, especially if they're not an expert. Indeed, we frequently look at our own code and scratch our heads wondering what on earth its doing. To avoid this, its helpful to frequently insert plain language comments into your code ‚Äî a style known as 'literate programming' because you spell out literally what the code is doing [@knuth1992].

* **Use defensive programming**. Errors can still occur in scripted analyses. Defensive programming is the idea that we should try to anticipate, detect, and avoid errors in advance. A typical defensive programming tool is the inclusion of 'tests' in your computer code. For example, let's say that 200 participants took part in your study. You pass your data through a series of preprocessing steps and then apply some functions to generate summary statistics. After the preprocessing, it would be helpful to include a brief line of code that checks if there are still 200 participants included in the dataset and you haven't inadvertently excluded any.

* **Use free/open-source software**. If possible, avoid using commercial software, like SPSS or Matlab, and instead use free, open-source software, like JASP, Jamovi, R, or Python. This will make it easier for others to access, reuse, and verify your work - including yourself! It would be very unfortunate to have spent your PhD learning Matlab and then find your new employer does not have a Matlab software license.

* **Use version control**. In Chapter 14 (see Appendix B for tutorial), we introduced you to the benefits of version control - a great way to incrementally save your analysis pipeline as you build it, helping you to roll-back to previous version if you accidentally introduce errors.

* **Preserve the computational environment**. Even if your analysis pipeline is entirely reproducible on your own computer, you still need to consider whether it will run on somebody else's computer, or even your own computer after you have updated your software. You can address this by documenting and preserving the computational environment in which the analysis pipeline runs successfully. Various tools are available to help with this, such as Code Ocean, renv (for R), and pip (for Python).

### The reproducibiltiy-collaboration trade-off
We would love to just leave it here and watch you walk off into the sunset with a spring in your step and a reproducible report under your arm, end of story. Unfortunately, we have to admit that writing reproducibly can create a few practical difficulties when it comes to collaboration. A major aspect of collaboration is exchanging comments and inline text edits with co-authors. You can do this with R Markdown files and Git, but these tools are not as user-friendly as, say, Word or Google Docs and many collaborators will be completely unfamiliar with them. Most journals also expect articles to be submitted as Word documents and outputing R Markdown files to Word can often introduce formatting issues, especially for moderately complex Tables. So until more user-friendly tools are introduced, some compromise between reproducibility and collaboration may be necessary. Here are three workflow styles we have used in our own work:

1. The **maximal reproducibility** approach. If your collaborators are familiar with R Markdown and you don't mind exchanging comments and edits via Git, then you can maintain a fully reproducible workflow for your project, at least up until you release a preprint of your work. The journal submission and publication process may still introduce some issues (like incorporating changes made by the copy editor), but at least your preprint will be fully reproducible.

2. The **two worlds** approach. This workflow is a bit clunky, but it facilitates collaboration and maintains reproducibility. Firstly, generate your results section via R Markdown and export to a Word document. Copy and paste the entire results section into an empty Google Doc. Write the remainder of the manuscript in the Google Doc, including incorporating comments and changes from collaborators. When everyone's happy you have a final version, copy and paste the abstract, introduction, methods, and discussion into the R Markdown document. Integrate any changes made to the results section requires a bit more effort. Save the Google Doc as a Word document and compare it to the original Word results section using Word's "compare documents" feature. New changes will be highlighted. Manually integrate the changes into the R Markdown file. You can use "compare documents" again to ensure the version of the Word document generate by your R Markdown file aligns with the one you wrote with your collaborators (barring some formatting differences). The advantage of this approach is that you have a reproducible document and your collaborators have not had to deviate from their preferred workflow. Unfortunately, it requires more effort from you.

3. The **reproducibility-lite** approach. !!! Actually not sure what this is... seems similar to above.

## Writing responsibly

No study is perfect. Even the most rigorously designed research will have limitations, simply because doing science is hard! Errors are also likely to occur, because we're only human, and we make mistakes.

Its your responsibility to communicate all relevant information about your study to enable other scientists to make an informed assessment. This includes methodological information, but also additional contextual information, like potential conflicts of interest or deviations from a preregistration. Finally, you will need to meet some scholarly obligations with regards to authorship and citations.

### Responsible disclosure and interpretation

* **Show your work**. Back in school, we all learned that getting the right answer is not enough, you need to demonstrate how you arrived at that answer in order to get full marks. The same expectation applies to research reports. Don't just tell the reader what you found, tell them how you found it. That means providing *all* methodological details^[Its pretty easy to overlook key details, especially when you reach the end of a project. Looking back at your study preregistration can be a helpful reminder. Reporting guidelines are also a helpful resource to reminder you of the key information that should be reported for different research designs (see @appelbaum2018)], including data, materials, and analysis scripts,. You do have some flexibility in terms of how much detail you provide in the main body and how much you relegate to the supplementary information. Readers have different needs; some may just want to know the highlights, and some will want to replicate your study and therefore need all the details. As a rule-of-thumb, try to make sure there is nothing in the supplementary information that would surprise the reader. You certainty should not use the supplementary information to hide important details or use it as a disorganized dumping ground - the principles of clear writing still apply here!

* **Acknowledge limitations**. All studies inevitably have limitations; for example, if your sample consisted only of university students or only used two different stimuli, the study may have limited generalizability. Think carefully about the limitations of your study and state these limtations clearly in the discussion section.

* **Don't overclaim**. Unfortunately, scientists often feel (and often are) evaluated based on the results of their research rather than the quality of the research. Consequently, it can be tempting to make bigger and bolder claims about your research than are really justified by the evidence. Think carefully about the limitations of your research and calibrate your conclusions to the evidence your have obtained, rather than what you hope to be able to claim. Ensure that your conclusions are appropriately stated throughtout the manuscript, including the title and abstract^[Overclaiming in titles is particularly common. Its usually best to avoid stating conclusions in the title at all because there are fewer words available to properly hedge and provide context. Instead, your title should focus on the research aim and method, for example, "Does post-event exposure to misinformation disrupt recall accuracy of eyewitnesses? An experimental investigation"].

* **Discuss, don't debate**. In the discussion section, your job is to help the reader interpret your research. Importantly, it is not a debate - don't feel the need to argue dogmatically for a particular position or interpretation ^[The goal of a debate is to win, the goal of a discussion is to exchange ideas.]. You should discuss the strengths and weaknesses of the evidence you can obtained, and the reletive merits of different interpretations. For example, perhaps there is a potential confounding variable that you were unable to eliminate with your research design. The reader might be able to spot this themselves, but regardless, its your responsibility to highlight it for them. Perhaps on balance you think the confound is unlikely to explain the results - that's fine, but you need to explain your reasoning to the reader.

* **Disclose conflicts of interest and funding**. Researchers are usually personally invested in the outcomes of their researcher and this can lead to bias (for example, overclaiming). However, sometimes the personal gains from researcher rise above a particular threshold and are considered 'conflicts of interest' that should be disclosed to readers. The most obvious conflicts of interest occur when you stand to benefit financially from the outcomes of your research (for example a pharmaceutical company evaluating their own drug). Where the threshold lies is not always completely clear. If in doubt, disclose it.

* **Report transparently**. In Chapter \@ref(preregistration), you learned about the problem of selective reporting and how it can bias research results and conclusions. The accident report describes how NOT to do it. There are several ways to avoid this in your own work. Firstly, assuming you have reported everything, include a statement in the methods section that explicitly says so. A statement suggested by @simmons2012 is ‚ÄúWe report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study.‚Äù If you have preregistered your study, clearly link to the preregistration and state whether you deviated from your original plan. You can include a detailed preregistration disclosure table in the supplementary information and highlight any major deviations in the methods section. In the results section, clearly identify (e.g., with sub-headings) which analyses were preplanned and included in the preregistration (confirmatory) and which were not planned (exploratory).

::: {.accident-report}
‚ö†Ô∏è Accident report: How (not) to write a research article. Daryl Bem‚Äôs infamous HARKING chapter encouraged people to tell a post-hoc story about data, but this practice is very problematic (Bem 1987). Contrast Bem and Gernsbacher (https://doi.org/10.1177/2515245918754485) guides to writing
:::

### Responsible handling of errors

Its not your responsibility to design perfect studies or never make mistakes. But it *is* your responsibility to respond to errors in a transparent and professional manner ^[As jazz musician Miles Davis once said, ‚ÄúIf you hit a wrong note, it‚Äôs the next note that you play that determines if it‚Äôs good or bad.‚Äù]. Regardless of how the error was identified (e.g., yourself or a reader), we recommend contacting the journal^[If there is also a preprint of your article available, you should also update it with a correction statement.] and requesting that they publish a correction statement^[Sometimes a correction statement is called an **erratum**.]. Several of us have corrected papers in the past. If the error is serious and cannot be fixed, you should consider retracting the article. The correction/retraction statement should include the following information:

1. **Acknowledge the error**. Be clear that an error has occurred.
2. **Describe the error**. Readers need to know the exact nature of the error.
3. **Describe the implications of the error**. Readers need to know how the error might affect their interpretation of the results.
4. **Describe how the error occurred**. Its useful to know how the error happened so others can avoid the same error.
5. **Describe what you have done to address the error**. Others may learn from how any changes you have made to your workflow that might reduce the chance of the error happening again.
6. **Acknowledge the person who identified the error**. Identifying errors often requires a lot of work; if the person is willing to be identified, this will give credit where credit is due.

::: {.accident-report}
‚ö†Ô∏è Accident report: In 2018, at a crucial stage of her career, Julia Strand published "the most interesting finding of her career" in the prestigious journal *Psychonomic Bulletin & Review*. She presented the work at conferences and received additional funding on the basis of it. But several months later, her team found that they could not replicate the result. Puzzled, Julia began searching for the cause of the discrepant results. Eventually, she found the culprit - an error in the programming code. As she staring at her computer in horror, she realized that it was unlikely no one else would ever find the bug. It would have been easy to hide it. Instead, Julia did the right thing. She spent the next day telling her students, her co-authors, the funding officer, the department chair overseeing her tenure review, and the journal - to initiate a retraction of the article. And... it didn't ruin her career. Everybody was understanding and appreciate she was doing the right thing. The journal corrected the article. She didn't lose her grant. She got tenure. Honest mistakes happen - its how you respond to them that matters. You can read Julia's story in her own words here: https://perma.cc/H958-VWHG 
:::

### Responsible authorship and citation

Science is a community activity - its important to acknowledge the contributions of other scholars to your work. This includes citing previous work and acknowledging direct contributions to the current work.

**Cite sources**. When you build upon prior work, you should cite it. This ensures the authors of prior work receive credit for their contribution and allows readers to verify the basis of your claims. Try to be explicit about why you are citing a source, for example, does it provide evidence to support your point? Is it relevant review? Or is it a description of a theory you are testing? You should certainly avoid copying the work of others and presenting as your own (plagiarism, see Chapter \@ref(ethics)).

**Read before you cite**. Make sure you read articles before you cite them to ensure you understand them. @stang2018 reports a troubling case of citation misuse. One of the authors had previously published a commentary criticizing a methodological tool (the Newcastle‚ÄìOttawa scale) designed to assess the quality of non-randomized trials. They recommend the tool should not be used. The commentary was highly cited - in fact, it received more citations than the article that originally introduced the tool. @stang2018 examined a random sample of 96 systematic reviews that cited the critical commentary and found that 94 of them suggested the commentary *supported* the use of the scale!.

**Avoid selective or uncritical citation**. Only citing prior work that supports the point you are trying to make is misleading. You should provide a balanced account of prior work, including evidence that contradicts your point. Make sure to evaluate and integrate evidence, rather than simply listing studies. Remember - every study has limitations.

**Acknowledge authors and contributors**. Its important to acknowledge the individuals who worked on a research project so they can be properly credited and so the community knows who is responsible for the work. Currently in academic, the *authorship model* is dominant. Under this model, authorship and authorship order are important signals about researchers contributions to a project. It is generally expected that to qualify for authorship, an individual should have made a substantial contribution to the research, assists with writing the research report, and takes joint responsibility for the research along with the other co-authors. Individuals who worked on the prokect but do not reach this threshold are mentioned in a separate acknowledgements section, but not considered 'authors'. Authorship order is often taken as an approximate indicate of an authors contribution. In psychology (and neighbouring disciplines), the first author and last author are typically the project leaders. The first author is often a junior colleague who practically implements the project and the last author is often a senior colleague who supervises the project. It has been argued that the authorship model should be replaced with a more inclusive *contributorship* model in which all individuals who worked on the project are acknowlegded as 'contributors' and there is no arbitrary authorship threshold. The actual contributions of each individual are explictly described, rather than relying on the conventions of authorship order. This might help to facilitate collaboration and ensure student assistants are properly credited for their contributions. You will porbably find that most journals still expect you to use the authorship model; however, its usually possible to include a contributorship statement in your article that states what everybody did^[Check out the CREDIT taxonomy and the tool Tenzing [@holcombe2020]]. Because authorship is such an important signal in academia, its important to agree on an authorship plan with your collaborators (particularly who will be the first and last authors)

^[In 1975, physicist and mathematician Jack H. Hetherington wrote a paper he intended to submit to the journal *Physical Review Letters*. We're not sure why, but Hetherington wrote the paper in first person plural (i.e., referring to himself as 'we'). He subsequently discovered that the journal would not accept this for single-authored articles. These were the old days and Hetherington had painstakingly tapped out the article on his type writer, an exercise he was not keen to repeat. Instead, he opted for a less taxing solution and named his cat ‚Äî a feline by the name of F.D.C Willard ‚Äî as a coauthor. The paper was accepted and published [@hetherington1975]. We're not sure what the moral of this tale is, we just thought you would like to know.]

^[If you have find yourself in a situation where all authors have contributed equally, you may have to draw inspiration from historical examples and determine authorship order based on a 25 game croquet series [@hassell1974], rock, paper, scissors [@kupfer2004], or a brownie bake-off [@young1992]. Alternatively, you can adopt @lakens2018 method and randomize the order in R, the authors even share their code!]

## Chapter summary: Writing

In this chapter, you learned some key principles for writing clearly, writing reproducibily, and writing responsibly. 

::: {.exercise}
Find a writing buddy and exchange feedback on your next articles. Think consciously about how to improve each other's writing using the advice offered in this chapter.
:::

::: {.exercise}
Identify a published research article with openly available data and see if you can reproduce the analysis. You can find support for this exercise at the Social Science Reproduction Platform (https://www.socialsciencereproduction.org) or ReproHack (https://www.reprohack.org).
:::

::: {.reading}
Gernsbacher, M. A. (2018). Writing empirical articles: Transparency, reproducibility, clarity, and memorability. *Advances in Methods and Practices in Psychological Science*, *1*, 403‚Äì14. https://doi.org/10.1177/2515245918754485.

Zinsser, W. (2006). On writing well: The classic guide to writing nonfiction [7th ed]. Harper Collins.
:::
