<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 4 Ethics | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 4 Ethics | Experimentology">

<title>Chapter 4 Ethics | Experimentology</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.21/datatables.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>



<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="toc/toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#section"></a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li><a href="1-experiments.html#experiments"><span class="toc-section-number">1</span> Experiments</a></li>
<li><a href="2-theories.html#theories"><span class="toc-section-number">2</span> Theories</a></li>
<li><a href="3-replication.html#replication"><span class="toc-section-number">3</span> Replication and reproducibility</a></li>
<li><a href="4-ethics.html#ethics"><span class="toc-section-number">4</span> Ethics</a></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li><a href="5-estimation.html#estimation"><span class="toc-section-number">5</span> Estimation</a></li>
<li><a href="6-inference.html#inference"><span class="toc-section-number">6</span> Inference</a></li>
<li><a href="7-models.html#models"><span class="toc-section-number">7</span> Models</a></li>
<li class="part"><span><b>III Design and Planning</b></span></li>
<li><a href="8-measurement.html#measurement"><span class="toc-section-number">8</span> Measurement</a></li>
<li><a href="9-design.html#design"><span class="toc-section-number">9</span> Design of experiments</a></li>
<li><a href="10-sampling.html#sampling"><span class="toc-section-number">10</span> Sampling</a></li>
<li><a href="11-strategy.html#strategy"><span class="toc-section-number">11</span> Experimental strategy</a></li>
<li class="part"><span><b>IV Execution</b></span></li>
<li><a href="12-prereg.html#prereg"><span class="toc-section-number">12</span> Preregistration</a></li>
<li><a href="13-consent.html#consent"><span class="toc-section-number">13</span> Consent and the ethics of participation</a></li>
<li><a href="14-collection.html#collection"><span class="toc-section-number">14</span> Data collection</a></li>
<li><a href="15-management.html#management"><span class="toc-section-number">15</span> Project management</a></li>
<li class="part"><span><b>V Analysis and Reporting</b></span></li>
<li><a href="16-viz.html#viz"><span class="toc-section-number">16</span> Visualization</a></li>
<li><a href="17-eda.html#eda"><span class="toc-section-number">17</span> Exploratory data analysis</a></li>
<li><a href="18-writing.html#writing"><span class="toc-section-number">18</span> Writing</a></li>
<li><a href="19-meta.html#meta"><span class="toc-section-number">19</span> Meta-analysis</a></li>
<li><a href="20-conclusions.html#conclusions"><span class="toc-section-number">20</span> Conclusions</a></li>
<li class="part"><span><b>VI Appendices</b></span></li>
<li><a href="21-git.html#git"><span class="toc-section-number">21</span> GitHub Tutorial</a></li>
<li><a href="22-rmarkdown.html#rmarkdown"><span class="toc-section-number">22</span> R Markdown Tutorial</a></li>
<li><a href="23-tidyverse.html#tidyverse"><span class="toc-section-number">23</span> Tidyverse Tutorial</a></li>
<li><a href="24-ggplot.html#ggplot"><span class="toc-section-number">24</span> ggplot Tutorial</a></li>
<li><a href="25-instructors.html#instructors"><span class="toc-section-number">25</span> Instructor‚Äôs guide</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="ethics" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Ethics</h1>
<!-- ```{r ethics-meme} -->
<!-- knitr::include_graphics("images/ethics/meme.jpg") -->
<!-- ``` -->
<div class="learning-goals">
<p>üçé Learning goals:</p>
<ul>
<li>Distinguish between deontological, utilitarian, and virtue ethics approaches to research</li>
<li>Identify key ethical issues in experimental research</li>
<li>Describe the interactions between ethical issues and research transparency</li>
</ul>
</div>
<p>The fundamental thesis of this book is that experiments are the way to estimate causal effects, which are the foundations of theory. And as we discussed in Chapter <a href="1-experiments.html#experiments">1</a>, the reason why experiments allow for strong causal inferences is because of two ingredients: a manipulation ‚Äì in which the experimenter changes the world in some way ‚Äì and randomization. Put a different way, experimenters learn about the world by randomly deciding to do things to their participants! Is that even allowed?</p>
<p>In all seriousness, experimental research raises a host of ethical issues that deserve consideration. What can we and can‚Äôt we do to participants in an experiment, and what consideration do we owe to them by virtue of their decision to participate? To facilitate our discussion of these issues, we start by briefly introducing the standard philosophical frameworks for ethical analysis. We then use those to discuss problems of experimental ethics, first from the perspective of participants and then second from the perspective of the scientific ecosystem more broadly.</p>
<p>We have placed this chapter near the beginning of our book because we think it‚Äôs critical to start the conversation about the your ethical responsibilities as an experimentalist and researcher even before you start planning a study. We‚Äôll come back to the ethical frameworks we describe here when we discuss topics like allowable types of manipulation (Chapter <a href="9-design.html#design">9</a>), data sharing and privacy (Chapter <a href="15-management.html#management">15</a>), and publication ethics (Chapter <a href="18-writing.html#writing">18</a>).</p>
<div class="case-study">
<p>üî¨ Case study: Shock treatment</p>
<p>A decade after surviving prisoners were liberated from the last concentration camp, Adolf Eichmann, one of the Holocaust‚Äôs primary organizers and leaders, was tried for the role he played <span class="citation">(Baade, <a href="#ref-baade1961" role="doc-biblioref">1961</a>)</span>. While reflecting on his rationale for forcibly removing, torturing, and eventually murdering millions of Jews, an unrepentant Eichmann claimed that he was ‚Äúmerely a cog in the machinery that carried out the directives of the German Reich‚Äù and that he was not directly responsible <span class="citation">(Kilham &amp; Mann, <a href="#ref-kilham1974" role="doc-biblioref">1974</a>)</span>. This startling admission gave a young researcher an interesting idea: ‚Äúcould it be that Eichmann and his million accomplices in the Holocaust were just following orders? Could we call them all accomplices?‚Äù <span class="citation">(Milgram, <a href="#ref-milgram1974" role="doc-biblioref">1974</a>)</span>.</p>
<p>Stanley Milgram aimed to make a direct test of whether people would comply under the direction of an authority figure no matter how uncomfortable or harmful the outcome. He invited participants into the laboratory to serve as a teacher for an activity <span class="citation">(Milgram, <a href="#ref-milgram1963" role="doc-biblioref">1963</a>)</span>. Participants were told that they were to administer electric shocks of increasing voltage to another participant, the student, in a nearby room whenever the student provided an incorrect response. In reality, the student was a confederate who was in on the experiment and only pretended to be in pain when they received the shocks. Participants were encouraged to continue administering shocks despite clearly audible pleas from students to stop the electric shocks. In one of his studies, nearly 65% of participants administered the maximum voltage to the student. This deeply unsettling result has become, as <span class="citation">Ross &amp; Nisbett (<a href="#ref-ross2011" role="doc-biblioref">2011</a>)</span> says, ‚Äúpart of our society‚Äôs shared intellectual legacy,‚Äù informing our scientific and popular conversation in myriad different ways.</p>
<p>Milgram‚Äôs study blatantly violates modern ethical norms around the conduct of research. Among other violations, the procedure involved <strong>coercion</strong> that violated participants‚Äô right to withdraw from the experiment. This coercion appeared to have negative consequences: Milgram noted that a number of his participants displayed anxiety symptoms and nervousness.<label for="tufte-sn-49" class="margin-toggle sidenote-number">49</label><input type="checkbox" id="tufte-sn-49" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">49</span> To be fair, Milgram also conducted a followup survey in which participants expressed gratitude for participating and did not note long-term negative effects <span class="citation">(Milgram, <a href="#ref-milgram1974" role="doc-biblioref">1974</a>)</span>.</span> This observation that distressed observers and led to calls for this sort of research to be declared unethical <span class="citation">(e.g., Baumrind, <a href="#ref-baumrind1964" role="doc-biblioref">1964</a>)</span>. The ethical issues surrounding Milgram‚Äôs study are complex, and some are relatively specific to the particulars of his study and moment <span class="citation">(Miller, <a href="#ref-miller2009" role="doc-biblioref">2009</a>)</span>. But the controversy around the study was an important part of convincing the scientific community to adopt stricter policies that protect study participants from unnecessary harm.</p>
</div>
<div id="ethical-frameworks" class="section level2">
<h2><span class="header-section-number">4.1</span> Ethical frameworks</h2>
<p>Was Milgram‚Äôs experiment ethically wrong ‚Äì in the sense that it should not have been performed? Some of us probably have the intuition that is was unethical, due to the harms that the participants might have experienced or the way they were deceived by the experimenter. Others might consider arguments in defense of the experiment, perhaps that we learned from the experiment was sufficiently valuable to justify its being conducted. Beyond simply arguing back and forth, how could we decide this issue?</p>
<p>Ethical frameworks offer tools for analyzing complex situations like the Milgram experiment and trying to make determinations. In this first section, we‚Äôll discuss three of the most commonly used ethical frameworks: deontological (rule-based), utilitarian, and virtue ethics. We‚Äôll discuss how each of these could be applied to Milgram‚Äôs paradigm. In subsequent sections, we‚Äôll then discuss how these frameworks have led to the ethical guidelines for researchers that are formalized in the ethics review process that research studies must undergo.</p>
<div id="consequentialist-theories" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Consequentialist theories</h3>
<p>Ethical theories provide principles for what constitute good actions. The simplest theory of good actions is the <strong>consequentialist</strong> theory: good actions are lead to good results. The most famous consequentialist position is the <strong>utilitarian position</strong>, originally defined by the philosopher John Stuart Mill <span class="citation">(Flinders, <a href="#ref-flinders1992" role="doc-biblioref">1992</a>)</span>. This view emphasizes decision-making based on the ‚Äúgreatest happiness principle‚Äù, or the idea that an action should be considered morally good based on the degree of happiness or pleasure people experience because of it, and likewise that an action should be considered morally bad based on the degree of unhappiness or pain people experience by the same action <span class="citation">(Mill, <a href="#ref-mill1859" role="doc-biblioref">1859</a>)</span>.</p>
<p>A consequentialist analysis of Milgram‚Äôs study considers the study‚Äôs negative and positive effects and weighs these against one another. Did the study cause harm to its participants? If so, this should be counted against it. On the other hand, did the study lead to knowledge that prevented harm or caused positive benefits?</p>
<p>Consequentialist analysis can be a straightforward way to justify the risks and benefits of a particular action, but in the research setting it is unsatisfying. Many experiments horrifying experiments would be licensed by a consequentialist analysis and yet feel untenable to us. Imagine a researcher forced you to undergo a risky and undesired medical intervention because the resulting knowledge might benefit thousands of others. This seems like the kind of thing our ethical framework should rule out!</p>
</div>
<div id="deontological-and-virtue-based-approaches" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Deontological and virtue-based approaches</h3>
<p>Harmful research performed against participants‚Äô will or without their knowledge ‚Äì like the Tuskeegee Syphilis Study discussed below ‚Äì is repugnant. Considering such cases makes us think about rules like ‚Äúresearchers must ask before conducting research on people.‚Äù Principles like this one are now formalized in all ethical codes for research. They exemplify an approach called <strong>deontological</strong> (or duty-based) ethics. Deontology emphasizes the importance of taking ethically permissible actions, regardless of their outcome <span class="citation">(<span class="citeproc-not-found" data-reference-id="Biagetti2020"><strong>???</strong></span>)</span>.</p>
<p>16th century philosopher and Deontology‚Äôs most cited figure, Immanuel Kant, believed that there exists universal moral laws everyone must obey, and that following these laws elevates us to rational agents. For example, The Ten Commandments, a biblical account in which the Jewish God (? is this the right way to word this) instructed his servant, Moses, to write down ten rules for the Israelite (? Israelite in the Bible, but better to say Israelis?) people to obey, is a prime example of deontological ethics <strong><span class="citation">(<span class="citeproc-not-found" data-reference-id="English"><strong>???</strong></span> Standard Version Bible. (2001). ESV Online. <a href="https://esv.literalword.com/" class="uri" role="doc-biblioref">https://esv.literalword.com/</a>)</span></strong>. Commands such as ‚ÄúThou shalt not steal‚Äù and ‚ÄúThou shalt not kill‚Äù offered clear instructions for the Israelite people to obey. To Kant, deontology provided a means of establishing order without the confusion of evaluating individual outcomes. This line of thinking is akin to prioritizing ‚Äúintent‚Äù over ‚Äúimpact.‚Äù It is important to remember that deontological ethics is unconcerned with individual needs, wants, desires, and goals, which means that morality is a function of both duty and action. Thinking back to our initial example that opened this paragraph, if we asked why we needed to respect our elders, we may have been told it was ‚Äúthe right thing to do.‚Äù</p>
<!-- ### The Virtue Approach -->
<p>Another way we can approach this ethical dilemma is through a virtue framework. You have probably heard the phrase, ‚Äúpatience is a virtue‚Äù more than you care to remember, and that is probably because we have cared a lot about virtues for a very long time. From Aristotle to Voltaire, Churchill to Baldwin, and many others in between, we place a premium on virtuous actions. Before we dive any further, let‚Äôs first discuss what we mean by virtue. A <strong>virtue</strong> is a trait, a disposition, or a quality that is thought to be a moral foundation <span class="citation">(Annas, <a href="#ref-annas2006" role="doc-biblioref">2006</a>)</span>. Someone who regularly collects and hands out coats to refugees in their community may be thought of as having a virtue of compassion while someone else who always seeks to tell the truth no matter the consequences may be thought of as having a virtue of honesty. These virtues are both learned from and revered by a society, which only reinforces their importance.</p>
<p>One essential feature of virtue ethics is that people can learn to be virtuous by observing those actions in others they admire <span class="citation">(Morris &amp; Morris, <a href="#ref-morris2016" role="doc-biblioref">2016</a>)</span>. Proponents of virtue ethics say this works for two reasons: (1) people are generally good at recognizing morally good traits in others and (2) people receive some fulfillment in living virtuously. This is different from utilitarianism because it focuses on the actions and character of the person rather than on the consequences the action brings to the majority of society. Let‚Äôs return to the auto accident example we discussed earlier to illustrate this idea. How would you approach your grandparent about their views of victims of auto accidents under this ethical framework? If you want to think like a virtue theorist, you might consider the question, ‚ÄúWhat do I need to do to lead a good life?‚Äù If what matters to you are virtues of compassion and kindness, you will share your disappointment with your grandparent‚Äôs decision and will challenge the city ordinance they put in place. But if you value honor and respect above all else, you might decide not to speak up in this case. Are you seeing the difference now? Virtue ethics emphasize the goals of the individual and relies on peoples‚Äô desires to do the ‚Äúright‚Äù thing as they see it.</p>
<p>It might be easy to see the potential downsides to this framework when we think about the variety of goals that drive our decisions. No clearer do we see these differences than in the American political context. American politics is primarily divided into two parties- Democratic (typically liberals) and Republican (typically conservatives). These two political parties have become more polarized over the last four decades, not because one party is a bad apple but because the virtues that drive decision-making within these parties have become more distinct. Political debates are primarily concerned with one or more of five moral foundations- care (where the goal is to reduce suffering), fairness (where the goal is to improve equality), loyalty (where the goal is to support in-group members), authority (where the goal is to respect leadership and tradition), and sanctity (where the goal is to promote purity) <span class="citation">(Feinberg &amp; Willer, <a href="#ref-feinberg2019" role="doc-biblioref">2019</a>; Graham et al., <a href="#ref-graham2009" role="doc-biblioref">2009</a>)</span>. Whereas conservatives tend to value loyalty, authority, and sanctity, liberals have been shown to value care and fairness virtues. Because both parties have placed importance on differing virtues, party members approach policy decisions from the lens of the virtues they value. So which side is right? According to virtue ethics, they both are. So long as party members uphold values most important to them, all is right with the world.</p>
</div>
<div id="deontological-principles-for-research" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Deontological principles for research</h3>
<!-- think about this content, and how it supports the ethical conduct of research bits -->
<p>Deontology is primarily concerned with four ethical tenets:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Respect for autonomy</strong>. This means that people participating in research studies can make their own decisions about their participation, and that those with diminished autonomy (children, neuro-divergent people, etc.) should receive equal protections <span class="citation">(Beauchamp et al., <a href="#ref-beauchamp2001" role="doc-biblioref">2001</a>)</span>. Respecting someone‚Äôs autonomy also means providing them with all the information they need to make an informed decision about their participation in a research study without coercion. In short, we respect that people can make the best decision for themselves when provided with the appropriate information related to that decision.</p></li>
<li><p><strong>Beneficence</strong>. This means that researchers are obligated (not simply suggested) to protect the well-being of participants for the duration of the study. Beneficence is broken down into two actions based on writing from Greek physician, Hippocrates. The first is to do no harm. Researchers must take steps to minimize the risks to participants and to disclose any known risks at the onset. If risks are discovered during participation, researchers must notify participants of their discovery and make reasonable efforts to mitigate these risks, even if that means stopping the study altogether. The second is to maximize potential benefits. This doesn‚Äôt mean compensating participants with exorbitant amounts of money or gifts, it just means identifying all possible benefits and making them available where possible. For example, a study that explores the impact of daily journaling on depressive symptoms in adolescents could maximize benefits by inviting participants in the control or placebo conditions to also try journaling at the end of the study if it was shown to be effective at reducing depressive symptoms.</p></li>
<li><p><strong>Nonmaleficence</strong>. This principle is similar to beneficence (in fact, beneficence and nonmaleficence were a single principle when they were first introduced in the <strong>Belmont Report</strong>, which we‚Äôll discuss later) but differs in it‚Äôs emphasis on doing/causing no harm. But remember, deontology is about intent, not impact, so harm is sometimes warranted when the intent is morally good. For example, administering a vaccine may cause some discomfort and pain, but the intent is to protect the patient from developing a deadly virus in the future. The harm is justifiable under this framework. In social science research, we might ask participants to think about a painful memory or experience to understand how emotions can be better regulated, which may temporarily bring discomfort and sadness but ultimately improve emotion research.</p></li>
<li><p><strong>Justice</strong>. This means that both the benefits and risks of a study should be equally distributed among all participants. Justice can be based on multiple criteria, including need, effort, contribution, and merit. In human subjects research we do not base justice on effort, contribution, or merit because doing so would violate equal access to participation in research. This is also true in how participants are assigned to study conditions. In general, participants should not be systematically assigned to one condition over another due to features they arrive to the study with, like socioeconomic status, race and ethnicity, or gender. The caveat here is when there is sufficient evidence or presumption that these factors affect people in systematic ways. Even then, distributive justice is of the utmost importance.</p></li>
</ol>
<!-- This approach to ethics works well until it doesn't. Imagine you have a grandparent who says that people who don't wear seat belts should not receive medical attention if they are involved in an auto accident. What's more, your grandparent is on the local city council board and has decided to pass a city ordinance to prevent paramedics from assisting anyone suspected of not wearing their seat belt. Suddenly, you are faced with incompatible goals; although you have learned to respect your elders, you also believe that people who are involved in auto accidents deserve medical attention, regardless of whether or not they were wearing a seat belt at the time of impact. Deontological ethics deals only in absolutist terms, meaning that there exists one set of standards to follow and that there can be no gray area. Deontology cannot solve your complicated moral dilemma, and you are no closer to arriving at a solution. -->
<p>Declaration of Helsinki</p>
</div>
</div>
<div id="ethical-responsibilities-to-research-participants" class="section level2">
<h2><span class="header-section-number">4.2</span> Ethical responsibilities to research participants</h2>
<p>Milgram‚Äôs shock experiment was just one of dozens of unethical human subjects studies that garnered the attention and anger of the public in the United States. In 1978, the US National Commission for the Protection of Human Services of Biomedical and Behavioral Research released <strong>The Belmont Report</strong>, which described protections for the rights of human subjects participating in research studies <span class="citation">(Adashi et al., <a href="#ref-adashi2018" role="doc-biblioref">2018</a>)</span>. Perhaps the most important message found in the Report was the notion that ‚Äúinvestigators should not have sole responsibility for determining whether research involving human subjects fulfills ethical standards. Others, who are independent of the research, must share the responsibility.‚Äù In other words, ethical research required both transparency and external oversight.</p>
<p>In this section, we‚Äôll discuss the role of institutional review boards first. We‚Äôll then focus specifically on the consent and debriefing processes, as well as special protections for what are referred to as <strong>vulnerable populations</strong>.</p>
<!-- Whereas much of the research being done before the release of the Belmont Report modeled a utilitarian framework, commissioners were adamant that this approach was both unethical and self-serving. The days of exploitative and rogue human subjects research were dwindling quickly.  -->
<div id="institutional-review-boards" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Institutional review boards</h3>
<p>A by-product of the Belmont Report, and of calls to reform biomedical and behavioral research involving human subjects, was the creation of <strong>institutional review boards</strong> (IRB) in the United States. While regulartory frameworks and standards vary across national boundaries, ethical review of research is ubiquitous across countries.<label for="tufte-sn-50" class="margin-toggle sidenote-number">50</label><input type="checkbox" id="tufte-sn-50" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">50</span> In what follows, we focus on the US regulatory framework as it has been a model for other ethical review systems.</span></p>
<p>An IRB is a committee of people who review, evaluate, and monitor human subjects research to make sure that participants‚Äô rights are protected when they participate in research <span class="citation">(Oakes, <a href="#ref-oakes2002" role="doc-biblioref">2002</a>)</span>. IRBs are local; every organization that conducts human subjects or animal research is required to have its own IRB (or to contract with an external one). If you are based at a university, yours likely has its own, and its members are probably a mix of scientists, doctors, professors, and community residents.</p>
<p>When a group of researchers have a research question they are interested in pursuing with human subjects, they must receive approval from their local IRB before beginning any data collection. The IRB reviews each study to make sure:</p>
<ol style="list-style-type: decimal">
<li><p>A study poses <strong>minimal risk</strong> to participants. This means the anticipated harm or discomfort to the participant is not greater than what would be experienced in everyday life.</p></li>
<li><p>Researchers obtain <strong>informed consent</strong> from participants before collecting any data. This requirement means experimenters must disclose all potential risks and benefits so that participants can make an informed decision about whether or not to participate in the study. Importantly, informed consent does not stop after participants sign a consent form. If researchers discover any new potential risks or benefits along the way, they must disclose these discoveries to all participants.</p></li>
<li><p>All collected information remains confidential. <strong>Confidentiality</strong> is critical, especially when collecting protected information (which we discuss in more depth in Chapter <a href="15-management.html#management">15</a>). Although regulatory frameworks vary, researchers typically have an obligation to their participants to protect all identifying information.</p></li>
<li><p>Participants are recruited equitably and without coercion. Before the IRB became a standard oversight, researchers often utilized marginalized and vulnerable populations to test their research questions, and these questions sometimes required extremely invasive procedures. We‚Äôll discuss what we mean by marginalized and vulnerable populations in the Special Considerations for Vulnerable Populations section. For now, you should know that participation in research studies should always be made voluntary and that everyone eligible to for a study should have equal access to participate.</p></li>
</ol>
<p>TODO: Framework for risks and benefits</p>
<!-- Did you know that the IRB operates under one of the three ethical frameworks we discussed in the last section? Based on what you've learned so far, take a moment to guess which framework the IRB has adopted (no peeking!). If you guessed deontological, you're right. Remember that deontologists are concerned with the intent over the impact of an action. We do not steal because stealing is wrong. We can see a deontological IRB in action when we consider how they make decisions. One of the IRB's primary oversights is ensuring the autonomy of participants, and they do this by following a strict set of guidelines. This rule-based approach to ethics is paramount to deontology  -->
<!-- <p> Proposed framework: virtue </p> -->
<!-- <p> Navigation </p> -->
</div>
<div id="informed-consent" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Informed consent</h3>
<p>TODO: issues in informed consent</p>
<ul>
<li>comprehension</li>
<li>risks and benefits</li>
</ul>
<p>Respect for persons</p>
</div>
<div id="debriefing-participants" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Debriefing participants</h3>
<p>Every study should have a debriefing to end the study. In general, a debriefing is composed of four parts: (1) participation gratitude, (2) discussion of goals, (3) explanation of deception, and (4) questions and clarification <span class="citation">(Allen, <a href="#ref-allen2017" role="doc-biblioref">2017</a>)</span>.</p>
<p><strong>Gratitude.</strong> Thank participants for their involvement in research study! Sometimes thanks is enough (for a short experiment), but manby studies also include an additional token of appreciation such as monetary compensation or course credit. If monetary or other physical compensation will be implemented, it should be commensurate with the amount of time and effort required for participation. Compensation structures vary widely from place to place; typically local IRBs will have guidelines that they ask reseachers to comply with.</p>
<p><strong>Discussion of goals.</strong> Researchers should briefly share the purpose of the research study with participants. Why were participants recruited for this study in the first place? What are the researchers hoping to learn by conducting this study? It is important to ensure that participants fully understand the goals of the study, so avoiding technical jargon or confusing language is critical. You might also consider sharing any preliminary findings or where to find the completed write-up at the study‚Äôs conclusion ‚Äì many engaged participants really appreciate a link to research findings, even months or years after participation.<label for="tufte-sn-51" class="margin-toggle sidenote-number">51</label><input type="checkbox" id="tufte-sn-51" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">51</span> Sharing goals is especially important when some aspect of the study appears evaluative ‚Äì participants will often be interested in knowing how well they preformed against their peers. For example, a parent whose child completed a word-recognition task may request information about their child‚Äôs performance. It is often important to highlight that the goals of the study are not about individual evaluation and ranking.</span></p>
<p><strong>Explanation of deception.</strong> Researchers must reveal any deception during debriefing, regardless of how minor the deception seems to the researcher. This component of the debriefing process can be thought of as ‚Äúdehoaxing‚Äù because it is meant to illuminate any aspects of the study that were previously misleading or inaccurate <span class="citation">(Holmes, <a href="#ref-holmes1976" role="doc-biblioref">1976</a>)</span>. The goal both to reveal the true intent of the study and to alleviate any potential anxiety associated with the deception. After identifying where the deception occurred, it is useful to explain why the deception was necessary for the study‚Äôs success.</p>
<p><strong>Questions and clarification.</strong> Finally, researchers should answer any questions or address any concerns raised by participants. Many researchers use this opportunity to first ask participants about their interpretation of the study, what they thought were the study goals. This not only illuminates aspects of the study design that may have been unclear to or hidden from participants, but it also begins a discussion where both researchers and participants can communicate about this joint experience. This step is also helpful in identifying negative emotions or feelings resulting from the study <span class="citation">(Allen, <a href="#ref-allen2017" role="doc-biblioref">2017</a>)</span>. When participants do express negative emotions, researchers are responsible for sharing resources participants can use to work though the discomfort.</p>
<p>With the widespread use of data collection sites such as Amazon Mechanical Turk and Prolific, many researchers have elected to conduct some or all of their studies online. Debriefing is required regardless of the study‚Äôs presentation method. When a study is fully automated and participants do not interact with experimenters, researchers can make use of <strong>debriefing statements</strong>. Debriefing statements are documents that summarize all four components of the debriefing process (participation gratitude, discussion of goals, explanation of deception, and questions and clarification). Because experimenters are not present at the end of the study to answer participant questions, the statement typically provides the contact information for both the principal investigator and the IRB office. These communication channels should be clearly conveyed should participants need to follow up about the study for any reason.<label for="tufte-sn-52" class="margin-toggle sidenote-number">52</label><input type="checkbox" id="tufte-sn-52" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">52</span> Some studies may not be ethically appropriate for being run online. Studies that have substantial deception or that induce negative emotions may require an experimenter present to alleviate concerns and adrdess points of deception rather than relying on a written statement.</span></p>
</div>
<div id="special-considerations-for-vulnerable-populations" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Special considerations for vulnerable populations</h3>
<p>Regardless of who is participating in research, investigators have an obligation to protect the rights and well-being of all participants. However, some populations have been should be considered <strong>vulnerable</strong> because of their decreased agency ‚Äì either in general or in the face of potentially coercive situations. These populations should receive additional considerations or oversight when involving them in research studies. In this section, we will consider a few common vulnerable populations and discuss whether and how to include them in research studies.</p>
<p><strong>People with disabilities.</strong> There are thousands of disabilities that affect cognition, development, motor ability, communication, and decision-making with varying degrees of interference, so it is first important to remember that considerations for this population will be just as diverse as its members. Officially, a disability is a diagnosed mental or physical condition that limits or restricts a person‚Äôs involvement in daily activities <span class="citation">(<span class="citeproc-not-found" data-reference-id="stineman2001"><strong>???</strong></span>)</span>. Roughly 8% of the US population is disabled, which makes it likely that, in the context of a research study, researchers may come into contact with someone who is disabled. Assuming all general rules and regulations are followed, there are no laws that preclude people with disabilities from participating in research. However, those with cognitive disabilities who are unable to make their own decisions (importantly, this also applies to children with or without disabilities) may only participant with written consent from a legal guardian and with their individual assent (if applicable). This means that even if the person provides assent, researchers may not enroll them in the research study without also obtaining consent from their guardian. Those retaining full cognitive capacity but who have other disabilities that make it challenging to participate normally in the research study should receive appropriate accommodations to access the material, including the study‚Äôs risks and benefits.</p>
<p><strong>Children.</strong></p>
<p><strong>Crowd workers.</strong></p>
<p><strong>Low-income populations.</strong></p>
<p><strong>Prison population.</strong></p>
<div class="accident-report">
<p>‚ö†Ô∏è Accident report: The Tuskeegee Syphilis Study</p>
<p>In 1929, The United States Public Health Service (USPHS) was perplexed by the effects of a particular disease with an epicenter in Macon County, Alabama, with an overwhelmingly Black population <span class="citation">(Brandt, <a href="#ref-brandt1978" role="doc-biblioref">1978</a>)</span>. Syphilis is a sexually transmitted bacterial infection that can either be in a visible and active stage or in a latent stage. At the time of the study‚Äôs inception, roughly 36% of Tuskegee‚Äôs adult population had developed some form of syphilis, one of the highest infection rates in America <span class="citation">(White, <a href="#ref-white2006" role="doc-biblioref">2006</a>)</span>.</p>
<p>USPHS recruited 400 Black males from 25‚Äì60 years of age with latent syphilis and 200 Black males without the infection to serve as a control group to participate in what would become one of the most exploitative research studies ever done on American soil <span class="citation">(Brandt, <a href="#ref-brandt1978" role="doc-biblioref">1978</a>)</span>. The USPHS sought the help of the Macon County Board of Health to recruit participants with the promise that they would provide treatment for community members with syphilis. The researchers sought poor, illiterate Blacks and, instead of telling them that they were being recruited for a research study, they merely informed them that they would be treated for ‚Äúbad blood‚Äù, a phrase used in that time to refer to syphilis.</p>
<p>Because the study was only interested in tracking the natural course of latent syphilis without any medical intervention, the USPHS had no intention of providing any care to its participants. To assuage participants, the USPHS distributed an ointment not been shown to be effective in the treatment of syphilis, and only small doses of a medication actually used to treat the infection. In addition, participants underwent a spinal tap which was presented to them as another form of therapy and their ‚Äúlast chance for free treatment.‚Äù By 1955, just over 30% of the original participants had died from syphilis complications.</p>
<p>It took until the 1970s before the final report was released and (the lack of) treatment ended. In total, 128 participants died of syphilis or complications from the infection, 40 wives became infected, and 19 children were born with the infection <span class="citation">(Katz &amp; Warren, <a href="#ref-katz2011" role="doc-biblioref">2011</a>)</span>. The damage rippled through two generations, and many never actually learned what had been done to them. The Tuskeegee experiment violates nearly every single guideline for research described above ‚Äì indeed in its many horrifying violations of research participants‚Äô agency, it provides a blueprint for future regulation to prevent any aspect of it from being repeated.</p>
<p>Investigators did not obtain informed consent. Participants were not made aware of all known risks and benefits involved with their participation. Instead, they were deceived by researchers who led them to believe that diagnostic and invasive exams were directly related to their treatment.<label for="tufte-sn-53" class="margin-toggle sidenote-number">53</label><input type="checkbox" id="tufte-sn-53" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">53</span> In human subjects research, <strong>deception</strong> is a specific technical term that refers to cases when (1) experimenters withold any information about its goals or intentions, (2) experimenters hide their true identity (such as when using a confederate), (3) some aspects of the research are under- or overstated to conceal certain information, or (4) participants receive any false or misleading information <span class="citation">(<span class="citeproc-not-found" data-reference-id="tai2011"><strong>???</strong></span>)</span>.</span></p>
<p>Participants were denied appropriate treatment following the discovery that penicillin was effective at treating syphilis <span class="citation">(Mahoney et al., <a href="#ref-mahoney1943" role="doc-biblioref">1943</a>)</span>. The USPHS requested that medical professionals overseeing their care outside of the research study not offer treatment to participants so as to perserve the study‚Äôs integrity. This intervention violated participants‚Äô rights to equal access to care, which should have taken precedence over the results of the study.</p>
<p>Finally, recruitment was both imbalanced and coercive. Not only were participants selected from the poorest of neighborhoods in the hopes of finding vulnerable populations with little agency, but they were also bribed with empty promises of treatment and a monetary incentive (payment for burial fees, a financial obstacle for many sharecroppers and tenant farmers at the time).</p>
</div>
</div>
</div>
<div id="ethical-responsibilities-in-analysis-and-reporting-of-research" class="section level2">
<h2><span class="header-section-number">4.3</span> Ethical responsibilities in analysis and reporting of research</h2>
<div class="case-study">
<p>üî¨ Case study: What data?</p>
<p>Dutch social psychologist Diederick Stapel contributed to more than 200 articles on social comparison, stereotype threat, and discrimination, many published in the most prestigious journals. Stapel reported that affirming positive personal qualities buffered against dangerous social comparison, that product advertisements related to a person‚Äôs attractiveness changed their sense of self, and that exposure to intelligent in-group members boosted a person‚Äôs performance on an upcoming task <span class="citation">(Gordijn &amp; Stapel, <a href="#ref-gordijn2012" role="doc-biblioref">2012</a>; Stapel &amp; Linde, <a href="#ref-stapel2012" role="doc-biblioref">2012</a>; Trampe et al., <a href="#ref-trampe2011" role="doc-biblioref">2011</a>)</span>. These findings were fresh and noteworthy at the time of publication, and Stapel‚Äôs papers were cited thousands of times. The only problem? Much of Stapel‚Äôs data were invented.</p>
<p>When Stapel first began fabricating data, he admitted to making small tweaks to a few points <span class="citation">(Stapel, <a href="#ref-stapel2012b" role="doc-biblioref">2012</a>)</span>. Changing a single number here and there would turn a flat study into an impressive one. Having achieved comfortable success (and having aroused little suspicion from journal editors and others in the scientific community), Stapel eventually began altering entire data sets and passing them off as his own. Several colleagues began to grow skeptical of his overwhelming success, however, and brought their concerns to the Psychology Department at Tilburg University. By the time the investigation of his work concluded, 58 of Stapel‚Äôs papers were <strong>retracted</strong>, meaning that the publishing journal decided to withdraw the paper due to a recognition that its contents were erroneous or invalid.</p>
<p>Everyone agrees that Stapel‚Äôs behavior was deeply unethical. But should we consider cases of falsification and fraud to be different in kind from other ethical violations in research? Or is it merely the endpoint in a continuum that might include other causes of reproducibility and replicability failures documented in Chapter <a href="3-replication.html#replication">3</a>? Lawyers and philosophers grapple with the precise boundary between sloppiness and neglect, and it can be difficult to know which one is at play when a typo changes the conclusion of a scientific paper. Similarly, if a researcher engages in so-called ‚Äúquestionable research practices,‚Äù at what point should they be considered to have made an ethical violation as opposed to simply performing their research poorly?</p>
<p>These are hard questions, and we won‚Äôt provide conclusive answers. But we think you should try to grapple with them, since these situations are not as rare as we would like. We know typos are common! But more negative practices are also surprisingly widespread. In the survey we mentioned in the last chapter, <span class="citation">John et al. (<a href="#ref-john2012" role="doc-biblioref">2012</a>)</span> found a high rate of questionable research practice. Even more recently, in a high-quality national study of scientists, one in 12 respondents admitted to committing one or more forms of research misconduct and one in three self-identified as commiting some sort of questionable research practice <span class="citation">(Vrieze, <a href="#ref-devrieze2021" role="doc-biblioref">2021</a>)</span>. Thus, ethical issues are pervasive ‚Äì orienting yourself to them is critical.</p>
</div>
<p>Basic principles, APA ethics:
Principle A: Beneficence and Nonmaleficence
Principle B: Fidelity and Responsibility
Principle C: Integrity
Principle D: Justice
Principle E: Respect for People‚Äôs Rights and Dignity</p>
<blockquote>
<p>APA: (a) Psychologists do not fabricate data. (See also Standard 5.01a, Avoidance of False or Deceptive Statements .)
(b) If psychologists discover significant errors in their published data, they take reasonable steps to correct such errors in a correction, retraction, erratum, or other appropriate publication means.</p>
</blockquote>
<blockquote>
<p>Psychologists do not present portions of another‚Äôs work or data as their own, even if the other work or data source is cited occasionally.</p>
</blockquote>
</div>
<div id="ethical-responsibilities-to-the-broader-scientific-community" class="section level2">
<h2><span class="header-section-number">4.4</span> Ethical responsibilities to the broader scientific community</h2>
<p>We end this chapter by providing a somewhat novel argument: that the open science principles that we will describe throughout this book are not only important correctives to issues of reproducibility and replicability, they are also ethical duties.</p>
<p>The sociologist Robert Merton described a set of norms that science is assumed to follow: communism ‚Äì that scientific knowledge belongs to the community; universalism ‚Äì that the validity of scientific results is independent of the identity of the scientists; disinterestedness ‚Äì that scientists and scientific institutions act for the benefit of the overall enterprise; and organized skepticism ‚Äì that scientific findings must be critically evaluated prior to acceptance <span class="citation">(Merton, <a href="#ref-merton1979" role="doc-biblioref">1979</a>)</span>.</p>
<p>If the products of science aren‚Äôt open, it is very hard to be a scientist by Merton‚Äôs definition. To contribute to the communal good, papers need to be openly available. And to be subject to skeptical inquiry, experimental materials, research data, analytic code, and software must be all available so that analytic calculations can be verified and experiments can be reproduced. Otherwise, you have to accept arguments on authority rather than by virtue of the materials and data.</p>
<p>Openness is not only definitionally part of the scientific enterprise, it‚Äôs also good for science and individual scientists <span class="citation">(<span class="citeproc-not-found" data-reference-id="gorgelewski"><strong>???</strong></span>)</span>. Open access publications are cited more <span class="citation">(<span class="citeproc-not-found" data-reference-id="eyesenbach"><strong>???</strong></span>; <span class="citeproc-not-found" data-reference-id="gargouri"><strong>???</strong></span>)</span>. Open data also increases the potential for citation and reuse, and maximizes the chances that errors are found and corrected.</p>
<p>But these benefits means that researchers have a responsibility to their funders to pursue open practices so as to seek the maximal return on funders‚Äô investments. And by the same logic, if research participants contribute their time to scientific projects, the researchers also owe it to these participants to maximize the impact of their contributions <span class="citation">(Brakewood &amp; Poldrack, <a href="#ref-brakewood2013" role="doc-biblioref">2013</a>)</span>. For all of these reasons, individual scientists have a duty to be open ‚Äì and scientific institutions have a duty to promote transparency in the science they support and publish.</p>
<p>But how should these duties be balanced against researchers‚Äô other responsibilities. For example, how should we balance the benefit of data sharing against the commitment to preserve participant privacy? And, since ransparency policies also carry costs in terms of time and effort, how should researchers consider those costs against other obligations?</p>
<p>First, open practices should be a default in cases where risks and costs are limited. For example, the vast majority of journals allow authors to post accepted manuscripts in their untypset form to an open repository. This route to ‚Äúgreen‚Äù open access is easy, cost free, and ‚Äì because it comes only after articles are accepted for publication ‚Äì confers essentially no risks of scooping. As a second example, the vast majority of analytic code can be posted as an explicit record of exactly how analyses were conducted, even if posting data is sometimes more fraught. These kinds of ‚Äúincentive compatible‚Äù actions towards openness can bring researchers much of the way to a fully transparent workflow, and there is no excuse not to take them.</p>
<p>Second, researchers should plan for sharing and build a workflow that decreases the costs of openness.
* consent
* good tools
* good organization
* good privacy practices</p>
<p>Finally, given the ethical imperative towards openness, institutions like funders, journals, and societies need to use their role to promote open practices and to mitigate potential negatives. Scholarly societies have an important role to play in educating scientists about the benefits of openness and providing resources to steer their members towards best practices for sharing their publication and other research products. Similarly, journals can set good defaults, for example by requiring data and code sharing except in cases where a strong justification is given. Finally, funders of research can and do signal their interest in openness through data sharing mandates.</p>
</div>
<div id="chapter-summary-ethics" class="section level2">
<h2><span class="header-section-number">4.5</span> Chapter summary: Ethics</h2>

</div>
</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-adashi2018">
<p>Adashi, E. Y., Walters, L. B., &amp; Menikoff, J. A. (2018). The belmont report at 40: Reckoning with time. <em>American Journal of Public Health</em>, <em>108</em>(10), 1345‚Äì1348.</p>
</div>
<div id="ref-allen2017">
<p>Allen, M. (2017). Debriefing of participants. In <em>The sage encyclopedia of communication research methods</em> (Vols. 1-4). Sage Publications.</p>
</div>
<div id="ref-annas2006">
<p>Annas, J. (2006). Virtue ethics. <em>The Oxford Handbook of Ethical Theory</em>, 515‚Äì536.</p>
</div>
<div id="ref-baade1961">
<p>Baade, H. W. (1961). The eichmann trial: Some legal aspects. <em>Duke LJ</em>, 400.</p>
</div>
<div id="ref-baumrind1964">
<p>Baumrind, D. (1964). Some thoughts on ethics of research: After reading milgram‚Äôs" behavioral study of obedience.". <em>American Psychologist</em>, <em>19</em>(6), 421.</p>
</div>
<div id="ref-beauchamp2001">
<p>Beauchamp, T. L., Childress, J. F., &amp; others. (2001). <em>Principles of biomedical ethics</em>. Oxford University Press, USA.</p>
</div>
<div id="ref-brakewood2013">
<p>Brakewood, B., &amp; Poldrack, R. A. (2013). The ethics of secondary data analysis: Considering the application of belmont principles to the sharing of neuroimaging data. <em>Neuroimage</em>, <em>82</em>, 671‚Äì676.</p>
</div>
<div id="ref-brandt1978">
<p>Brandt, A. M. (1978). Racism and research: The case of the tuskegee syphilis study. <em>Hastings Center Report</em>, 21‚Äì29.</p>
</div>
<div id="ref-feinberg2019">
<p>Feinberg, M., &amp; Willer, R. (2019). Moral reframing: A technique for effective and persuasive communication across political divides. <em>Social and Personality Psychology Compass</em>, <em>13</em>(12), e12501.</p>
</div>
<div id="ref-flinders1992">
<p>Flinders, D. J. (1992). In search of ethical guidance: Constructing a basis for dialogue. <em>International Journal of Qualitative Studies in Education</em>, <em>5</em>(2), 101‚Äì115.</p>
</div>
<div id="ref-gordijn2012">
<p>Gordijn, E. H., &amp; Stapel, D. A. (2012). Behavioural effects of automatic interpersonal versus intergroup social comparison (retraction of vol 45, pg 717, 2006). <em>BRITISH JOURNAL OF SOCIAL PSYCHOLOGY</em>, <em>51</em>(3), 498‚Äì498.</p>
</div>
<div id="ref-graham2009">
<p>Graham, J., Haidt, J., &amp; Nosek, B. A. (2009). Liberals and conservatives rely on different sets of moral foundations. <em>Journal of Personality and Social Psychology</em>, <em>96</em>(5), 1029.</p>
</div>
<div id="ref-holmes1976">
<p>Holmes, D. S. (1976). Debriefing after psychological experiments: I. Effectiveness of postdeception dehoaxing. <em>American Psychologist</em>, <em>31</em>(12), 858.</p>
</div>
<div id="ref-john2012">
<p>John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth telling. <em>Psychological Science</em>, <em>23</em>(5), 524‚Äì532.</p>
</div>
<div id="ref-katz2011">
<p>Katz, R. V., &amp; Warren, R. C. (2011). <em>The search for the legacy of the usphs syphilis study at tuskegee</em>. Lexington Books.</p>
</div>
<div id="ref-kilham1974">
<p>Kilham, W., &amp; Mann, L. (1974). Level of destructive obedience as a function of transmitter and executant roles in the milgram obedience paradigm. <em>Journal of Personality and Social Psychology</em>, <em>29</em>(5), 696.</p>
</div>
<div id="ref-mahoney1943">
<p>Mahoney, J. F., Arnold, R., &amp; Harris, A. (1943). Penicillin treatment of early syphilis‚Äîa preliminary report. <em>American Journal of Public Health and the Nations Health</em>, <em>33</em>(12), 1387‚Äì1391.</p>
</div>
<div id="ref-merton1979">
<p>Merton, R. K. (1979). The normative structure of science. <em>The Sociology of Science: Theoretical and Empirical Investigations</em>, 267‚Äì278.</p>
</div>
<div id="ref-milgram1963">
<p>Milgram, S. (1963). Behavioral study of obedience. <em>The Journal of Abnormal and Social Psychology</em>, <em>67</em>(4), 371.</p>
</div>
<div id="ref-milgram1974">
<p>Milgram, S. (1974). <em>Obedience to authority: An experimental view</em>. Harper &amp; Row.</p>
</div>
<div id="ref-mill1859">
<p>Mill, J. S. (1859). Utilitarianism (1863). <em>Utilitarianism, Liberty, Representative Government</em>, 7‚Äì9.</p>
</div>
<div id="ref-miller2009">
<p>Miller, A. G. (2009). <em>Reflections on" replicating milgram"(Burger, 2009).</em></p>
</div>
<div id="ref-morris2016">
<p>Morris, M. C., &amp; Morris, J. Z. (2016). The importance of virtue ethics in the irb. <em>Research Ethics</em>, <em>12</em>(4), 201‚Äì216.</p>
</div>
<div id="ref-oakes2002">
<p>Oakes, J. M. (2002). Risks and wrongs in social science research: An evaluator‚Äôs guide to the irb. <em>Evaluation Review</em>, <em>26</em>(5), 443‚Äì479.</p>
</div>
<div id="ref-ross2011">
<p>Ross, L., &amp; Nisbett, R. E. (2011). <em>The person and the situation: Perspectives of social psychology</em>. Pinter &amp; Martin Publishers.</p>
</div>
<div id="ref-stapel2012b">
<p>Stapel, D. A. (2012). <em>Ontsporing</em>. Prometheus Amsterdam.</p>
</div>
<div id="ref-stapel2012">
<p>Stapel, D. A., &amp; Linde, L. A. van der. (2012). <em>"What drives self-affirmation effects? On the importance of differentiating value affirmation and attribute affirmation": Retraction of stapel and van der linde (2011).</em></p>
</div>
<div id="ref-trampe2011">
<p>Trampe, D., Stapel, D. A., &amp; Siero, F. W. (2011). Retracted: The self-activation effect of advertisements: Ads can affect whether and how consumers think about the self. <em>Journal of Consumer Research</em>, <em>37</em>(6), 1030‚Äì1045.</p>
</div>
<div id="ref-devrieze2021">
<p>Vrieze, J. de. (2021). Large survey finds questionable research practices are common. <em>Large Survey Finds Questionable Research Practices Are Common</em>.</p>
</div>
<div id="ref-white2006">
<p>White, R. M. (2006). Effects of untreated syphilis in the negro male, 1932 to 1972: A closure comes to the tuskegee study, 2004. <em>Urology</em>, <em>67</em>(3), 654.</p>
</div>
</div>
<p style="text-align: center;">
<a href="3-replication.html"><button class="btn btn-default">Previous</button></a>
<a href="5-estimation.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<script src="toc/toc.js"></script>


</body>
</html>
